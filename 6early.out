2023-10-19 05:01:29 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:01:29 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16002
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16002
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16002
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16002
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | initialized host eic-gt-gpu1 as rank 3
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | initialized host eic-gt-gpu1 as rank 1
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | initialized host eic-gt-gpu1 as rank 2
2023-10-19 05:01:33 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-10-19 05:01:33 | INFO | fairseq.distributed.utils | initialized host eic-gt-gpu1 as rank 0
2023-10-19 05:01:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16002', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_sidenet_gpt2_small', 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 12, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': True, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'reduction_factor': 8, 'layer_reduction_factor': 2, 'reload_ptm_layer': True, 'tune_lm_head': False, 'gpt_encoder_path': 'gpt2_bpe', 'use_external_memory': True, 'retrieval_layer_index': 17, 'chunk_size': 4, 'dstore_fp16': False, 'use_gpu_to_search': True, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 64, 'probe': 32, 'dstore_filename': 'data/datastore', 'long_context_attention': False, 'memory_size': 65536, 'precompute_mem_layer': 6, 'pretrained_model_path': '/data/zyu401_data/anirudh/longmem_data/LongMem_public_checkpoints/gpt2_medium/checkpoint_last.pt', 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': '/data/zyu401_data/anirudh/longmem_data/data-bin/longmem', 'sample_break_mode': none, 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'data_iteration': False, 'data_no_shuffle': True, 'seed': 42, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 100000.0, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-10-19 05:01:36 | INFO | fairseq.tasks.language_modeling | dictionary: 51200 types
Load Pre-trained GPT from /data/zyu401_data/anirudh/longmem_data/LongMem_public_checkpoints/gpt2_medium/checkpoint_last.pt
2023-10-19 05:01:49 | INFO | fairseq.tasks.gpt | dictionary: 51200 types
NewGPT retrieval Layer Index 17
Reload from pretrained model layer
set up external memory
chunk size 4
put index from cpu to gpu 0
put done
2023-10-19 05:01:59 | INFO | fairseq_cli.train | TransformerLanguageModelSideNet(
  (decoder): TransformerDecoderSideNet(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51200, 1024, padding_idx=1)
    (layers): ModuleList(
      (0-7): 8 x TransformerDecoderSideNetLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)
        )
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderSideNetLayer(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttentionWeightedSum(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)
        )
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9-11): 3 x TransformerDecoderSideNetLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)
        )
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (pretrained_model): NewGPTLanguageModel(
      (decoder): NewGPTDecoder(
        (model): NewGPTForCausalLM(
          (transformer): NewGPTModel(
            (wte): Embedding(51200, 1024)
            (drop): Dropout(p=0.1, inplace=False)
            (h): ModuleList(
              (0-23): 24 x NewGPTBlock(
                (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): NewGPTAttention(
                  (resid_dropout): Dropout(p=0.1, inplace=False)
                  (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
                  (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
                  (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
                  (out_proj): Linear(in_features=1024, out_features=1024, bias=False)
                )
                (mlp): NewGPTMLP(
                  (fc_in): Linear(in_features=1024, out_features=4096, bias=True)
                  (fc_out): Linear(in_features=4096, out_features=1024, bias=True)
                  (act): NewGELUActivation()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (ln_f): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (lm_head): Linear(in_features=1024, out_features=51200, bias=True)
        )
      )
    )
    (output_projection): Linear(in_features=1024, out_features=51200, bias=False)
  )
)
2023-10-19 05:01:59 | INFO | fairseq_cli.train | task: LanguageModelingTask
2023-10-19 05:01:59 | INFO | fairseq_cli.train | model: TransformerLanguageModelSideNet
2023-10-19 05:01:59 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2023-10-19 05:01:59 | INFO | fairseq_cli.train | num. shared model params: 558,155,792 (num. trained: 151,083,024)
2023-10-19 05:01:59 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-10-19 05:02:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-19 05:02:00 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.pretrained_model.decoder.model.transformer.wte.weight
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.0.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.0.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.0.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.1.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.1.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.1.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.1.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.2.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.2.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.2.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.2.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.3.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.3.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.3.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.3.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.4.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.4.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.4.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.4.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.5.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.5.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.5.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.5.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.6.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.6.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.6.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.6.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.7.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.7.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.7.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.7.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.8.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.8.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.8.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.8.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.9.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.9.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.9.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.9.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.10.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.10.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.10.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.10.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.11.self_attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.11.self_attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.11.self_attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.layers.11.self_attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.0.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.0.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.0.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.0.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.1.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.1.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.1.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.1.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.2.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.2.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.2.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.2.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.3.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.3.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.3.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.3.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.4.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.4.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.4.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.4.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.5.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.5.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.5.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.5.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.6.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.6.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.6.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.6.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.7.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.7.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.7.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.7.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.8.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.8.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.8.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.8.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.9.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.9.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.9.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.9.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.10.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.10.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.10.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.10.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.11.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.11.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.11.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.11.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.12.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.12.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.12.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.12.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.13.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.13.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.13.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.13.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.14.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.14.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.14.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.14.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.15.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.15.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.15.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.15.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.16.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.16.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.16.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.16.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.17.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.17.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.17.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.17.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.18.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.18.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.18.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.18.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.19.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.19.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.19.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.19.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.20.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.20.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.20.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.20.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.21.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.21.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.21.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.21.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.22.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.22.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.22.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.22.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.23.attn.q_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.23.attn.k_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.23.attn.v_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.pretrained_model.decoder.model.transformer.h.23.attn.out_proj.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.layers.0.self_attn.k_proj.bias <- decoder.output_projection.bias
2023-10-19 05:02:00 | INFO | fairseq.trainer | detected shared parameter: decoder.pretrained_model.decoder.model.lm_head.weight <- decoder.output_projection.weight
2023-10-19 05:02:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-10-19 05:02:01 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 22.188 GB ; name = NVIDIA RTX A5000                        
2023-10-19 05:02:01 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 22.188 GB ; name = NVIDIA RTX A5000                        
2023-10-19 05:02:01 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 22.188 GB ; name = NVIDIA RTX A5000                        
2023-10-19 05:02:01 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 22.188 GB ; name = NVIDIA RTX A5000                        
2023-10-19 05:02:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-10-19 05:02:01 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-10-19 05:02:01 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1
2023-10-19 05:02:01 | INFO | fairseq.trainer | Preparing to load checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_last.pt
2023-10-19 05:02:01 | INFO | fairseq.trainer | No existing checkpoint found /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_last.pt
2023-10-19 05:02:01 | INFO | fairseq.trainer | loading train data for epoch 1
2023-10-19 05:04:30 | INFO | fairseq.data.data_utils | loaded 1,681,792,185 examples from: /data/zyu401_data/anirudh/longmem_data/data-bin/longmem/train
Load Pre-trained GPT from /data/zyu401_data/anirudh/longmem_data/LongMem_public_checkpoints/gpt2_medium/checkpoint_last.pt
NewGPT retrieval Layer Index 17
Reload from pretrained model layer
set up external memory
chunk size 4
put index from cpu to gpu 2
put done
[29290284]
[29290285]
Load Pre-trained GPT from /data/zyu401_data/anirudh/longmem_data/LongMem_public_checkpoints/gpt2_medium/checkpoint_last.pt
NewGPT retrieval Layer Index 17
Reload from pretrained model layer
set up external memory
chunk size 4
put index from cpu to gpu 1
put done
[14645142]
[14645143]
[0]
[1]
2023-10-19 05:09:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1830643
2023-10-19 05:09:30 | INFO | fairseq.trainer | begin training epoch 1
2023-10-19 05:09:30 | INFO | fairseq_cli.train | Start iterating over samples
Load Pre-trained GPT from /data/zyu401_data/anirudh/longmem_data/LongMem_public_checkpoints/gpt2_medium/checkpoint_last.pt
NewGPT retrieval Layer Index 17
Reload from pretrained model layer
set up external memory
chunk size 4
put index from cpu to gpu 3
put done
[43935426]
[43935427]
2023-10-19 05:09:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:09:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:09:33 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:09:33 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:09:35 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:09:35 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
2023-10-19 05:09:35 | INFO | faiss.loader | Loading faiss with AVX2 support.
2023-10-19 05:09:35 | INFO | faiss.loader | Successfully loaded faiss with AVX2 support.
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2023-10-19 05:11:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-10-19 05:11:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-10-19 05:11:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 05:11:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 05:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 05:11:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 05:13:38 | INFO | train_inner | epoch 001:    106 / 1830643 loss=4.215, ppl=18.57, wps=24109.1, ups=0.74, wpb=32768, bsz=32, num_updates=100, lr=0.0001998, gnorm=0.52, loss_scale=2, train_wall=144, gb_free=15.4, wall=698
2023-10-19 05:15:55 | INFO | train_inner | epoch 001:    206 / 1830643 loss=4.009, ppl=16.11, wps=23908.2, ups=0.73, wpb=32768, bsz=32, num_updates=200, lr=0.0001996, gnorm=0.28, loss_scale=2, train_wall=137, gb_free=15.4, wall=835
2023-10-19 05:18:11 | INFO | train_inner | epoch 001:    306 / 1830643 loss=3.913, ppl=15.06, wps=24094.9, ups=0.74, wpb=32768, bsz=32, num_updates=300, lr=0.0001994, gnorm=0.288, loss_scale=2, train_wall=136, gb_free=15.4, wall=971
2023-10-19 05:20:28 | INFO | train_inner | epoch 001:    406 / 1830643 loss=4.035, ppl=16.39, wps=24057.9, ups=0.73, wpb=32768, bsz=32, num_updates=400, lr=0.0001992, gnorm=0.281, loss_scale=2, train_wall=136, gb_free=15.4, wall=1107
2023-10-19 05:22:44 | INFO | train_inner | epoch 001:    506 / 1830643 loss=3.7, ppl=12.99, wps=24047, ups=0.73, wpb=32768, bsz=32, num_updates=500, lr=0.000199, gnorm=0.268, loss_scale=2, train_wall=136, gb_free=15.4, wall=1243
2023-10-19 05:25:00 | INFO | train_inner | epoch 001:    606 / 1830643 loss=3.713, ppl=13.11, wps=24111.7, ups=0.74, wpb=32768, bsz=32, num_updates=600, lr=0.0001988, gnorm=0.286, loss_scale=4, train_wall=136, gb_free=15.4, wall=1379
2023-10-19 05:27:16 | INFO | train_inner | epoch 001:    706 / 1830643 loss=3.694, ppl=12.95, wps=24129.2, ups=0.74, wpb=32768, bsz=32, num_updates=700, lr=0.0001986, gnorm=0.305, loss_scale=4, train_wall=135, gb_free=15.4, wall=1515
2023-10-19 05:29:32 | INFO | train_inner | epoch 001:    806 / 1830643 loss=3.653, ppl=12.58, wps=24025.5, ups=0.73, wpb=32768, bsz=32, num_updates=800, lr=0.0001984, gnorm=0.255, loss_scale=4, train_wall=136, gb_free=15.4, wall=1651
2023-10-19 05:31:48 | INFO | train_inner | epoch 001:    906 / 1830643 loss=3.735, ppl=13.32, wps=24048.5, ups=0.73, wpb=32768, bsz=32, num_updates=900, lr=0.0001982, gnorm=0.256, loss_scale=4, train_wall=136, gb_free=15.4, wall=1787
2023-10-19 05:34:05 | INFO | train_inner | epoch 001:   1006 / 1830643 loss=3.732, ppl=13.28, wps=24005.8, ups=0.73, wpb=32768, bsz=32, num_updates=1000, lr=0.000198, gnorm=0.268, loss_scale=4, train_wall=136, gb_free=15.4, wall=1924
2023-10-19 05:36:20 | INFO | train_inner | epoch 001:   1106 / 1830643 loss=3.592, ppl=12.06, wps=24130.9, ups=0.74, wpb=32768, bsz=32, num_updates=1100, lr=0.0001978, gnorm=0.287, loss_scale=8, train_wall=135, gb_free=15.4, wall=2060
2023-10-19 05:38:37 | INFO | train_inner | epoch 001:   1206 / 1830643 loss=3.759, ppl=13.54, wps=24051.4, ups=0.73, wpb=32768, bsz=32, num_updates=1200, lr=0.0001976, gnorm=0.236, loss_scale=8, train_wall=136, gb_free=15.4, wall=2196
2023-10-19 05:40:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 05:40:54 | INFO | train_inner | epoch 001:   1307 / 1830643 loss=3.804, ppl=13.97, wps=23786.7, ups=0.73, wpb=32768, bsz=32, num_updates=1300, lr=0.0001974, gnorm=0.272, loss_scale=4, train_wall=137, gb_free=15.4, wall=2334
2023-10-19 05:43:11 | INFO | train_inner | epoch 001:   1407 / 1830643 loss=3.851, ppl=14.43, wps=24053.3, ups=0.73, wpb=32768, bsz=32, num_updates=1400, lr=0.0001972, gnorm=0.231, loss_scale=4, train_wall=136, gb_free=15.4, wall=2470
2023-10-19 05:45:27 | INFO | train_inner | epoch 001:   1507 / 1830643 loss=3.427, ppl=10.75, wps=24064.4, ups=0.73, wpb=32768, bsz=32, num_updates=1500, lr=0.000197, gnorm=0.202, loss_scale=4, train_wall=136, gb_free=15.4, wall=2606
2023-10-19 05:47:43 | INFO | train_inner | epoch 001:   1607 / 1830643 loss=3.839, ppl=14.31, wps=24107, ups=0.74, wpb=32768, bsz=32, num_updates=1600, lr=0.0001968, gnorm=0.268, loss_scale=4, train_wall=136, gb_free=15.4, wall=2742
2023-10-19 05:49:59 | INFO | train_inner | epoch 001:   1707 / 1830643 loss=3.628, ppl=12.36, wps=24022.4, ups=0.73, wpb=32768, bsz=32, num_updates=1700, lr=0.0001966, gnorm=0.267, loss_scale=4, train_wall=136, gb_free=15.4, wall=2878
2023-10-19 05:50:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 05:52:16 | INFO | train_inner | epoch 001:   1808 / 1830643 loss=3.821, ppl=14.14, wps=23871.3, ups=0.73, wpb=32768, bsz=32, num_updates=1800, lr=0.0001964, gnorm=0.222, loss_scale=2, train_wall=137, gb_free=15.4, wall=3016
2023-10-19 05:54:33 | INFO | train_inner | epoch 001:   1908 / 1830643 loss=3.687, ppl=12.88, wps=24062.1, ups=0.73, wpb=32768, bsz=32, num_updates=1900, lr=0.0001962, gnorm=0.236, loss_scale=2, train_wall=136, gb_free=15.4, wall=3152
2023-10-19 05:56:49 | INFO | train_inner | epoch 001:   2008 / 1830643 loss=3.334, ppl=10.09, wps=24108.9, ups=0.74, wpb=32768, bsz=32, num_updates=2000, lr=0.000196, gnorm=0.236, loss_scale=2, train_wall=136, gb_free=15.4, wall=3288
2023-10-19 05:59:05 | INFO | train_inner | epoch 001:   2108 / 1830643 loss=3.684, ppl=12.85, wps=24059.2, ups=0.73, wpb=32768, bsz=32, num_updates=2100, lr=0.0001958, gnorm=0.227, loss_scale=2, train_wall=136, gb_free=15.4, wall=3424
2023-10-19 06:01:21 | INFO | train_inner | epoch 001:   2208 / 1830643 loss=3.655, ppl=12.6, wps=24004.7, ups=0.73, wpb=32768, bsz=32, num_updates=2200, lr=0.0001956, gnorm=0.222, loss_scale=2, train_wall=136, gb_free=15.4, wall=3561
2023-10-19 06:03:38 | INFO | train_inner | epoch 001:   2308 / 1830643 loss=3.573, ppl=11.9, wps=23992.1, ups=0.73, wpb=32768, bsz=32, num_updates=2300, lr=0.0001954, gnorm=0.252, loss_scale=4, train_wall=136, gb_free=15.4, wall=3697
2023-10-19 06:05:54 | INFO | train_inner | epoch 001:   2408 / 1830643 loss=3.734, ppl=13.31, wps=24132.3, ups=0.74, wpb=32768, bsz=32, num_updates=2400, lr=0.0001952, gnorm=0.229, loss_scale=4, train_wall=135, gb_free=15.4, wall=3833
2023-10-19 06:08:09 | INFO | train_inner | epoch 001:   2508 / 1830643 loss=3.609, ppl=12.21, wps=24205.1, ups=0.74, wpb=32768, bsz=32, num_updates=2500, lr=0.000195, gnorm=0.217, loss_scale=4, train_wall=135, gb_free=15.4, wall=3968
2023-10-19 06:10:24 | INFO | train_inner | epoch 001:   2608 / 1830643 loss=3.635, ppl=12.42, wps=24209.3, ups=0.74, wpb=32768, bsz=32, num_updates=2600, lr=0.0001948, gnorm=0.21, loss_scale=4, train_wall=135, gb_free=15.4, wall=4104
2023-10-19 06:12:40 | INFO | train_inner | epoch 001:   2708 / 1830643 loss=3.727, ppl=13.24, wps=24192.9, ups=0.74, wpb=32768, bsz=32, num_updates=2700, lr=0.0001946, gnorm=0.228, loss_scale=4, train_wall=135, gb_free=15.4, wall=4239
2023-10-19 06:14:55 | INFO | train_inner | epoch 001:   2808 / 1830643 loss=3.676, ppl=12.78, wps=24174.5, ups=0.74, wpb=32768, bsz=32, num_updates=2800, lr=0.0001944, gnorm=0.212, loss_scale=8, train_wall=135, gb_free=15.4, wall=4375
2023-10-19 06:17:11 | INFO | train_inner | epoch 001:   2908 / 1830643 loss=3.585, ppl=12, wps=24190.2, ups=0.74, wpb=32768, bsz=32, num_updates=2900, lr=0.0001942, gnorm=0.241, loss_scale=8, train_wall=135, gb_free=15.4, wall=4510
2023-10-19 06:19:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 06:19:27 | INFO | train_inner | epoch 001:   3009 / 1830643 loss=3.672, ppl=12.74, wps=23993.4, ups=0.73, wpb=32768, bsz=32, num_updates=3000, lr=0.000194, gnorm=0.241, loss_scale=4, train_wall=136, gb_free=15.4, wall=4647
2023-10-19 06:21:43 | INFO | train_inner | epoch 001:   3109 / 1830643 loss=3.619, ppl=12.29, wps=24238.1, ups=0.74, wpb=32768, bsz=32, num_updates=3100, lr=0.0001938, gnorm=0.199, loss_scale=4, train_wall=135, gb_free=15.4, wall=4782
2023-10-19 06:23:58 | INFO | train_inner | epoch 001:   3209 / 1830643 loss=3.646, ppl=12.52, wps=24236.5, ups=0.74, wpb=32768, bsz=32, num_updates=3200, lr=0.0001936, gnorm=0.214, loss_scale=4, train_wall=135, gb_free=15.4, wall=4917
2023-10-19 06:26:13 | INFO | train_inner | epoch 001:   3309 / 1830643 loss=3.551, ppl=11.72, wps=24214.2, ups=0.74, wpb=32768, bsz=32, num_updates=3300, lr=0.0001934, gnorm=0.228, loss_scale=4, train_wall=135, gb_free=15.4, wall=5052
2023-10-19 06:28:29 | INFO | train_inner | epoch 001:   3409 / 1830643 loss=3.683, ppl=12.85, wps=24197.6, ups=0.74, wpb=32768, bsz=32, num_updates=3400, lr=0.0001932, gnorm=0.214, loss_scale=4, train_wall=135, gb_free=15.4, wall=5188
2023-10-19 06:30:44 | INFO | train_inner | epoch 001:   3509 / 1830643 loss=3.63, ppl=12.38, wps=24240.8, ups=0.74, wpb=32768, bsz=32, num_updates=3500, lr=0.000193, gnorm=0.206, loss_scale=4, train_wall=135, gb_free=15.4, wall=5323
2023-10-19 06:32:59 | INFO | train_inner | epoch 001:   3609 / 1830643 loss=3.487, ppl=11.22, wps=24243.1, ups=0.74, wpb=32768, bsz=32, num_updates=3600, lr=0.0001928, gnorm=0.2, loss_scale=8, train_wall=135, gb_free=15.4, wall=5458
2023-10-19 06:35:14 | INFO | train_inner | epoch 001:   3709 / 1830643 loss=3.531, ppl=11.56, wps=24178, ups=0.74, wpb=32768, bsz=32, num_updates=3700, lr=0.0001926, gnorm=0.205, loss_scale=8, train_wall=135, gb_free=15.4, wall=5594
2023-10-19 06:37:30 | INFO | train_inner | epoch 001:   3809 / 1830643 loss=3.754, ppl=13.49, wps=24182.8, ups=0.74, wpb=32768, bsz=32, num_updates=3800, lr=0.0001924, gnorm=0.231, loss_scale=8, train_wall=135, gb_free=15.4, wall=5729
2023-10-19 06:39:45 | INFO | train_inner | epoch 001:   3909 / 1830643 loss=3.574, ppl=11.91, wps=24190.6, ups=0.74, wpb=32768, bsz=32, num_updates=3900, lr=0.0001922, gnorm=0.204, loss_scale=8, train_wall=135, gb_free=15.4, wall=5865
2023-10-19 06:42:00 | INFO | train_inner | epoch 001:   4009 / 1830643 loss=3.676, ppl=12.78, wps=24273.7, ups=0.74, wpb=32768, bsz=32, num_updates=4000, lr=0.000192, gnorm=0.223, loss_scale=8, train_wall=135, gb_free=15.4, wall=6000
2023-10-19 06:42:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 06:44:17 | INFO | train_inner | epoch 001:   4110 / 1830643 loss=3.582, ppl=11.98, wps=24012.7, ups=0.73, wpb=32768, bsz=32, num_updates=4100, lr=0.0001918, gnorm=0.213, loss_scale=8, train_wall=136, gb_free=15.4, wall=6136
2023-10-19 06:46:32 | INFO | train_inner | epoch 001:   4210 / 1830643 loss=3.533, ppl=11.58, wps=24199.2, ups=0.74, wpb=32768, bsz=32, num_updates=4200, lr=0.0001916, gnorm=0.21, loss_scale=8, train_wall=135, gb_free=15.4, wall=6271
2023-10-19 06:48:48 | INFO | train_inner | epoch 001:   4310 / 1830643 loss=3.649, ppl=12.55, wps=24225, ups=0.74, wpb=32768, bsz=32, num_updates=4300, lr=0.0001914, gnorm=0.208, loss_scale=8, train_wall=135, gb_free=15.4, wall=6407
2023-10-19 06:51:03 | INFO | train_inner | epoch 001:   4410 / 1830643 loss=3.529, ppl=11.54, wps=24215, ups=0.74, wpb=32768, bsz=32, num_updates=4400, lr=0.0001912, gnorm=0.215, loss_scale=8, train_wall=135, gb_free=15.4, wall=6542
2023-10-19 06:53:19 | INFO | train_inner | epoch 001:   4510 / 1830643 loss=3.487, ppl=11.21, wps=24114, ups=0.74, wpb=32768, bsz=32, num_updates=4500, lr=0.000191, gnorm=0.209, loss_scale=8, train_wall=135, gb_free=15.4, wall=6678
2023-10-19 06:55:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 06:55:36 | INFO | train_inner | epoch 001:   4611 / 1830643 loss=3.626, ppl=12.35, wps=23919.9, ups=0.73, wpb=32768, bsz=32, num_updates=4600, lr=0.0001908, gnorm=0.204, loss_scale=8, train_wall=137, gb_free=15.4, wall=6815
2023-10-19 06:57:52 | INFO | train_inner | epoch 001:   4711 / 1830643 loss=3.701, ppl=13, wps=24103.9, ups=0.74, wpb=32768, bsz=32, num_updates=4700, lr=0.0001906, gnorm=0.206, loss_scale=8, train_wall=136, gb_free=15.4, wall=6951
2023-10-19 07:00:07 | INFO | train_inner | epoch 001:   4811 / 1830643 loss=3.703, ppl=13.03, wps=24201.6, ups=0.74, wpb=32768, bsz=32, num_updates=4800, lr=0.0001904, gnorm=0.207, loss_scale=8, train_wall=135, gb_free=15.4, wall=7086
2023-10-19 07:02:22 | INFO | train_inner | epoch 001:   4911 / 1830643 loss=3.628, ppl=12.36, wps=24227.6, ups=0.74, wpb=32768, bsz=32, num_updates=4900, lr=0.0001902, gnorm=0.192, loss_scale=8, train_wall=135, gb_free=15.4, wall=7222
2023-10-19 07:04:38 | INFO | train_inner | epoch 001:   5011 / 1830643 loss=3.523, ppl=11.5, wps=24189, ups=0.74, wpb=32768, bsz=32, num_updates=5000, lr=0.00019, gnorm=0.214, loss_scale=8, train_wall=135, gb_free=15.4, wall=7357
2023-10-19 07:06:54 | INFO | train_inner | epoch 001:   5111 / 1830643 loss=3.703, ppl=13.02, wps=24139.1, ups=0.74, wpb=32768, bsz=32, num_updates=5100, lr=0.0001898, gnorm=0.208, loss_scale=8, train_wall=135, gb_free=15.4, wall=7493
2023-10-19 07:07:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 07:09:10 | INFO | train_inner | epoch 001:   5212 / 1830643 loss=3.783, ppl=13.76, wps=24033.1, ups=0.73, wpb=32768, bsz=32, num_updates=5200, lr=0.0001896, gnorm=0.22, loss_scale=8, train_wall=136, gb_free=15.4, wall=7629
2023-10-19 07:11:25 | INFO | train_inner | epoch 001:   5312 / 1830643 loss=3.721, ppl=13.18, wps=24213, ups=0.74, wpb=32768, bsz=32, num_updates=5300, lr=0.0001894, gnorm=0.194, loss_scale=8, train_wall=135, gb_free=15.4, wall=7764
2023-10-19 07:13:41 | INFO | train_inner | epoch 001:   5412 / 1830643 loss=3.572, ppl=11.89, wps=24117, ups=0.74, wpb=32768, bsz=32, num_updates=5400, lr=0.0001892, gnorm=0.186, loss_scale=8, train_wall=135, gb_free=15.4, wall=7900
2023-10-19 07:15:57 | INFO | train_inner | epoch 001:   5512 / 1830643 loss=3.599, ppl=12.12, wps=24143, ups=0.74, wpb=32768, bsz=32, num_updates=5500, lr=0.000189, gnorm=0.24, loss_scale=8, train_wall=135, gb_free=15.4, wall=8036
2023-10-19 07:18:12 | INFO | train_inner | epoch 001:   5612 / 1830643 loss=3.568, ppl=11.86, wps=24177.1, ups=0.74, wpb=32768, bsz=32, num_updates=5600, lr=0.0001888, gnorm=0.19, loss_scale=8, train_wall=135, gb_free=15.4, wall=8172
2023-10-19 07:20:28 | INFO | train_inner | epoch 001:   5712 / 1830643 loss=3.603, ppl=12.15, wps=24204.1, ups=0.74, wpb=32768, bsz=32, num_updates=5700, lr=0.0001886, gnorm=0.191, loss_scale=16, train_wall=135, gb_free=15.4, wall=8307
2023-10-19 07:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 07:22:44 | INFO | train_inner | epoch 001:   5813 / 1830643 loss=3.698, ppl=12.98, wps=23976.4, ups=0.73, wpb=32768, bsz=32, num_updates=5800, lr=0.0001884, gnorm=0.212, loss_scale=8, train_wall=136, gb_free=15.4, wall=8444
2023-10-19 07:25:00 | INFO | train_inner | epoch 001:   5913 / 1830643 loss=3.465, ppl=11.04, wps=24195.8, ups=0.74, wpb=32768, bsz=32, num_updates=5900, lr=0.0001882, gnorm=0.191, loss_scale=8, train_wall=135, gb_free=15.4, wall=8579
2023-10-19 07:26:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 07:27:17 | INFO | train_inner | epoch 001:   6014 / 1830643 loss=3.452, ppl=10.95, wps=23935.5, ups=0.73, wpb=32768, bsz=32, num_updates=6000, lr=0.000188, gnorm=0.202, loss_scale=4, train_wall=137, gb_free=15.4, wall=8716
2023-10-19 07:29:32 | INFO | train_inner | epoch 001:   6114 / 1830643 loss=3.462, ppl=11.02, wps=24194.9, ups=0.74, wpb=32768, bsz=32, num_updates=6100, lr=0.0001878, gnorm=0.203, loss_scale=4, train_wall=135, gb_free=15.4, wall=8851
2023-10-19 07:31:48 | INFO | train_inner | epoch 001:   6214 / 1830643 loss=3.558, ppl=11.78, wps=24187.1, ups=0.74, wpb=32768, bsz=32, num_updates=6200, lr=0.0001876, gnorm=0.197, loss_scale=4, train_wall=135, gb_free=15.4, wall=8987
2023-10-19 07:34:03 | INFO | train_inner | epoch 001:   6314 / 1830643 loss=3.483, ppl=11.18, wps=24176.6, ups=0.74, wpb=32768, bsz=32, num_updates=6300, lr=0.0001874, gnorm=0.222, loss_scale=4, train_wall=135, gb_free=15.4, wall=9122
2023-10-19 07:36:18 | INFO | train_inner | epoch 001:   6414 / 1830643 loss=3.777, ppl=13.71, wps=24230.9, ups=0.74, wpb=32768, bsz=32, num_updates=6400, lr=0.0001872, gnorm=0.211, loss_scale=4, train_wall=135, gb_free=15.4, wall=9258
2023-10-19 07:38:34 | INFO | train_inner | epoch 001:   6514 / 1830643 loss=3.638, ppl=12.45, wps=24154.6, ups=0.74, wpb=32768, bsz=32, num_updates=6500, lr=0.000187, gnorm=0.197, loss_scale=8, train_wall=135, gb_free=15.4, wall=9393
2023-10-19 07:40:50 | INFO | train_inner | epoch 001:   6614 / 1830643 loss=3.705, ppl=13.04, wps=24178, ups=0.74, wpb=32768, bsz=32, num_updates=6600, lr=0.0001868, gnorm=0.191, loss_scale=8, train_wall=135, gb_free=15.4, wall=9529
2023-10-19 07:43:06 | INFO | train_inner | epoch 001:   6714 / 1830643 loss=3.378, ppl=10.39, wps=24100.9, ups=0.74, wpb=32768, bsz=32, num_updates=6700, lr=0.0001866, gnorm=0.185, loss_scale=8, train_wall=136, gb_free=15.4, wall=9665
2023-10-19 07:44:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 07:45:22 | INFO | train_inner | epoch 001:   6815 / 1830643 loss=3.576, ppl=11.93, wps=23945.3, ups=0.73, wpb=32768, bsz=32, num_updates=6800, lr=0.0001864, gnorm=0.195, loss_scale=4, train_wall=136, gb_free=15.4, wall=9802
2023-10-19 07:47:38 | INFO | train_inner | epoch 001:   6915 / 1830643 loss=3.707, ppl=13.06, wps=24149.3, ups=0.74, wpb=32768, bsz=32, num_updates=6900, lr=0.0001862, gnorm=0.199, loss_scale=4, train_wall=135, gb_free=15.4, wall=9937
2023-10-19 07:49:54 | INFO | train_inner | epoch 001:   7015 / 1830643 loss=3.609, ppl=12.2, wps=24141.7, ups=0.74, wpb=32768, bsz=32, num_updates=7000, lr=0.000186, gnorm=0.189, loss_scale=4, train_wall=135, gb_free=15.4, wall=10073
2023-10-19 07:52:09 | INFO | train_inner | epoch 001:   7115 / 1830643 loss=3.483, ppl=11.18, wps=24181.6, ups=0.74, wpb=32768, bsz=32, num_updates=7100, lr=0.0001858, gnorm=0.191, loss_scale=4, train_wall=135, gb_free=15.4, wall=10209
2023-10-19 07:54:25 | INFO | train_inner | epoch 001:   7215 / 1830643 loss=3.521, ppl=11.48, wps=24228, ups=0.74, wpb=32768, bsz=32, num_updates=7200, lr=0.0001856, gnorm=0.197, loss_scale=4, train_wall=135, gb_free=15.4, wall=10344
2023-10-19 07:56:40 | INFO | train_inner | epoch 001:   7315 / 1830643 loss=3.617, ppl=12.27, wps=24225.4, ups=0.74, wpb=32768, bsz=32, num_updates=7300, lr=0.0001854, gnorm=0.183, loss_scale=8, train_wall=135, gb_free=15.4, wall=10479
2023-10-19 07:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 07:58:57 | INFO | train_inner | epoch 001:   7416 / 1830643 loss=3.491, ppl=11.25, wps=23908.5, ups=0.73, wpb=32768, bsz=32, num_updates=7400, lr=0.0001852, gnorm=0.223, loss_scale=4, train_wall=137, gb_free=15.4, wall=10616
2023-10-19 08:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 08:01:14 | INFO | train_inner | epoch 001:   7517 / 1830643 loss=3.289, ppl=9.78, wps=23950.8, ups=0.73, wpb=32768, bsz=32, num_updates=7500, lr=0.000185, gnorm=0.198, loss_scale=2, train_wall=136, gb_free=15.4, wall=10753
2023-10-19 08:03:29 | INFO | train_inner | epoch 001:   7617 / 1830643 loss=3.472, ppl=11.09, wps=24208.9, ups=0.74, wpb=32768, bsz=32, num_updates=7600, lr=0.0001848, gnorm=0.233, loss_scale=2, train_wall=135, gb_free=15.4, wall=10888
2023-10-19 08:05:44 | INFO | train_inner | epoch 001:   7717 / 1830643 loss=3.486, ppl=11.2, wps=24246.7, ups=0.74, wpb=32768, bsz=32, num_updates=7700, lr=0.0001846, gnorm=0.187, loss_scale=2, train_wall=135, gb_free=15.4, wall=11023
2023-10-19 08:07:59 | INFO | train_inner | epoch 001:   7817 / 1830643 loss=3.48, ppl=11.16, wps=24261.6, ups=0.74, wpb=32768, bsz=32, num_updates=7800, lr=0.0001844, gnorm=0.18, loss_scale=2, train_wall=135, gb_free=15.4, wall=11159
2023-10-19 08:10:15 | INFO | train_inner | epoch 001:   7917 / 1830643 loss=3.585, ppl=12, wps=24134.2, ups=0.74, wpb=32768, bsz=32, num_updates=7900, lr=0.0001842, gnorm=0.178, loss_scale=2, train_wall=135, gb_free=15.4, wall=11294
2023-10-19 08:12:30 | INFO | train_inner | epoch 001:   8017 / 1830643 loss=3.629, ppl=12.38, wps=24256.2, ups=0.74, wpb=32768, bsz=32, num_updates=8000, lr=0.000184, gnorm=0.191, loss_scale=4, train_wall=135, gb_free=15.4, wall=11429
2023-10-19 08:14:45 | INFO | train_inner | epoch 001:   8117 / 1830643 loss=3.654, ppl=12.59, wps=24245.5, ups=0.74, wpb=32768, bsz=32, num_updates=8100, lr=0.0001838, gnorm=0.185, loss_scale=4, train_wall=135, gb_free=15.4, wall=11565
2023-10-19 08:17:01 | INFO | train_inner | epoch 001:   8217 / 1830643 loss=3.435, ppl=10.81, wps=24193, ups=0.74, wpb=32768, bsz=32, num_updates=8200, lr=0.0001836, gnorm=0.189, loss_scale=4, train_wall=135, gb_free=15.4, wall=11700
2023-10-19 08:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 08:18:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-10-19 08:19:19 | INFO | train_inner | epoch 001:   8319 / 1830643 loss=3.579, ppl=11.95, wps=23738.1, ups=0.72, wpb=32768, bsz=32, num_updates=8300, lr=0.0001834, gnorm=0.179, loss_scale=1, train_wall=138, gb_free=15.4, wall=11838
2023-10-19 08:21:35 | INFO | train_inner | epoch 001:   8419 / 1830643 loss=3.571, ppl=11.89, wps=24110, ups=0.74, wpb=32768, bsz=32, num_updates=8400, lr=0.0001832, gnorm=0.199, loss_scale=1, train_wall=136, gb_free=15.4, wall=11974
2023-10-19 08:23:51 | INFO | train_inner | epoch 001:   8519 / 1830643 loss=3.526, ppl=11.52, wps=24102.1, ups=0.74, wpb=32768, bsz=32, num_updates=8500, lr=0.000183, gnorm=0.185, loss_scale=1, train_wall=136, gb_free=15.4, wall=12110
2023-10-19 08:26:05 | INFO | train_inner | epoch 001:   8619 / 1830643 loss=3.583, ppl=11.98, wps=24323.5, ups=0.74, wpb=32768, bsz=32, num_updates=8600, lr=0.0001828, gnorm=0.201, loss_scale=1, train_wall=134, gb_free=15.4, wall=12245
2023-10-19 08:28:20 | INFO | train_inner | epoch 001:   8719 / 1830643 loss=3.509, ppl=11.38, wps=24264.9, ups=0.74, wpb=32768, bsz=32, num_updates=8700, lr=0.0001826, gnorm=0.206, loss_scale=1, train_wall=135, gb_free=15.4, wall=12380
2023-10-19 08:30:36 | INFO | train_inner | epoch 001:   8819 / 1830643 loss=3.611, ppl=12.22, wps=24184.4, ups=0.74, wpb=32768, bsz=32, num_updates=8800, lr=0.0001824, gnorm=0.178, loss_scale=2, train_wall=135, gb_free=15.4, wall=12515
2023-10-19 08:32:51 | INFO | train_inner | epoch 001:   8919 / 1830643 loss=3.409, ppl=10.62, wps=24230.3, ups=0.74, wpb=32768, bsz=32, num_updates=8900, lr=0.0001822, gnorm=0.185, loss_scale=2, train_wall=135, gb_free=15.4, wall=12650
2023-10-19 08:35:06 | INFO | train_inner | epoch 001:   9019 / 1830643 loss=3.613, ppl=12.24, wps=24248, ups=0.74, wpb=32768, bsz=32, num_updates=9000, lr=0.000182, gnorm=0.185, loss_scale=2, train_wall=135, gb_free=15.4, wall=12786
2023-10-19 08:37:22 | INFO | train_inner | epoch 001:   9119 / 1830643 loss=3.523, ppl=11.5, wps=24204.1, ups=0.74, wpb=32768, bsz=32, num_updates=9100, lr=0.0001818, gnorm=0.186, loss_scale=2, train_wall=135, gb_free=15.4, wall=12921
2023-10-19 08:39:37 | INFO | train_inner | epoch 001:   9219 / 1830643 loss=3.604, ppl=12.16, wps=24246.9, ups=0.74, wpb=32768, bsz=32, num_updates=9200, lr=0.0001816, gnorm=0.196, loss_scale=2, train_wall=135, gb_free=15.4, wall=13056
2023-10-19 08:41:53 | INFO | train_inner | epoch 001:   9319 / 1830643 loss=3.438, ppl=10.84, wps=24116.8, ups=0.74, wpb=32768, bsz=32, num_updates=9300, lr=0.0001814, gnorm=0.164, loss_scale=4, train_wall=136, gb_free=15.4, wall=13192
2023-10-19 08:44:08 | INFO | train_inner | epoch 001:   9419 / 1830643 loss=3.839, ppl=14.31, wps=24246.9, ups=0.74, wpb=32768, bsz=32, num_updates=9400, lr=0.0001812, gnorm=0.188, loss_scale=4, train_wall=135, gb_free=15.4, wall=13327
2023-10-19 08:46:23 | INFO | train_inner | epoch 001:   9519 / 1830643 loss=3.711, ppl=13.09, wps=24219.9, ups=0.74, wpb=32768, bsz=32, num_updates=9500, lr=0.000181, gnorm=0.19, loss_scale=4, train_wall=135, gb_free=15.4, wall=13462
2023-10-19 08:48:39 | INFO | train_inner | epoch 001:   9619 / 1830643 loss=3.843, ppl=14.35, wps=24127.5, ups=0.74, wpb=32768, bsz=32, num_updates=9600, lr=0.0001808, gnorm=0.187, loss_scale=4, train_wall=135, gb_free=15.4, wall=13598
2023-10-19 08:50:54 | INFO | train_inner | epoch 001:   9719 / 1830643 loss=3.902, ppl=14.95, wps=24189, ups=0.74, wpb=32768, bsz=32, num_updates=9700, lr=0.0001806, gnorm=0.182, loss_scale=4, train_wall=135, gb_free=15.4, wall=13734
2023-10-19 08:53:10 | INFO | train_inner | epoch 001:   9819 / 1830643 loss=3.571, ppl=11.88, wps=24230.9, ups=0.74, wpb=32768, bsz=32, num_updates=9800, lr=0.0001804, gnorm=0.179, loss_scale=4, train_wall=135, gb_free=15.4, wall=13869
2023-10-19 08:55:25 | INFO | train_inner | epoch 001:   9919 / 1830643 loss=3.556, ppl=11.76, wps=24161.1, ups=0.74, wpb=32768, bsz=32, num_updates=9900, lr=0.0001802, gnorm=0.195, loss_scale=8, train_wall=135, gb_free=15.4, wall=14004
2023-10-19 08:57:41 | INFO | train_inner | epoch 001:  10019 / 1830643 loss=3.569, ppl=11.87, wps=24149.3, ups=0.74, wpb=32768, bsz=32, num_updates=10000, lr=0.00018, gnorm=0.204, loss_scale=8, train_wall=135, gb_free=15.4, wall=14140
2023-10-19 08:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-10-19 08:57:41 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_10000.pt
2023-10-19 08:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_10000.pt
2023-10-19 08:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score None) (writing took 7.206942133139819 seconds)
2023-10-19 09:00:04 | INFO | train_inner | epoch 001:  10119 / 1830643 loss=3.633, ppl=12.4, wps=22936.9, ups=0.7, wpb=32768, bsz=32, num_updates=10100, lr=0.0001798, gnorm=0.189, loss_scale=8, train_wall=135, gb_free=15.4, wall=14283
2023-10-19 09:02:19 | INFO | train_inner | epoch 001:  10219 / 1830643 loss=3.443, ppl=10.87, wps=24253, ups=0.74, wpb=32768, bsz=32, num_updates=10200, lr=0.0001796, gnorm=0.179, loss_scale=8, train_wall=135, gb_free=15.4, wall=14418
2023-10-19 09:04:34 | INFO | train_inner | epoch 001:  10319 / 1830643 loss=3.594, ppl=12.07, wps=24224.7, ups=0.74, wpb=32768, bsz=32, num_updates=10300, lr=0.0001794, gnorm=0.175, loss_scale=8, train_wall=135, gb_free=15.4, wall=14553
2023-10-19 09:06:49 | INFO | train_inner | epoch 001:  10419 / 1830643 loss=3.512, ppl=11.41, wps=24222.6, ups=0.74, wpb=32768, bsz=32, num_updates=10400, lr=0.0001792, gnorm=0.178, loss_scale=16, train_wall=135, gb_free=15.4, wall=14689
2023-10-19 09:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 09:09:06 | INFO | train_inner | epoch 001:  10520 / 1830643 loss=3.848, ppl=14.4, wps=23978.2, ups=0.73, wpb=32768, bsz=32, num_updates=10500, lr=0.000179, gnorm=0.182, loss_scale=8, train_wall=136, gb_free=15.4, wall=14825
2023-10-19 09:11:21 | INFO | train_inner | epoch 001:  10620 / 1830643 loss=3.526, ppl=11.52, wps=24284, ups=0.74, wpb=32768, bsz=32, num_updates=10600, lr=0.0001788, gnorm=0.176, loss_scale=8, train_wall=135, gb_free=15.4, wall=14960
2023-10-19 09:13:36 | INFO | train_inner | epoch 001:  10720 / 1830643 loss=3.393, ppl=10.51, wps=24272.8, ups=0.74, wpb=32768, bsz=32, num_updates=10700, lr=0.0001786, gnorm=0.185, loss_scale=8, train_wall=135, gb_free=15.4, wall=15095
2023-10-19 09:15:51 | INFO | train_inner | epoch 001:  10820 / 1830643 loss=3.499, ppl=11.31, wps=24317.5, ups=0.74, wpb=32768, bsz=32, num_updates=10800, lr=0.0001784, gnorm=0.181, loss_scale=8, train_wall=134, gb_free=15.4, wall=15230
2023-10-19 09:18:06 | INFO | train_inner | epoch 001:  10920 / 1830643 loss=3.546, ppl=11.68, wps=24278.3, ups=0.74, wpb=32768, bsz=32, num_updates=10900, lr=0.0001782, gnorm=0.177, loss_scale=8, train_wall=135, gb_free=15.4, wall=15365
2023-10-19 09:18:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 09:20:23 | INFO | train_inner | epoch 001:  11021 / 1830643 loss=3.367, ppl=10.32, wps=23931.1, ups=0.73, wpb=32768, bsz=32, num_updates=11000, lr=0.000178, gnorm=0.19, loss_scale=8, train_wall=137, gb_free=15.4, wall=15502
2023-10-19 09:22:38 | INFO | train_inner | epoch 001:  11121 / 1830643 loss=3.547, ppl=11.69, wps=24215.7, ups=0.74, wpb=32768, bsz=32, num_updates=11100, lr=0.0001778, gnorm=0.193, loss_scale=8, train_wall=135, gb_free=15.4, wall=15637
2023-10-19 09:24:53 | INFO | train_inner | epoch 001:  11221 / 1830643 loss=3.495, ppl=11.27, wps=24219, ups=0.74, wpb=32768, bsz=32, num_updates=11200, lr=0.0001776, gnorm=0.193, loss_scale=8, train_wall=135, gb_free=15.4, wall=15773
2023-10-19 09:27:08 | INFO | train_inner | epoch 001:  11321 / 1830643 loss=3.477, ppl=11.14, wps=24323.4, ups=0.74, wpb=32768, bsz=32, num_updates=11300, lr=0.0001774, gnorm=0.169, loss_scale=8, train_wall=134, gb_free=15.4, wall=15907
2023-10-19 09:29:24 | INFO | train_inner | epoch 001:  11421 / 1830643 loss=3.557, ppl=11.77, wps=24174.2, ups=0.74, wpb=32768, bsz=32, num_updates=11400, lr=0.0001772, gnorm=0.188, loss_scale=8, train_wall=135, gb_free=15.4, wall=16043
2023-10-19 09:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 09:31:40 | INFO | train_inner | epoch 001:  11522 / 1830643 loss=3.581, ppl=11.97, wps=24038.3, ups=0.73, wpb=32768, bsz=32, num_updates=11500, lr=0.000177, gnorm=0.206, loss_scale=8, train_wall=136, gb_free=15.4, wall=16179
2023-10-19 09:33:55 | INFO | train_inner | epoch 001:  11622 / 1830643 loss=3.604, ppl=12.16, wps=24203.8, ups=0.74, wpb=32768, bsz=32, num_updates=11600, lr=0.0001768, gnorm=0.177, loss_scale=8, train_wall=135, gb_free=15.4, wall=16315
2023-10-19 09:36:10 | INFO | train_inner | epoch 001:  11722 / 1830643 loss=3.493, ppl=11.26, wps=24257, ups=0.74, wpb=32768, bsz=32, num_updates=11700, lr=0.0001766, gnorm=0.166, loss_scale=8, train_wall=135, gb_free=15.4, wall=16450
2023-10-19 09:38:26 | INFO | train_inner | epoch 001:  11822 / 1830643 loss=3.66, ppl=12.64, wps=24204.1, ups=0.74, wpb=32768, bsz=32, num_updates=11800, lr=0.0001764, gnorm=0.186, loss_scale=8, train_wall=135, gb_free=15.4, wall=16585
2023-10-19 09:40:41 | INFO | train_inner | epoch 001:  11922 / 1830643 loss=3.483, ppl=11.18, wps=24227.1, ups=0.74, wpb=32768, bsz=32, num_updates=11900, lr=0.0001762, gnorm=0.184, loss_scale=8, train_wall=135, gb_free=15.4, wall=16720
2023-10-19 09:42:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 09:42:57 | INFO | train_inner | epoch 001:  12023 / 1830643 loss=3.624, ppl=12.33, wps=24032, ups=0.73, wpb=32768, bsz=32, num_updates=12000, lr=0.000176, gnorm=0.179, loss_scale=8, train_wall=136, gb_free=15.4, wall=16857
2023-10-19 09:45:13 | INFO | train_inner | epoch 001:  12123 / 1830643 loss=3.38, ppl=10.41, wps=24148.2, ups=0.74, wpb=32768, bsz=32, num_updates=12100, lr=0.0001758, gnorm=0.182, loss_scale=8, train_wall=135, gb_free=15.4, wall=16992
2023-10-19 09:47:28 | INFO | train_inner | epoch 001:  12223 / 1830643 loss=3.458, ppl=10.99, wps=24228.7, ups=0.74, wpb=32768, bsz=32, num_updates=12200, lr=0.0001756, gnorm=0.17, loss_scale=8, train_wall=135, gb_free=15.4, wall=17128
2023-10-19 09:49:44 | INFO | train_inner | epoch 001:  12323 / 1830643 loss=3.714, ppl=13.12, wps=24205, ups=0.74, wpb=32768, bsz=32, num_updates=12300, lr=0.0001754, gnorm=0.167, loss_scale=8, train_wall=135, gb_free=15.4, wall=17263
2023-10-19 09:51:59 | INFO | train_inner | epoch 001:  12423 / 1830643 loss=3.51, ppl=11.39, wps=24236, ups=0.74, wpb=32768, bsz=32, num_updates=12400, lr=0.0001752, gnorm=0.189, loss_scale=8, train_wall=135, gb_free=15.4, wall=17398
2023-10-19 09:54:15 | INFO | train_inner | epoch 001:  12523 / 1830643 loss=3.599, ppl=12.12, wps=24134.9, ups=0.74, wpb=32768, bsz=32, num_updates=12500, lr=0.000175, gnorm=0.188, loss_scale=16, train_wall=135, gb_free=15.4, wall=17534
2023-10-19 09:56:30 | INFO | train_inner | epoch 001:  12623 / 1830643 loss=3.589, ppl=12.03, wps=24221.4, ups=0.74, wpb=32768, bsz=32, num_updates=12600, lr=0.0001748, gnorm=0.176, loss_scale=16, train_wall=135, gb_free=15.4, wall=17669
2023-10-19 09:57:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 09:58:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 09:58:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 09:58:49 | INFO | train_inner | epoch 001:  12726 / 1830643 loss=3.375, ppl=10.38, wps=23515.9, ups=0.72, wpb=32768, bsz=32, num_updates=12700, lr=0.0001746, gnorm=0.19, loss_scale=2, train_wall=139, gb_free=15.4, wall=17809
2023-10-19 10:01:05 | INFO | train_inner | epoch 001:  12826 / 1830643 loss=3.617, ppl=12.27, wps=24117.2, ups=0.74, wpb=32768, bsz=32, num_updates=12800, lr=0.0001744, gnorm=0.176, loss_scale=2, train_wall=136, gb_free=15.4, wall=17944
2023-10-19 10:03:21 | INFO | train_inner | epoch 001:  12926 / 1830643 loss=3.532, ppl=11.56, wps=24164.7, ups=0.74, wpb=32768, bsz=32, num_updates=12900, lr=0.0001742, gnorm=0.19, loss_scale=2, train_wall=135, gb_free=15.4, wall=18080
2023-10-19 10:05:37 | INFO | train_inner | epoch 001:  13026 / 1830643 loss=3.461, ppl=11.01, wps=24121.8, ups=0.74, wpb=32768, bsz=32, num_updates=13000, lr=0.000174, gnorm=0.204, loss_scale=2, train_wall=135, gb_free=15.4, wall=18216
2023-10-19 10:07:52 | INFO | train_inner | epoch 001:  13126 / 1830643 loss=3.623, ppl=12.32, wps=24257.5, ups=0.74, wpb=32768, bsz=32, num_updates=13100, lr=0.0001738, gnorm=0.18, loss_scale=2, train_wall=135, gb_free=15.4, wall=18351
2023-10-19 10:10:07 | INFO | train_inner | epoch 001:  13226 / 1830643 loss=3.686, ppl=12.87, wps=24257.8, ups=0.74, wpb=32768, bsz=32, num_updates=13200, lr=0.0001736, gnorm=0.182, loss_scale=4, train_wall=135, gb_free=15.4, wall=18486
2023-10-19 10:12:22 | INFO | train_inner | epoch 001:  13326 / 1830643 loss=3.154, ppl=8.9, wps=24254.2, ups=0.74, wpb=32768, bsz=32, num_updates=13300, lr=0.0001734, gnorm=0.165, loss_scale=4, train_wall=135, gb_free=15.4, wall=18621
2023-10-19 10:14:37 | INFO | train_inner | epoch 001:  13426 / 1830643 loss=3.218, ppl=9.31, wps=24210.2, ups=0.74, wpb=32768, bsz=32, num_updates=13400, lr=0.0001732, gnorm=0.174, loss_scale=4, train_wall=135, gb_free=15.4, wall=18756
2023-10-19 10:16:53 | INFO | train_inner | epoch 001:  13526 / 1830643 loss=3.08, ppl=8.46, wps=24117.3, ups=0.74, wpb=32768, bsz=32, num_updates=13500, lr=0.000173, gnorm=0.169, loss_scale=4, train_wall=136, gb_free=15.4, wall=18892
2023-10-19 10:19:09 | INFO | train_inner | epoch 001:  13626 / 1830643 loss=3.467, ppl=11.05, wps=24131.9, ups=0.74, wpb=32768, bsz=32, num_updates=13600, lr=0.0001728, gnorm=0.178, loss_scale=4, train_wall=135, gb_free=15.4, wall=19028
2023-10-19 10:21:24 | INFO | train_inner | epoch 001:  13726 / 1830643 loss=3.465, ppl=11.05, wps=24179.4, ups=0.74, wpb=32768, bsz=32, num_updates=13700, lr=0.0001726, gnorm=0.189, loss_scale=8, train_wall=135, gb_free=15.4, wall=19164
2023-10-19 10:23:39 | INFO | train_inner | epoch 001:  13826 / 1830643 loss=3.634, ppl=12.41, wps=24268.7, ups=0.74, wpb=32768, bsz=32, num_updates=13800, lr=0.0001724, gnorm=0.169, loss_scale=8, train_wall=135, gb_free=15.4, wall=19299
2023-10-19 10:23:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 10:23:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 10:25:58 | INFO | train_inner | epoch 001:  13928 / 1830643 loss=3.563, ppl=11.82, wps=23668, ups=0.72, wpb=32768, bsz=32, num_updates=13900, lr=0.0001722, gnorm=0.171, loss_scale=2, train_wall=138, gb_free=15.4, wall=19437
2023-10-19 10:28:13 | INFO | train_inner | epoch 001:  14028 / 1830643 loss=3.626, ppl=12.35, wps=24224.9, ups=0.74, wpb=32768, bsz=32, num_updates=14000, lr=0.000172, gnorm=0.193, loss_scale=2, train_wall=135, gb_free=15.4, wall=19572
2023-10-19 10:30:29 | INFO | train_inner | epoch 001:  14128 / 1830643 loss=3.547, ppl=11.69, wps=24190.5, ups=0.74, wpb=32768, bsz=32, num_updates=14100, lr=0.0001718, gnorm=0.181, loss_scale=2, train_wall=135, gb_free=15.4, wall=19708
2023-10-19 10:32:44 | INFO | train_inner | epoch 001:  14228 / 1830643 loss=3.609, ppl=12.2, wps=24184.9, ups=0.74, wpb=32768, bsz=32, num_updates=14200, lr=0.0001716, gnorm=0.174, loss_scale=2, train_wall=135, gb_free=15.4, wall=19843
2023-10-19 10:35:00 | INFO | train_inner | epoch 001:  14328 / 1830643 loss=3.589, ppl=12.03, wps=24164.7, ups=0.74, wpb=32768, bsz=32, num_updates=14300, lr=0.0001714, gnorm=0.169, loss_scale=2, train_wall=135, gb_free=15.4, wall=19979
2023-10-19 10:37:15 | INFO | train_inner | epoch 001:  14428 / 1830643 loss=3.688, ppl=12.89, wps=24123.9, ups=0.74, wpb=32768, bsz=32, num_updates=14400, lr=0.0001712, gnorm=0.194, loss_scale=4, train_wall=135, gb_free=15.4, wall=20115
2023-10-19 10:39:31 | INFO | train_inner | epoch 001:  14528 / 1830643 loss=3.497, ppl=11.29, wps=24217.9, ups=0.74, wpb=32768, bsz=32, num_updates=14500, lr=0.000171, gnorm=0.181, loss_scale=4, train_wall=135, gb_free=15.4, wall=20250
2023-10-19 10:41:46 | INFO | train_inner | epoch 001:  14628 / 1830643 loss=3.64, ppl=12.46, wps=24233, ups=0.74, wpb=32768, bsz=32, num_updates=14600, lr=0.0001708, gnorm=0.199, loss_scale=4, train_wall=135, gb_free=15.4, wall=20385
2023-10-19 10:44:02 | INFO | train_inner | epoch 001:  14728 / 1830643 loss=3.674, ppl=12.77, wps=24181.7, ups=0.74, wpb=32768, bsz=32, num_updates=14700, lr=0.0001706, gnorm=0.167, loss_scale=4, train_wall=135, gb_free=15.4, wall=20521
2023-10-19 10:46:17 | INFO | train_inner | epoch 001:  14828 / 1830643 loss=3.64, ppl=12.47, wps=24156.2, ups=0.74, wpb=32768, bsz=32, num_updates=14800, lr=0.0001704, gnorm=0.177, loss_scale=4, train_wall=135, gb_free=15.4, wall=20656
2023-10-19 10:48:32 | INFO | train_inner | epoch 001:  14928 / 1830643 loss=3.523, ppl=11.5, wps=24240.4, ups=0.74, wpb=32768, bsz=32, num_updates=14900, lr=0.0001702, gnorm=0.163, loss_scale=8, train_wall=135, gb_free=15.4, wall=20792
2023-10-19 10:50:48 | INFO | train_inner | epoch 001:  15028 / 1830643 loss=3.622, ppl=12.31, wps=24187.4, ups=0.74, wpb=32768, bsz=32, num_updates=15000, lr=0.00017, gnorm=0.173, loss_scale=8, train_wall=135, gb_free=15.4, wall=20927
2023-10-19 10:53:03 | INFO | train_inner | epoch 001:  15128 / 1830643 loss=3.744, ppl=13.4, wps=24212.6, ups=0.74, wpb=32768, bsz=32, num_updates=15100, lr=0.0001698, gnorm=0.177, loss_scale=8, train_wall=135, gb_free=15.4, wall=21062
2023-10-19 10:54:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 10:54:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 10:55:22 | INFO | train_inner | epoch 001:  15230 / 1830643 loss=3.708, ppl=13.06, wps=23673.6, ups=0.72, wpb=32768, bsz=32, num_updates=15200, lr=0.0001696, gnorm=0.194, loss_scale=2, train_wall=138, gb_free=15.4, wall=21201
2023-10-19 10:57:37 | INFO | train_inner | epoch 001:  15330 / 1830643 loss=4.023, ppl=16.26, wps=24164.1, ups=0.74, wpb=32768, bsz=32, num_updates=15300, lr=0.0001694, gnorm=0.176, loss_scale=2, train_wall=135, gb_free=15.4, wall=21336
2023-10-19 10:59:53 | INFO | train_inner | epoch 001:  15430 / 1830643 loss=3.573, ppl=11.9, wps=24170.7, ups=0.74, wpb=32768, bsz=32, num_updates=15400, lr=0.0001692, gnorm=0.159, loss_scale=2, train_wall=135, gb_free=15.4, wall=21472
2023-10-19 11:02:08 | INFO | train_inner | epoch 001:  15530 / 1830643 loss=3.668, ppl=12.71, wps=24268.2, ups=0.74, wpb=32768, bsz=32, num_updates=15500, lr=0.000169, gnorm=0.167, loss_scale=2, train_wall=135, gb_free=15.4, wall=21607
2023-10-19 11:04:24 | INFO | train_inner | epoch 001:  15630 / 1830643 loss=3.725, ppl=13.22, wps=24129.8, ups=0.74, wpb=32768, bsz=32, num_updates=15600, lr=0.0001688, gnorm=0.177, loss_scale=2, train_wall=135, gb_free=15.4, wall=21743
2023-10-19 11:06:39 | INFO | train_inner | epoch 001:  15730 / 1830643 loss=3.547, ppl=11.69, wps=24229.6, ups=0.74, wpb=32768, bsz=32, num_updates=15700, lr=0.0001686, gnorm=0.176, loss_scale=4, train_wall=135, gb_free=15.4, wall=21878
2023-10-19 11:08:54 | INFO | train_inner | epoch 001:  15830 / 1830643 loss=3.715, ppl=13.13, wps=24208, ups=0.74, wpb=32768, bsz=32, num_updates=15800, lr=0.0001684, gnorm=0.18, loss_scale=4, train_wall=135, gb_free=15.4, wall=22013
2023-10-19 11:11:10 | INFO | train_inner | epoch 001:  15930 / 1830643 loss=3.461, ppl=11.01, wps=24193.7, ups=0.74, wpb=32768, bsz=32, num_updates=15900, lr=0.0001682, gnorm=0.158, loss_scale=4, train_wall=135, gb_free=15.4, wall=22149
2023-10-19 11:13:25 | INFO | train_inner | epoch 001:  16030 / 1830643 loss=3.621, ppl=12.3, wps=24222, ups=0.74, wpb=32768, bsz=32, num_updates=16000, lr=0.000168, gnorm=0.192, loss_scale=4, train_wall=135, gb_free=15.4, wall=22284
2023-10-19 11:15:41 | INFO | train_inner | epoch 001:  16130 / 1830643 loss=3.703, ppl=13.02, wps=24153.9, ups=0.74, wpb=32768, bsz=32, num_updates=16100, lr=0.0001678, gnorm=0.173, loss_scale=4, train_wall=135, gb_free=15.4, wall=22420
2023-10-19 11:17:56 | INFO | train_inner | epoch 001:  16230 / 1830643 loss=3.655, ppl=12.6, wps=24261.6, ups=0.74, wpb=32768, bsz=32, num_updates=16200, lr=0.0001676, gnorm=0.177, loss_scale=4, train_wall=135, gb_free=15.4, wall=22555
2023-10-19 11:20:11 | INFO | train_inner | epoch 001:  16330 / 1830643 loss=3.562, ppl=11.81, wps=24254.8, ups=0.74, wpb=32768, bsz=32, num_updates=16300, lr=0.0001674, gnorm=0.157, loss_scale=8, train_wall=135, gb_free=15.4, wall=22690
2023-10-19 11:22:26 | INFO | train_inner | epoch 001:  16430 / 1830643 loss=3.685, ppl=12.86, wps=24239.8, ups=0.74, wpb=32768, bsz=32, num_updates=16400, lr=0.0001672, gnorm=0.173, loss_scale=8, train_wall=135, gb_free=15.4, wall=22825
2023-10-19 11:24:41 | INFO | train_inner | epoch 001:  16530 / 1830643 loss=3.595, ppl=12.08, wps=24249.6, ups=0.74, wpb=32768, bsz=32, num_updates=16500, lr=0.000167, gnorm=0.162, loss_scale=8, train_wall=135, gb_free=15.4, wall=22960
2023-10-19 11:26:56 | INFO | train_inner | epoch 001:  16630 / 1830643 loss=3.599, ppl=12.12, wps=24203.1, ups=0.74, wpb=32768, bsz=32, num_updates=16600, lr=0.0001668, gnorm=0.169, loss_scale=8, train_wall=135, gb_free=15.4, wall=23096
2023-10-19 11:29:12 | INFO | train_inner | epoch 001:  16730 / 1830643 loss=3.65, ppl=12.55, wps=24219, ups=0.74, wpb=32768, bsz=32, num_updates=16700, lr=0.0001666, gnorm=0.163, loss_scale=8, train_wall=135, gb_free=15.4, wall=23231
2023-10-19 11:31:27 | INFO | train_inner | epoch 001:  16830 / 1830643 loss=3.582, ppl=11.97, wps=24280.2, ups=0.74, wpb=32768, bsz=32, num_updates=16800, lr=0.0001664, gnorm=0.16, loss_scale=16, train_wall=135, gb_free=15.4, wall=23366
2023-10-19 11:33:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 11:33:43 | INFO | train_inner | epoch 001:  16931 / 1830643 loss=3.452, ppl=10.95, wps=24003.5, ups=0.73, wpb=32768, bsz=32, num_updates=16900, lr=0.0001662, gnorm=0.164, loss_scale=8, train_wall=136, gb_free=15.4, wall=23502
2023-10-19 11:35:58 | INFO | train_inner | epoch 001:  17031 / 1830643 loss=3.499, ppl=11.31, wps=24274.8, ups=0.74, wpb=32768, bsz=32, num_updates=17000, lr=0.000166, gnorm=0.158, loss_scale=8, train_wall=135, gb_free=15.4, wall=23637
2023-10-19 11:38:13 | INFO | train_inner | epoch 001:  17131 / 1830643 loss=3.575, ppl=11.92, wps=24292.5, ups=0.74, wpb=32768, bsz=32, num_updates=17100, lr=0.0001658, gnorm=0.189, loss_scale=8, train_wall=135, gb_free=15.4, wall=23772
2023-10-19 11:40:28 | INFO | train_inner | epoch 001:  17231 / 1830643 loss=3.502, ppl=11.33, wps=24217.5, ups=0.74, wpb=32768, bsz=32, num_updates=17200, lr=0.0001656, gnorm=0.167, loss_scale=8, train_wall=135, gb_free=15.4, wall=23908
2023-10-19 11:42:44 | INFO | train_inner | epoch 001:  17331 / 1830643 loss=3.532, ppl=11.56, wps=24225.1, ups=0.74, wpb=32768, bsz=32, num_updates=17300, lr=0.0001654, gnorm=0.18, loss_scale=8, train_wall=135, gb_free=15.4, wall=24043
2023-10-19 11:44:59 | INFO | train_inner | epoch 001:  17431 / 1830643 loss=3.524, ppl=11.5, wps=24177.6, ups=0.74, wpb=32768, bsz=32, num_updates=17400, lr=0.0001652, gnorm=0.186, loss_scale=8, train_wall=135, gb_free=15.4, wall=24178
2023-10-19 11:45:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 11:47:16 | INFO | train_inner | epoch 001:  17532 / 1830643 loss=3.65, ppl=12.56, wps=23995.4, ups=0.73, wpb=32768, bsz=32, num_updates=17500, lr=0.000165, gnorm=0.168, loss_scale=8, train_wall=136, gb_free=15.4, wall=24315
2023-10-19 11:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 11:47:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 11:49:33 | INFO | train_inner | epoch 001:  17634 / 1830643 loss=3.649, ppl=12.55, wps=23805.2, ups=0.73, wpb=32768, bsz=32, num_updates=17600, lr=0.0001648, gnorm=0.203, loss_scale=2, train_wall=137, gb_free=15.4, wall=24453
2023-10-19 11:51:49 | INFO | train_inner | epoch 001:  17734 / 1830643 loss=3.437, ppl=10.83, wps=24183.8, ups=0.74, wpb=32768, bsz=32, num_updates=17700, lr=0.0001646, gnorm=0.168, loss_scale=2, train_wall=135, gb_free=15.4, wall=24588
2023-10-19 11:54:04 | INFO | train_inner | epoch 001:  17834 / 1830643 loss=3.523, ppl=11.49, wps=24254.9, ups=0.74, wpb=32768, bsz=32, num_updates=17800, lr=0.0001644, gnorm=0.159, loss_scale=2, train_wall=135, gb_free=15.4, wall=24723
2023-10-19 11:56:19 | INFO | train_inner | epoch 001:  17934 / 1830643 loss=3.64, ppl=12.47, wps=24228.6, ups=0.74, wpb=32768, bsz=32, num_updates=17900, lr=0.0001642, gnorm=0.187, loss_scale=2, train_wall=135, gb_free=15.4, wall=24858
2023-10-19 11:58:35 | INFO | train_inner | epoch 001:  18034 / 1830643 loss=3.47, ppl=11.08, wps=24221, ups=0.74, wpb=32768, bsz=32, num_updates=18000, lr=0.000164, gnorm=0.17, loss_scale=2, train_wall=135, gb_free=15.4, wall=24994
2023-10-19 12:00:50 | INFO | train_inner | epoch 001:  18134 / 1830643 loss=3.548, ppl=11.7, wps=24244.7, ups=0.74, wpb=32768, bsz=32, num_updates=18100, lr=0.0001638, gnorm=0.168, loss_scale=4, train_wall=135, gb_free=15.4, wall=25129
2023-10-19 12:03:05 | INFO | train_inner | epoch 001:  18234 / 1830643 loss=3.417, ppl=10.68, wps=24166.7, ups=0.74, wpb=32768, bsz=32, num_updates=18200, lr=0.0001636, gnorm=0.176, loss_scale=4, train_wall=135, gb_free=15.4, wall=25265
2023-10-19 12:03:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 12:03:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-10-19 12:05:24 | INFO | train_inner | epoch 001:  18336 / 1830643 loss=3.514, ppl=11.42, wps=23667.2, ups=0.72, wpb=32768, bsz=32, num_updates=18300, lr=0.0001634, gnorm=0.173, loss_scale=1, train_wall=138, gb_free=15.4, wall=25403
2023-10-19 12:07:39 | INFO | train_inner | epoch 001:  18436 / 1830643 loss=3.613, ppl=12.23, wps=24183.2, ups=0.74, wpb=32768, bsz=32, num_updates=18400, lr=0.0001632, gnorm=0.171, loss_scale=1, train_wall=135, gb_free=15.4, wall=25538
2023-10-19 12:09:55 | INFO | train_inner | epoch 001:  18536 / 1830643 loss=3.523, ppl=11.49, wps=24201, ups=0.74, wpb=32768, bsz=32, num_updates=18500, lr=0.000163, gnorm=0.182, loss_scale=1, train_wall=135, gb_free=15.4, wall=25674
2023-10-19 12:12:09 | INFO | train_inner | epoch 001:  18636 / 1830643 loss=3.392, ppl=10.5, wps=24308.2, ups=0.74, wpb=32768, bsz=32, num_updates=18600, lr=0.0001628, gnorm=0.167, loss_scale=1, train_wall=134, gb_free=15.4, wall=25809
2023-10-19 12:14:25 | INFO | train_inner | epoch 001:  18736 / 1830643 loss=3.393, ppl=10.5, wps=24244.9, ups=0.74, wpb=32768, bsz=32, num_updates=18700, lr=0.0001626, gnorm=0.182, loss_scale=1, train_wall=135, gb_free=15.4, wall=25944
2023-10-19 12:16:40 | INFO | train_inner | epoch 001:  18836 / 1830643 loss=3.551, ppl=11.72, wps=24239.6, ups=0.74, wpb=32768, bsz=32, num_updates=18800, lr=0.0001624, gnorm=0.175, loss_scale=2, train_wall=135, gb_free=15.4, wall=26079
2023-10-19 12:18:54 | INFO | train_inner | epoch 001:  18936 / 1830643 loss=3.536, ppl=11.6, wps=24349.3, ups=0.74, wpb=32768, bsz=32, num_updates=18900, lr=0.0001622, gnorm=0.178, loss_scale=2, train_wall=134, gb_free=15.4, wall=26214
2023-10-19 12:21:10 | INFO | train_inner | epoch 001:  19036 / 1830643 loss=3.533, ppl=11.58, wps=24185.6, ups=0.74, wpb=32768, bsz=32, num_updates=19000, lr=0.000162, gnorm=0.168, loss_scale=2, train_wall=135, gb_free=15.4, wall=26349
2023-10-19 12:23:25 | INFO | train_inner | epoch 001:  19136 / 1830643 loss=3.413, ppl=10.65, wps=24314.3, ups=0.74, wpb=32768, bsz=32, num_updates=19100, lr=0.0001618, gnorm=0.184, loss_scale=2, train_wall=134, gb_free=15.4, wall=26484
2023-10-19 12:25:40 | INFO | train_inner | epoch 001:  19236 / 1830643 loss=3.505, ppl=11.35, wps=24238.7, ups=0.74, wpb=32768, bsz=32, num_updates=19200, lr=0.0001616, gnorm=0.167, loss_scale=2, train_wall=135, gb_free=15.4, wall=26619
2023-10-19 12:27:55 | INFO | train_inner | epoch 001:  19336 / 1830643 loss=3.473, ppl=11.11, wps=24200.8, ups=0.74, wpb=32768, bsz=32, num_updates=19300, lr=0.0001614, gnorm=0.174, loss_scale=4, train_wall=135, gb_free=15.4, wall=26754
2023-10-19 12:30:10 | INFO | train_inner | epoch 001:  19436 / 1830643 loss=3.455, ppl=10.97, wps=24276.8, ups=0.74, wpb=32768, bsz=32, num_updates=19400, lr=0.0001612, gnorm=0.177, loss_scale=4, train_wall=135, gb_free=15.4, wall=26889
2023-10-19 12:32:25 | INFO | train_inner | epoch 001:  19536 / 1830643 loss=3.408, ppl=10.62, wps=24244.2, ups=0.74, wpb=32768, bsz=32, num_updates=19500, lr=0.000161, gnorm=0.165, loss_scale=4, train_wall=135, gb_free=15.4, wall=27025
2023-10-19 12:34:40 | INFO | train_inner | epoch 001:  19636 / 1830643 loss=3.437, ppl=10.83, wps=24243.7, ups=0.74, wpb=32768, bsz=32, num_updates=19600, lr=0.0001608, gnorm=0.173, loss_scale=4, train_wall=135, gb_free=15.4, wall=27160
2023-10-19 12:35:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 12:35:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-10-19 12:36:58 | INFO | train_inner | epoch 001:  19738 / 1830643 loss=3.489, ppl=11.22, wps=23780.5, ups=0.73, wpb=32768, bsz=32, num_updates=19700, lr=0.0001606, gnorm=0.229, loss_scale=1, train_wall=137, gb_free=15.4, wall=27298
2023-10-19 12:39:13 | INFO | train_inner | epoch 001:  19838 / 1830643 loss=3.571, ppl=11.88, wps=24278.1, ups=0.74, wpb=32768, bsz=32, num_updates=19800, lr=0.0001604, gnorm=0.165, loss_scale=1, train_wall=135, gb_free=15.4, wall=27433
2023-10-19 12:41:29 | INFO | train_inner | epoch 001:  19938 / 1830643 loss=3.412, ppl=10.64, wps=24130.7, ups=0.74, wpb=32768, bsz=32, num_updates=19900, lr=0.0001602, gnorm=0.169, loss_scale=1, train_wall=135, gb_free=15.4, wall=27568
2023-10-19 12:43:44 | INFO | train_inner | epoch 001:  20038 / 1830643 loss=3.615, ppl=12.26, wps=24236.3, ups=0.74, wpb=32768, bsz=32, num_updates=20000, lr=0.00016, gnorm=0.174, loss_scale=1, train_wall=135, gb_free=15.4, wall=27704
2023-10-19 12:43:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-10-19 12:43:44 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_20000.pt
2023-10-19 12:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_20000.pt
2023-10-19 12:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score None) (writing took 17.091131164925173 seconds)
2023-10-19 12:46:16 | INFO | train_inner | epoch 001:  20138 / 1830643 loss=3.444, ppl=10.88, wps=21544, ups=0.66, wpb=32768, bsz=32, num_updates=20100, lr=0.0001598, gnorm=0.197, loss_scale=1, train_wall=135, gb_free=15.4, wall=27856
2023-10-19 12:48:32 | INFO | train_inner | epoch 001:  20238 / 1830643 loss=3.413, ppl=10.65, wps=24161.6, ups=0.74, wpb=32768, bsz=32, num_updates=20200, lr=0.0001596, gnorm=0.184, loss_scale=2, train_wall=135, gb_free=15.4, wall=27991
2023-10-19 12:50:48 | INFO | train_inner | epoch 001:  20338 / 1830643 loss=3.418, ppl=10.69, wps=24118, ups=0.74, wpb=32768, bsz=32, num_updates=20300, lr=0.0001594, gnorm=0.183, loss_scale=2, train_wall=136, gb_free=15.4, wall=28127
2023-10-19 12:53:03 | INFO | train_inner | epoch 001:  20438 / 1830643 loss=3.612, ppl=12.22, wps=24246.3, ups=0.74, wpb=32768, bsz=32, num_updates=20400, lr=0.0001592, gnorm=0.179, loss_scale=2, train_wall=135, gb_free=15.4, wall=28262
2023-10-19 12:55:19 | INFO | train_inner | epoch 001:  20538 / 1830643 loss=3.507, ppl=11.37, wps=24037.3, ups=0.73, wpb=32768, bsz=32, num_updates=20500, lr=0.000159, gnorm=0.161, loss_scale=2, train_wall=136, gb_free=15.4, wall=28399
2023-10-19 12:57:35 | INFO | train_inner | epoch 001:  20638 / 1830643 loss=3.329, ppl=10.05, wps=24195.8, ups=0.74, wpb=32768, bsz=32, num_updates=20600, lr=0.0001588, gnorm=0.18, loss_scale=2, train_wall=135, gb_free=15.4, wall=28534
2023-10-19 12:59:50 | INFO | train_inner | epoch 001:  20738 / 1830643 loss=3.444, ppl=10.88, wps=24302.2, ups=0.74, wpb=32768, bsz=32, num_updates=20700, lr=0.0001586, gnorm=0.195, loss_scale=4, train_wall=134, gb_free=15.4, wall=28669
2023-10-19 13:02:05 | INFO | train_inner | epoch 001:  20838 / 1830643 loss=3.506, ppl=11.36, wps=24247.9, ups=0.74, wpb=32768, bsz=32, num_updates=20800, lr=0.0001584, gnorm=0.18, loss_scale=4, train_wall=135, gb_free=15.4, wall=28804
2023-10-19 13:04:20 | INFO | train_inner | epoch 001:  20938 / 1830643 loss=3.434, ppl=10.8, wps=24236.3, ups=0.74, wpb=32768, bsz=32, num_updates=20900, lr=0.0001582, gnorm=0.165, loss_scale=4, train_wall=135, gb_free=15.4, wall=28939
2023-10-19 13:06:35 | INFO | train_inner | epoch 001:  21038 / 1830643 loss=3.459, ppl=10.99, wps=24215, ups=0.74, wpb=32768, bsz=32, num_updates=21000, lr=0.000158, gnorm=0.173, loss_scale=4, train_wall=135, gb_free=15.4, wall=29074
2023-10-19 13:08:51 | INFO | train_inner | epoch 001:  21138 / 1830643 loss=3.508, ppl=11.38, wps=24151.5, ups=0.74, wpb=32768, bsz=32, num_updates=21100, lr=0.0001578, gnorm=0.174, loss_scale=4, train_wall=135, gb_free=15.4, wall=29210
2023-10-19 13:11:06 | INFO | train_inner | epoch 001:  21238 / 1830643 loss=3.482, ppl=11.17, wps=24230, ups=0.74, wpb=32768, bsz=32, num_updates=21200, lr=0.0001576, gnorm=0.172, loss_scale=8, train_wall=135, gb_free=15.4, wall=29345
2023-10-19 13:13:21 | INFO | train_inner | epoch 001:  21338 / 1830643 loss=3.558, ppl=11.78, wps=24216.9, ups=0.74, wpb=32768, bsz=32, num_updates=21300, lr=0.0001574, gnorm=0.18, loss_scale=8, train_wall=135, gb_free=15.4, wall=29481
2023-10-19 13:15:37 | INFO | train_inner | epoch 001:  21438 / 1830643 loss=3.538, ppl=11.61, wps=24260.6, ups=0.74, wpb=32768, bsz=32, num_updates=21400, lr=0.0001572, gnorm=0.165, loss_scale=8, train_wall=135, gb_free=15.4, wall=29616
2023-10-19 13:17:52 | INFO | train_inner | epoch 001:  21538 / 1830643 loss=3.393, ppl=10.5, wps=24130.3, ups=0.74, wpb=32768, bsz=32, num_updates=21500, lr=0.000157, gnorm=0.199, loss_scale=8, train_wall=135, gb_free=15.4, wall=29752
2023-10-19 13:20:08 | INFO | train_inner | epoch 001:  21638 / 1830643 loss=3.352, ppl=10.21, wps=24231.6, ups=0.74, wpb=32768, bsz=32, num_updates=21600, lr=0.0001568, gnorm=0.16, loss_scale=8, train_wall=135, gb_free=15.4, wall=29887
2023-10-19 13:22:23 | INFO | train_inner | epoch 001:  21738 / 1830643 loss=3.439, ppl=10.85, wps=24216.5, ups=0.74, wpb=32768, bsz=32, num_updates=21700, lr=0.0001566, gnorm=0.162, loss_scale=16, train_wall=135, gb_free=15.4, wall=30022
2023-10-19 13:24:38 | INFO | train_inner | epoch 001:  21838 / 1830643 loss=3.316, ppl=9.96, wps=24286, ups=0.74, wpb=32768, bsz=32, num_updates=21800, lr=0.0001564, gnorm=0.169, loss_scale=16, train_wall=135, gb_free=15.4, wall=30157
2023-10-19 13:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 13:26:55 | INFO | train_inner | epoch 001:  21939 / 1830643 loss=3.45, ppl=10.93, wps=23968.7, ups=0.73, wpb=32768, bsz=32, num_updates=21900, lr=0.0001562, gnorm=0.164, loss_scale=8, train_wall=136, gb_free=15.4, wall=30294
2023-10-19 13:29:10 | INFO | train_inner | epoch 001:  22039 / 1830643 loss=3.457, ppl=10.98, wps=24188.5, ups=0.74, wpb=32768, bsz=32, num_updates=22000, lr=0.000156, gnorm=0.16, loss_scale=8, train_wall=135, gb_free=15.4, wall=30429
2023-10-19 13:31:25 | INFO | train_inner | epoch 001:  22139 / 1830643 loss=3.282, ppl=9.73, wps=24247, ups=0.74, wpb=32768, bsz=32, num_updates=22100, lr=0.0001558, gnorm=0.16, loss_scale=8, train_wall=135, gb_free=15.4, wall=30564
2023-10-19 13:32:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 13:33:41 | INFO | train_inner | epoch 001:  22240 / 1830643 loss=3.449, ppl=10.92, wps=24031.1, ups=0.73, wpb=32768, bsz=32, num_updates=22200, lr=0.0001556, gnorm=0.165, loss_scale=4, train_wall=136, gb_free=15.4, wall=30701
2023-10-19 13:35:56 | INFO | train_inner | epoch 001:  22340 / 1830643 loss=3.431, ppl=10.79, wps=24314.9, ups=0.74, wpb=32768, bsz=32, num_updates=22300, lr=0.0001554, gnorm=0.166, loss_scale=4, train_wall=134, gb_free=15.4, wall=30835
2023-10-19 13:38:11 | INFO | train_inner | epoch 001:  22440 / 1830643 loss=3.723, ppl=13.2, wps=24338.8, ups=0.74, wpb=32768, bsz=32, num_updates=22400, lr=0.0001552, gnorm=0.166, loss_scale=4, train_wall=134, gb_free=15.4, wall=30970
2023-10-19 13:40:26 | INFO | train_inner | epoch 001:  22540 / 1830643 loss=3.581, ppl=11.97, wps=24271.3, ups=0.74, wpb=32768, bsz=32, num_updates=22500, lr=0.000155, gnorm=0.162, loss_scale=4, train_wall=135, gb_free=15.4, wall=31105
2023-10-19 13:42:41 | INFO | train_inner | epoch 001:  22640 / 1830643 loss=3.637, ppl=12.44, wps=24313.4, ups=0.74, wpb=32768, bsz=32, num_updates=22600, lr=0.0001548, gnorm=0.174, loss_scale=4, train_wall=134, gb_free=15.4, wall=31240
2023-10-19 13:44:55 | INFO | train_inner | epoch 001:  22740 / 1830643 loss=3.412, ppl=10.64, wps=24325.1, ups=0.74, wpb=32768, bsz=32, num_updates=22700, lr=0.0001546, gnorm=0.161, loss_scale=8, train_wall=134, gb_free=15.4, wall=31375
2023-10-19 13:47:10 | INFO | train_inner | epoch 001:  22840 / 1830643 loss=3.671, ppl=12.74, wps=24291.5, ups=0.74, wpb=32768, bsz=32, num_updates=22800, lr=0.0001544, gnorm=0.185, loss_scale=8, train_wall=135, gb_free=15.4, wall=31510
2023-10-19 13:49:25 | INFO | train_inner | epoch 001:  22940 / 1830643 loss=3.511, ppl=11.4, wps=24236.5, ups=0.74, wpb=32768, bsz=32, num_updates=22900, lr=0.0001542, gnorm=0.178, loss_scale=8, train_wall=135, gb_free=15.4, wall=31645
2023-10-19 13:51:40 | INFO | train_inner | epoch 001:  23040 / 1830643 loss=3.467, ppl=11.06, wps=24324.3, ups=0.74, wpb=32768, bsz=32, num_updates=23000, lr=0.000154, gnorm=0.186, loss_scale=8, train_wall=134, gb_free=15.4, wall=31779
2023-10-19 13:53:55 | INFO | train_inner | epoch 001:  23140 / 1830643 loss=3.501, ppl=11.32, wps=24254, ups=0.74, wpb=32768, bsz=32, num_updates=23100, lr=0.0001538, gnorm=0.18, loss_scale=8, train_wall=135, gb_free=15.4, wall=31915
2023-10-19 13:56:11 | INFO | train_inner | epoch 001:  23240 / 1830643 loss=3.335, ppl=10.09, wps=24192.4, ups=0.74, wpb=32768, bsz=32, num_updates=23200, lr=0.0001536, gnorm=0.172, loss_scale=16, train_wall=135, gb_free=15.4, wall=32050
2023-10-19 13:58:26 | INFO | train_inner | epoch 001:  23340 / 1830643 loss=3.557, ppl=11.77, wps=24249.5, ups=0.74, wpb=32768, bsz=32, num_updates=23300, lr=0.0001534, gnorm=0.161, loss_scale=16, train_wall=135, gb_free=15.4, wall=32185
2023-10-19 13:59:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 14:00:42 | INFO | train_inner | epoch 001:  23441 / 1830643 loss=3.57, ppl=11.88, wps=24095.2, ups=0.74, wpb=32768, bsz=32, num_updates=23400, lr=0.0001532, gnorm=0.166, loss_scale=8, train_wall=136, gb_free=15.4, wall=32321
2023-10-19 14:02:59 | INFO | train_inner | epoch 001:  23541 / 1830643 loss=3.425, ppl=10.74, wps=23973.1, ups=0.73, wpb=32768, bsz=32, num_updates=23500, lr=0.000153, gnorm=0.171, loss_scale=8, train_wall=136, gb_free=15.4, wall=32458
2023-10-19 14:05:15 | INFO | train_inner | epoch 001:  23641 / 1830643 loss=3.52, ppl=11.47, wps=23981.1, ups=0.73, wpb=32768, bsz=32, num_updates=23600, lr=0.0001528, gnorm=0.184, loss_scale=8, train_wall=136, gb_free=15.4, wall=32594
2023-10-19 14:07:32 | INFO | train_inner | epoch 001:  23741 / 1830643 loss=3.661, ppl=12.65, wps=24025.5, ups=0.73, wpb=32768, bsz=32, num_updates=23700, lr=0.0001526, gnorm=0.158, loss_scale=8, train_wall=136, gb_free=15.4, wall=32731
2023-10-19 14:09:47 | INFO | train_inner | epoch 001:  23841 / 1830643 loss=3.49, ppl=11.24, wps=24241.3, ups=0.74, wpb=32768, bsz=32, num_updates=23800, lr=0.0001524, gnorm=0.172, loss_scale=8, train_wall=135, gb_free=15.4, wall=32866
2023-10-19 14:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 14:12:03 | INFO | train_inner | epoch 001:  23942 / 1830643 loss=3.398, ppl=10.54, wps=24018.4, ups=0.73, wpb=32768, bsz=32, num_updates=23900, lr=0.0001522, gnorm=0.162, loss_scale=8, train_wall=136, gb_free=15.4, wall=33002
2023-10-19 14:12:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 14:14:19 | INFO | train_inner | epoch 001:  24043 / 1830643 loss=3.589, ppl=12.04, wps=24044, ups=0.73, wpb=32768, bsz=32, num_updates=24000, lr=0.000152, gnorm=0.203, loss_scale=4, train_wall=136, gb_free=15.4, wall=33139
2023-10-19 14:16:34 | INFO | train_inner | epoch 001:  24143 / 1830643 loss=3.46, ppl=11.01, wps=24277.1, ups=0.74, wpb=32768, bsz=32, num_updates=24100, lr=0.0001518, gnorm=0.166, loss_scale=4, train_wall=135, gb_free=15.4, wall=33274
2023-10-19 14:18:49 | INFO | train_inner | epoch 001:  24243 / 1830643 loss=3.493, ppl=11.26, wps=24302.7, ups=0.74, wpb=32768, bsz=32, num_updates=24200, lr=0.0001516, gnorm=0.159, loss_scale=4, train_wall=134, gb_free=15.4, wall=33409
2023-10-19 14:21:04 | INFO | train_inner | epoch 001:  24343 / 1830643 loss=3.367, ppl=10.32, wps=24248.3, ups=0.74, wpb=32768, bsz=32, num_updates=24300, lr=0.0001514, gnorm=0.161, loss_scale=4, train_wall=135, gb_free=15.4, wall=33544
2023-10-19 14:23:19 | INFO | train_inner | epoch 001:  24443 / 1830643 loss=3.477, ppl=11.14, wps=24291.1, ups=0.74, wpb=32768, bsz=32, num_updates=24400, lr=0.0001512, gnorm=0.18, loss_scale=4, train_wall=135, gb_free=15.4, wall=33679
2023-10-19 14:25:35 | INFO | train_inner | epoch 001:  24543 / 1830643 loss=3.444, ppl=10.89, wps=24201.3, ups=0.74, wpb=32768, bsz=32, num_updates=24500, lr=0.000151, gnorm=0.16, loss_scale=8, train_wall=135, gb_free=15.4, wall=33814
2023-10-19 14:26:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 14:27:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 14:27:53 | INFO | train_inner | epoch 001:  24645 / 1830643 loss=3.713, ppl=13.11, wps=23687.8, ups=0.72, wpb=32768, bsz=32, num_updates=24600, lr=0.0001508, gnorm=0.166, loss_scale=2, train_wall=138, gb_free=15.4, wall=33952
2023-10-19 14:30:08 | INFO | train_inner | epoch 001:  24745 / 1830643 loss=3.558, ppl=11.78, wps=24280.5, ups=0.74, wpb=32768, bsz=32, num_updates=24700, lr=0.0001506, gnorm=0.157, loss_scale=2, train_wall=135, gb_free=15.4, wall=34087
2023-10-19 14:32:23 | INFO | train_inner | epoch 001:  24845 / 1830643 loss=3.586, ppl=12.01, wps=24267.4, ups=0.74, wpb=32768, bsz=32, num_updates=24800, lr=0.0001504, gnorm=0.161, loss_scale=2, train_wall=135, gb_free=15.4, wall=34222
2023-10-19 14:34:38 | INFO | train_inner | epoch 001:  24945 / 1830643 loss=3.382, ppl=10.43, wps=24276.4, ups=0.74, wpb=32768, bsz=32, num_updates=24900, lr=0.0001502, gnorm=0.236, loss_scale=2, train_wall=135, gb_free=15.4, wall=34357
2023-10-19 14:36:53 | INFO | train_inner | epoch 001:  25045 / 1830643 loss=3.398, ppl=10.54, wps=24319.9, ups=0.74, wpb=32768, bsz=32, num_updates=25000, lr=0.00015, gnorm=0.162, loss_scale=2, train_wall=134, gb_free=15.4, wall=34492
2023-10-19 14:39:09 | INFO | train_inner | epoch 001:  25145 / 1830643 loss=3.404, ppl=10.59, wps=24085.7, ups=0.74, wpb=32768, bsz=32, num_updates=25100, lr=0.0001498, gnorm=0.162, loss_scale=4, train_wall=136, gb_free=15.4, wall=34628
2023-10-19 14:41:28 | INFO | train_inner | epoch 001:  25245 / 1830643 loss=3.49, ppl=11.23, wps=23594.3, ups=0.72, wpb=32768, bsz=32, num_updates=25200, lr=0.0001496, gnorm=0.165, loss_scale=4, train_wall=138, gb_free=15.4, wall=34767
2023-10-19 14:43:47 | INFO | train_inner | epoch 001:  25345 / 1830643 loss=3.559, ppl=11.78, wps=23459.1, ups=0.72, wpb=32768, bsz=32, num_updates=25300, lr=0.0001494, gnorm=0.152, loss_scale=4, train_wall=139, gb_free=15.4, wall=34907
2023-10-19 14:46:07 | INFO | train_inner | epoch 001:  25445 / 1830643 loss=3.612, ppl=12.23, wps=23535.7, ups=0.72, wpb=32768, bsz=32, num_updates=25400, lr=0.0001492, gnorm=0.166, loss_scale=4, train_wall=139, gb_free=15.4, wall=35046
2023-10-19 14:48:22 | INFO | train_inner | epoch 001:  25545 / 1830643 loss=3.418, ppl=10.69, wps=24123.3, ups=0.74, wpb=32768, bsz=32, num_updates=25500, lr=0.000149, gnorm=0.157, loss_scale=4, train_wall=135, gb_free=15.4, wall=35182
2023-10-19 14:50:38 | INFO | train_inner | epoch 001:  25645 / 1830643 loss=3.525, ppl=11.51, wps=24172.6, ups=0.74, wpb=32768, bsz=32, num_updates=25600, lr=0.0001488, gnorm=0.171, loss_scale=8, train_wall=135, gb_free=15.4, wall=35317
2023-10-19 14:52:53 | INFO | train_inner | epoch 001:  25745 / 1830643 loss=3.475, ppl=11.12, wps=24198.2, ups=0.74, wpb=32768, bsz=32, num_updates=25700, lr=0.0001486, gnorm=0.161, loss_scale=8, train_wall=135, gb_free=15.4, wall=35453
2023-10-19 14:55:09 | INFO | train_inner | epoch 001:  25845 / 1830643 loss=3.524, ppl=11.51, wps=24135.5, ups=0.74, wpb=32768, bsz=32, num_updates=25800, lr=0.0001484, gnorm=0.16, loss_scale=8, train_wall=135, gb_free=15.4, wall=35588
2023-10-19 14:57:24 | INFO | train_inner | epoch 001:  25945 / 1830643 loss=3.52, ppl=11.47, wps=24220.7, ups=0.74, wpb=32768, bsz=32, num_updates=25900, lr=0.0001482, gnorm=0.154, loss_scale=8, train_wall=135, gb_free=15.4, wall=35724
2023-10-19 14:59:40 | INFO | train_inner | epoch 001:  26045 / 1830643 loss=3.449, ppl=10.92, wps=24158.2, ups=0.74, wpb=32768, bsz=32, num_updates=26000, lr=0.000148, gnorm=0.17, loss_scale=8, train_wall=135, gb_free=15.4, wall=35859
2023-10-19 15:01:56 | INFO | train_inner | epoch 001:  26145 / 1830643 loss=3.346, ppl=10.17, wps=24170, ups=0.74, wpb=32768, bsz=32, num_updates=26100, lr=0.0001478, gnorm=0.158, loss_scale=16, train_wall=135, gb_free=15.4, wall=35995
2023-10-19 15:04:11 | INFO | train_inner | epoch 001:  26245 / 1830643 loss=3.168, ppl=8.99, wps=24192.1, ups=0.74, wpb=32768, bsz=32, num_updates=26200, lr=0.0001476, gnorm=0.162, loss_scale=16, train_wall=135, gb_free=15.4, wall=36130
2023-10-19 15:06:26 | INFO | train_inner | epoch 001:  26345 / 1830643 loss=3.388, ppl=10.47, wps=24233.5, ups=0.74, wpb=32768, bsz=32, num_updates=26300, lr=0.0001474, gnorm=0.174, loss_scale=16, train_wall=135, gb_free=15.4, wall=36266
2023-10-19 15:06:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 15:08:43 | INFO | train_inner | epoch 001:  26446 / 1830643 loss=3.465, ppl=11.04, wps=23930.2, ups=0.73, wpb=32768, bsz=32, num_updates=26400, lr=0.0001472, gnorm=0.151, loss_scale=8, train_wall=137, gb_free=15.4, wall=36403
2023-10-19 15:10:59 | INFO | train_inner | epoch 001:  26546 / 1830643 loss=3.468, ppl=11.06, wps=24192.9, ups=0.74, wpb=32768, bsz=32, num_updates=26500, lr=0.000147, gnorm=0.163, loss_scale=8, train_wall=135, gb_free=15.4, wall=36538
2023-10-19 15:13:14 | INFO | train_inner | epoch 001:  26646 / 1830643 loss=3.615, ppl=12.25, wps=24231.2, ups=0.74, wpb=32768, bsz=32, num_updates=26600, lr=0.0001468, gnorm=0.159, loss_scale=8, train_wall=135, gb_free=15.4, wall=36673
2023-10-19 15:15:32 | INFO | train_inner | epoch 001:  26746 / 1830643 loss=3.441, ppl=10.86, wps=23650.2, ups=0.72, wpb=32768, bsz=32, num_updates=26700, lr=0.0001466, gnorm=0.17, loss_scale=8, train_wall=138, gb_free=15.4, wall=36812
2023-10-19 15:17:48 | INFO | train_inner | epoch 001:  26846 / 1830643 loss=3.381, ppl=10.42, wps=24262.7, ups=0.74, wpb=32768, bsz=32, num_updates=26800, lr=0.0001464, gnorm=0.156, loss_scale=8, train_wall=135, gb_free=15.4, wall=36947
2023-10-19 15:20:05 | INFO | train_inner | epoch 001:  26946 / 1830643 loss=3.484, ppl=11.19, wps=23883.4, ups=0.73, wpb=32768, bsz=32, num_updates=26900, lr=0.0001462, gnorm=0.155, loss_scale=16, train_wall=137, gb_free=15.4, wall=37084
2023-10-19 15:22:20 | INFO | train_inner | epoch 001:  27046 / 1830643 loss=3.708, ppl=13.07, wps=24152.7, ups=0.74, wpb=32768, bsz=32, num_updates=27000, lr=0.000146, gnorm=0.162, loss_scale=16, train_wall=135, gb_free=15.4, wall=37220
2023-10-19 15:24:36 | INFO | train_inner | epoch 001:  27146 / 1830643 loss=3.328, ppl=10.04, wps=24083.3, ups=0.73, wpb=32768, bsz=32, num_updates=27100, lr=0.0001458, gnorm=0.16, loss_scale=16, train_wall=136, gb_free=15.4, wall=37356
2023-10-19 15:26:55 | INFO | train_inner | epoch 001:  27246 / 1830643 loss=3.479, ppl=11.15, wps=23693.9, ups=0.72, wpb=32768, bsz=32, num_updates=27200, lr=0.0001456, gnorm=0.149, loss_scale=16, train_wall=138, gb_free=15.4, wall=37494
2023-10-19 15:29:11 | INFO | train_inner | epoch 001:  27346 / 1830643 loss=3.597, ppl=12.1, wps=24018.8, ups=0.73, wpb=32768, bsz=32, num_updates=27300, lr=0.0001454, gnorm=0.175, loss_scale=16, train_wall=136, gb_free=15.4, wall=37630
2023-10-19 15:30:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 15:30:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 15:31:29 | INFO | train_inner | epoch 001:  27448 / 1830643 loss=3.494, ppl=11.27, wps=23743.5, ups=0.72, wpb=32768, bsz=32, num_updates=27400, lr=0.0001452, gnorm=0.166, loss_scale=8, train_wall=138, gb_free=15.4, wall=37768
2023-10-19 15:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 15:33:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 15:33:47 | INFO | train_inner | epoch 001:  27550 / 1830643 loss=3.497, ppl=11.29, wps=23744.6, ups=0.72, wpb=32768, bsz=32, num_updates=27500, lr=0.000145, gnorm=0.199, loss_scale=2, train_wall=138, gb_free=15.4, wall=37906
2023-10-19 15:36:03 | INFO | train_inner | epoch 001:  27650 / 1830643 loss=3.528, ppl=11.54, wps=24209, ups=0.74, wpb=32768, bsz=32, num_updates=27600, lr=0.0001448, gnorm=0.168, loss_scale=2, train_wall=135, gb_free=15.4, wall=38042
2023-10-19 15:38:19 | INFO | train_inner | epoch 001:  27750 / 1830643 loss=3.524, ppl=11.5, wps=24062.8, ups=0.73, wpb=32768, bsz=32, num_updates=27700, lr=0.0001446, gnorm=0.158, loss_scale=2, train_wall=136, gb_free=15.4, wall=38178
2023-10-19 15:40:35 | INFO | train_inner | epoch 001:  27850 / 1830643 loss=3.488, ppl=11.22, wps=24080.6, ups=0.73, wpb=32768, bsz=32, num_updates=27800, lr=0.0001444, gnorm=0.148, loss_scale=2, train_wall=136, gb_free=15.4, wall=38314
2023-10-19 15:42:58 | INFO | train_inner | epoch 001:  27950 / 1830643 loss=3.704, ppl=13.03, wps=22921.5, ups=0.7, wpb=32768, bsz=32, num_updates=27900, lr=0.0001442, gnorm=0.167, loss_scale=2, train_wall=143, gb_free=15.4, wall=38457
2023-10-19 15:45:40 | INFO | train_inner | epoch 001:  28050 / 1830643 loss=3.362, ppl=10.28, wps=20189.7, ups=0.62, wpb=32768, bsz=32, num_updates=28000, lr=0.000144, gnorm=0.157, loss_scale=4, train_wall=162, gb_free=15.4, wall=38619
2023-10-19 15:48:10 | INFO | train_inner | epoch 001:  28150 / 1830643 loss=3.555, ppl=11.75, wps=21880, ups=0.67, wpb=32768, bsz=32, num_updates=28100, lr=0.0001438, gnorm=0.171, loss_scale=4, train_wall=149, gb_free=15.4, wall=38769
2023-10-19 15:50:37 | INFO | train_inner | epoch 001:  28250 / 1830643 loss=3.43, ppl=10.78, wps=22228.8, ups=0.68, wpb=32768, bsz=32, num_updates=28200, lr=0.0001436, gnorm=0.154, loss_scale=4, train_wall=147, gb_free=15.4, wall=38917
2023-10-19 15:52:54 | INFO | train_inner | epoch 001:  28350 / 1830643 loss=3.399, ppl=10.55, wps=24039.6, ups=0.73, wpb=32768, bsz=32, num_updates=28300, lr=0.0001434, gnorm=0.167, loss_scale=4, train_wall=136, gb_free=15.4, wall=39053
2023-10-19 15:55:12 | INFO | train_inner | epoch 001:  28450 / 1830643 loss=3.59, ppl=12.04, wps=23634.5, ups=0.72, wpb=32768, bsz=32, num_updates=28400, lr=0.0001432, gnorm=0.164, loss_scale=4, train_wall=138, gb_free=15.4, wall=39191
2023-10-19 15:57:28 | INFO | train_inner | epoch 001:  28550 / 1830643 loss=3.495, ppl=11.27, wps=24116.8, ups=0.74, wpb=32768, bsz=32, num_updates=28500, lr=0.000143, gnorm=0.168, loss_scale=4, train_wall=135, gb_free=15.4, wall=39327
2023-10-19 15:59:44 | INFO | train_inner | epoch 001:  28650 / 1830643 loss=3.524, ppl=11.5, wps=24073.1, ups=0.73, wpb=32768, bsz=32, num_updates=28600, lr=0.0001428, gnorm=0.169, loss_scale=8, train_wall=136, gb_free=15.4, wall=39463
2023-10-19 16:02:00 | INFO | train_inner | epoch 001:  28750 / 1830643 loss=3.63, ppl=12.38, wps=24119.4, ups=0.74, wpb=32768, bsz=32, num_updates=28700, lr=0.0001426, gnorm=0.147, loss_scale=8, train_wall=135, gb_free=15.4, wall=39599
2023-10-19 16:04:16 | INFO | train_inner | epoch 001:  28850 / 1830643 loss=3.456, ppl=10.98, wps=24172.2, ups=0.74, wpb=32768, bsz=32, num_updates=28800, lr=0.0001424, gnorm=0.154, loss_scale=8, train_wall=135, gb_free=15.4, wall=39735
2023-10-19 16:05:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 16:06:34 | INFO | train_inner | epoch 001:  28951 / 1830643 loss=3.345, ppl=10.16, wps=23679.1, ups=0.72, wpb=32768, bsz=32, num_updates=28900, lr=0.0001422, gnorm=0.17, loss_scale=4, train_wall=138, gb_free=15.4, wall=39873
2023-10-19 16:08:50 | INFO | train_inner | epoch 001:  29051 / 1830643 loss=3.488, ppl=11.22, wps=24041.4, ups=0.73, wpb=32768, bsz=32, num_updates=29000, lr=0.000142, gnorm=0.178, loss_scale=4, train_wall=136, gb_free=15.4, wall=40010
2023-10-19 16:11:49 | INFO | train_inner | epoch 001:  29151 / 1830643 loss=3.133, ppl=8.77, wps=18312.8, ups=0.56, wpb=32768, bsz=32, num_updates=29100, lr=0.0001418, gnorm=0.171, loss_scale=4, train_wall=179, gb_free=15.4, wall=40188
2023-10-19 16:14:45 | INFO | train_inner | epoch 001:  29251 / 1830643 loss=3.385, ppl=10.45, wps=18645.9, ups=0.57, wpb=32768, bsz=32, num_updates=29200, lr=0.0001416, gnorm=0.189, loss_scale=4, train_wall=175, gb_free=15.4, wall=40364
2023-10-19 16:17:41 | INFO | train_inner | epoch 001:  29351 / 1830643 loss=3.436, ppl=10.82, wps=18592.4, ups=0.57, wpb=32768, bsz=32, num_updates=29300, lr=0.0001414, gnorm=0.165, loss_scale=4, train_wall=176, gb_free=15.4, wall=40540
2023-10-19 16:20:12 | INFO | train_inner | epoch 001:  29451 / 1830643 loss=3.576, ppl=11.92, wps=21669.3, ups=0.66, wpb=32768, bsz=32, num_updates=29400, lr=0.0001412, gnorm=0.163, loss_scale=8, train_wall=151, gb_free=15.4, wall=40692
2023-10-19 16:23:07 | INFO | train_inner | epoch 001:  29551 / 1830643 loss=3.427, ppl=10.76, wps=18741.1, ups=0.57, wpb=32768, bsz=32, num_updates=29500, lr=0.000141, gnorm=0.162, loss_scale=8, train_wall=174, gb_free=15.4, wall=40867
2023-10-19 16:26:04 | INFO | train_inner | epoch 001:  29651 / 1830643 loss=3.368, ppl=10.33, wps=18493.1, ups=0.56, wpb=32768, bsz=32, num_updates=29600, lr=0.0001408, gnorm=0.158, loss_scale=8, train_wall=177, gb_free=15.4, wall=41044
2023-10-19 16:29:01 | INFO | train_inner | epoch 001:  29751 / 1830643 loss=3.422, ppl=10.72, wps=18597, ups=0.57, wpb=32768, bsz=32, num_updates=29700, lr=0.0001406, gnorm=0.157, loss_scale=8, train_wall=176, gb_free=15.4, wall=41220
2023-10-19 16:31:58 | INFO | train_inner | epoch 001:  29851 / 1830643 loss=3.53, ppl=11.55, wps=18530.5, ups=0.57, wpb=32768, bsz=32, num_updates=29800, lr=0.0001404, gnorm=0.165, loss_scale=8, train_wall=176, gb_free=15.4, wall=41397
2023-10-19 16:34:54 | INFO | train_inner | epoch 001:  29951 / 1830643 loss=3.443, ppl=10.88, wps=18588.2, ups=0.57, wpb=32768, bsz=32, num_updates=29900, lr=0.0001402, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=41573
2023-10-19 16:36:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 16:37:51 | INFO | train_inner | epoch 001:  30052 / 1830643 loss=3.619, ppl=12.29, wps=18443.4, ups=0.56, wpb=32768, bsz=32, num_updates=30000, lr=0.00014, gnorm=0.163, loss_scale=8, train_wall=177, gb_free=15.4, wall=41751
2023-10-19 16:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 30000 updates
2023-10-19 16:37:51 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_30000.pt
2023-10-19 16:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_30000.pt
2023-10-19 16:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score None) (writing took 14.757470593089238 seconds)
2023-10-19 16:41:03 | INFO | train_inner | epoch 001:  30152 / 1830643 loss=3.488, ppl=11.22, wps=17084.2, ups=0.52, wpb=32768, bsz=32, num_updates=30100, lr=0.0001398, gnorm=0.159, loss_scale=8, train_wall=177, gb_free=15.4, wall=41943
2023-10-19 16:43:59 | INFO | train_inner | epoch 001:  30252 / 1830643 loss=3.462, ppl=11.02, wps=18608.4, ups=0.57, wpb=32768, bsz=32, num_updates=30200, lr=0.0001396, gnorm=0.17, loss_scale=8, train_wall=176, gb_free=15.4, wall=42119
2023-10-19 16:46:55 | INFO | train_inner | epoch 001:  30352 / 1830643 loss=3.615, ppl=12.25, wps=18620.9, ups=0.57, wpb=32768, bsz=32, num_updates=30300, lr=0.0001394, gnorm=0.148, loss_scale=8, train_wall=176, gb_free=15.4, wall=42295
2023-10-19 16:49:52 | INFO | train_inner | epoch 001:  30452 / 1830643 loss=3.333, ppl=10.08, wps=18547.7, ups=0.57, wpb=32768, bsz=32, num_updates=30400, lr=0.0001392, gnorm=0.154, loss_scale=8, train_wall=176, gb_free=15.4, wall=42471
2023-10-19 16:52:49 | INFO | train_inner | epoch 001:  30552 / 1830643 loss=3.416, ppl=10.67, wps=18502.3, ups=0.56, wpb=32768, bsz=32, num_updates=30500, lr=0.000139, gnorm=0.16, loss_scale=16, train_wall=177, gb_free=15.4, wall=42648
2023-10-19 16:55:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 16:55:39 | INFO | train_inner | epoch 001:  30653 / 1830643 loss=3.49, ppl=11.23, wps=19282.8, ups=0.59, wpb=32768, bsz=32, num_updates=30600, lr=0.0001388, gnorm=0.156, loss_scale=8, train_wall=170, gb_free=15.4, wall=42818
2023-10-19 16:57:55 | INFO | train_inner | epoch 001:  30753 / 1830643 loss=3.437, ppl=10.83, wps=24154, ups=0.74, wpb=32768, bsz=32, num_updates=30700, lr=0.0001386, gnorm=0.154, loss_scale=8, train_wall=135, gb_free=15.4, wall=42954
2023-10-19 17:00:31 | INFO | train_inner | epoch 001:  30853 / 1830643 loss=3.454, ppl=10.96, wps=20943.5, ups=0.64, wpb=32768, bsz=32, num_updates=30800, lr=0.0001384, gnorm=0.17, loss_scale=8, train_wall=156, gb_free=15.4, wall=43110
2023-10-19 17:03:27 | INFO | train_inner | epoch 001:  30953 / 1830643 loss=3.344, ppl=10.15, wps=18647.9, ups=0.57, wpb=32768, bsz=32, num_updates=30900, lr=0.0001382, gnorm=0.164, loss_scale=8, train_wall=175, gb_free=15.4, wall=43286
2023-10-19 17:06:22 | INFO | train_inner | epoch 001:  31053 / 1830643 loss=3.171, ppl=9.01, wps=18676.3, ups=0.57, wpb=32768, bsz=32, num_updates=31000, lr=0.000138, gnorm=0.162, loss_scale=8, train_wall=175, gb_free=15.4, wall=43462
2023-10-19 17:09:18 | INFO | train_inner | epoch 001:  31153 / 1830643 loss=3.323, ppl=10.01, wps=18619.2, ups=0.57, wpb=32768, bsz=32, num_updates=31100, lr=0.0001378, gnorm=0.155, loss_scale=8, train_wall=176, gb_free=15.4, wall=43638
2023-10-19 17:12:14 | INFO | train_inner | epoch 001:  31253 / 1830643 loss=3.601, ppl=12.14, wps=18605.3, ups=0.57, wpb=32768, bsz=32, num_updates=31200, lr=0.0001376, gnorm=0.156, loss_scale=16, train_wall=176, gb_free=15.4, wall=43814
2023-10-19 17:15:10 | INFO | train_inner | epoch 001:  31353 / 1830643 loss=3.3, ppl=9.85, wps=18622.5, ups=0.57, wpb=32768, bsz=32, num_updates=31300, lr=0.0001374, gnorm=0.16, loss_scale=16, train_wall=176, gb_free=15.4, wall=43990
2023-10-19 17:15:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 17:18:08 | INFO | train_inner | epoch 001:  31454 / 1830643 loss=3.539, ppl=11.62, wps=18469.1, ups=0.56, wpb=32768, bsz=32, num_updates=31400, lr=0.0001372, gnorm=0.164, loss_scale=8, train_wall=177, gb_free=15.4, wall=44167
2023-10-19 17:21:04 | INFO | train_inner | epoch 001:  31554 / 1830643 loss=3.534, ppl=11.58, wps=18605.3, ups=0.57, wpb=32768, bsz=32, num_updates=31500, lr=0.000137, gnorm=0.16, loss_scale=8, train_wall=176, gb_free=15.4, wall=44343
2023-10-19 17:23:59 | INFO | train_inner | epoch 001:  31654 / 1830643 loss=3.551, ppl=11.72, wps=18671.6, ups=0.57, wpb=32768, bsz=32, num_updates=31600, lr=0.0001368, gnorm=0.161, loss_scale=8, train_wall=175, gb_free=15.4, wall=44519
2023-10-19 17:26:56 | INFO | train_inner | epoch 001:  31754 / 1830643 loss=3.626, ppl=12.35, wps=18520.3, ups=0.57, wpb=32768, bsz=32, num_updates=31700, lr=0.0001366, gnorm=0.171, loss_scale=8, train_wall=177, gb_free=15.4, wall=44696
2023-10-19 17:29:52 | INFO | train_inner | epoch 001:  31854 / 1830643 loss=3.471, ppl=11.09, wps=18612.4, ups=0.57, wpb=32768, bsz=32, num_updates=31800, lr=0.0001364, gnorm=0.153, loss_scale=8, train_wall=176, gb_free=15.4, wall=44872
2023-10-19 17:32:50 | INFO | train_inner | epoch 001:  31954 / 1830643 loss=3.494, ppl=11.27, wps=18437.9, ups=0.56, wpb=32768, bsz=32, num_updates=31900, lr=0.0001362, gnorm=0.166, loss_scale=16, train_wall=177, gb_free=15.4, wall=45049
2023-10-19 17:33:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 17:35:48 | INFO | train_inner | epoch 001:  32055 / 1830643 loss=3.456, ppl=10.97, wps=18384, ups=0.56, wpb=32768, bsz=32, num_updates=32000, lr=0.000136, gnorm=0.166, loss_scale=8, train_wall=178, gb_free=15.4, wall=45228
2023-10-19 17:38:45 | INFO | train_inner | epoch 001:  32155 / 1830643 loss=3.577, ppl=11.93, wps=18526.8, ups=0.57, wpb=32768, bsz=32, num_updates=32100, lr=0.0001358, gnorm=0.156, loss_scale=8, train_wall=177, gb_free=15.4, wall=45405
2023-10-19 17:41:41 | INFO | train_inner | epoch 001:  32255 / 1830643 loss=3.528, ppl=11.54, wps=18612.6, ups=0.57, wpb=32768, bsz=32, num_updates=32200, lr=0.0001356, gnorm=0.159, loss_scale=8, train_wall=176, gb_free=15.4, wall=45581
2023-10-19 17:44:40 | INFO | train_inner | epoch 001:  32355 / 1830643 loss=3.454, ppl=10.96, wps=18372.7, ups=0.56, wpb=32768, bsz=32, num_updates=32300, lr=0.0001354, gnorm=0.157, loss_scale=8, train_wall=178, gb_free=15.4, wall=45759
2023-10-19 17:47:36 | INFO | train_inner | epoch 001:  32455 / 1830643 loss=3.566, ppl=11.84, wps=18546.9, ups=0.57, wpb=32768, bsz=32, num_updates=32400, lr=0.0001352, gnorm=0.156, loss_scale=8, train_wall=176, gb_free=15.4, wall=45936
2023-10-19 17:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 17:50:34 | INFO | train_inner | epoch 001:  32556 / 1830643 loss=3.431, ppl=10.79, wps=18396.9, ups=0.56, wpb=32768, bsz=32, num_updates=32500, lr=0.000135, gnorm=0.167, loss_scale=8, train_wall=178, gb_free=15.4, wall=46114
2023-10-19 17:53:30 | INFO | train_inner | epoch 001:  32656 / 1830643 loss=3.45, ppl=10.93, wps=18631.4, ups=0.57, wpb=32768, bsz=32, num_updates=32600, lr=0.0001348, gnorm=0.159, loss_scale=8, train_wall=176, gb_free=15.4, wall=46290
2023-10-19 17:56:26 | INFO | train_inner | epoch 001:  32756 / 1830643 loss=3.298, ppl=9.84, wps=18681, ups=0.57, wpb=32768, bsz=32, num_updates=32700, lr=0.0001346, gnorm=0.152, loss_scale=8, train_wall=175, gb_free=15.4, wall=46465
2023-10-19 17:59:22 | INFO | train_inner | epoch 001:  32856 / 1830643 loss=3.469, ppl=11.07, wps=18578.5, ups=0.57, wpb=32768, bsz=32, num_updates=32800, lr=0.0001344, gnorm=0.153, loss_scale=8, train_wall=176, gb_free=15.4, wall=46641
2023-10-19 18:02:19 | INFO | train_inner | epoch 001:  32956 / 1830643 loss=3.509, ppl=11.38, wps=18582, ups=0.57, wpb=32768, bsz=32, num_updates=32900, lr=0.0001342, gnorm=0.168, loss_scale=8, train_wall=176, gb_free=15.4, wall=46818
2023-10-19 18:05:16 | INFO | train_inner | epoch 001:  33056 / 1830643 loss=3.409, ppl=10.62, wps=18468.7, ups=0.56, wpb=32768, bsz=32, num_updates=33000, lr=0.000134, gnorm=0.156, loss_scale=16, train_wall=177, gb_free=15.4, wall=46995
2023-10-19 18:08:10 | INFO | train_inner | epoch 001:  33156 / 1830643 loss=3.55, ppl=11.71, wps=18785.5, ups=0.57, wpb=32768, bsz=32, num_updates=33100, lr=0.0001338, gnorm=0.157, loss_scale=16, train_wall=174, gb_free=15.4, wall=47170
2023-10-19 18:11:07 | INFO | train_inner | epoch 001:  33256 / 1830643 loss=3.466, ppl=11.05, wps=18565.8, ups=0.57, wpb=32768, bsz=32, num_updates=33200, lr=0.0001336, gnorm=0.168, loss_scale=16, train_wall=176, gb_free=15.4, wall=47346
2023-10-19 18:14:04 | INFO | train_inner | epoch 001:  33356 / 1830643 loss=3.397, ppl=10.53, wps=18503.6, ups=0.56, wpb=32768, bsz=32, num_updates=33300, lr=0.0001334, gnorm=0.156, loss_scale=16, train_wall=177, gb_free=15.4, wall=47523
2023-10-19 18:17:01 | INFO | train_inner | epoch 001:  33456 / 1830643 loss=3.357, ppl=10.24, wps=18557.4, ups=0.57, wpb=32768, bsz=32, num_updates=33400, lr=0.0001332, gnorm=0.152, loss_scale=16, train_wall=176, gb_free=15.4, wall=47700
2023-10-19 18:18:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 18:18:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 18:18:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-19 18:20:04 | INFO | train_inner | epoch 001:  33559 / 1830643 loss=3.612, ppl=12.23, wps=17832.5, ups=0.54, wpb=32768, bsz=32, num_updates=33500, lr=0.000133, gnorm=0.184, loss_scale=2, train_wall=183, gb_free=15.4, wall=47884
2023-10-19 18:23:01 | INFO | train_inner | epoch 001:  33659 / 1830643 loss=3.533, ppl=11.58, wps=18519.6, ups=0.57, wpb=32768, bsz=32, num_updates=33600, lr=0.0001328, gnorm=0.173, loss_scale=2, train_wall=177, gb_free=15.4, wall=48060
2023-10-19 18:25:57 | INFO | train_inner | epoch 001:  33759 / 1830643 loss=3.46, ppl=11, wps=18631.8, ups=0.57, wpb=32768, bsz=32, num_updates=33700, lr=0.0001326, gnorm=0.155, loss_scale=2, train_wall=176, gb_free=15.4, wall=48236
2023-10-19 18:28:56 | INFO | train_inner | epoch 001:  33859 / 1830643 loss=3.382, ppl=10.42, wps=18356.8, ups=0.56, wpb=32768, bsz=32, num_updates=33800, lr=0.0001324, gnorm=0.16, loss_scale=2, train_wall=178, gb_free=15.4, wall=48415
2023-10-19 18:31:50 | INFO | train_inner | epoch 001:  33959 / 1830643 loss=3.353, ppl=10.22, wps=18738.4, ups=0.57, wpb=32768, bsz=32, num_updates=33900, lr=0.0001322, gnorm=0.152, loss_scale=2, train_wall=175, gb_free=15.4, wall=48590
2023-10-19 18:34:47 | INFO | train_inner | epoch 001:  34059 / 1830643 loss=3.399, ppl=10.55, wps=18577.6, ups=0.57, wpb=32768, bsz=32, num_updates=34000, lr=0.000132, gnorm=0.167, loss_scale=4, train_wall=176, gb_free=15.4, wall=48766
2023-10-19 18:37:43 | INFO | train_inner | epoch 001:  34159 / 1830643 loss=3.334, ppl=10.09, wps=18618.9, ups=0.57, wpb=32768, bsz=32, num_updates=34100, lr=0.0001318, gnorm=0.16, loss_scale=4, train_wall=176, gb_free=15.4, wall=48942
2023-10-19 18:40:39 | INFO | train_inner | epoch 001:  34259 / 1830643 loss=3.53, ppl=11.55, wps=18634.4, ups=0.57, wpb=32768, bsz=32, num_updates=34200, lr=0.0001316, gnorm=0.166, loss_scale=4, train_wall=175, gb_free=15.4, wall=49118
2023-10-19 18:43:34 | INFO | train_inner | epoch 001:  34359 / 1830643 loss=3.466, ppl=11.05, wps=18645.1, ups=0.57, wpb=32768, bsz=32, num_updates=34300, lr=0.0001314, gnorm=0.166, loss_scale=4, train_wall=175, gb_free=15.4, wall=49294
2023-10-19 18:46:32 | INFO | train_inner | epoch 001:  34459 / 1830643 loss=3.503, ppl=11.34, wps=18429.6, ups=0.56, wpb=32768, bsz=32, num_updates=34400, lr=0.0001312, gnorm=0.161, loss_scale=4, train_wall=177, gb_free=15.4, wall=49472
2023-10-19 18:49:28 | INFO | train_inner | epoch 001:  34559 / 1830643 loss=3.493, ppl=11.26, wps=18683.1, ups=0.57, wpb=32768, bsz=32, num_updates=34500, lr=0.000131, gnorm=0.171, loss_scale=8, train_wall=175, gb_free=15.4, wall=49647
2023-10-19 18:52:23 | INFO | train_inner | epoch 001:  34659 / 1830643 loss=3.495, ppl=11.28, wps=18683.6, ups=0.57, wpb=32768, bsz=32, num_updates=34600, lr=0.0001308, gnorm=0.161, loss_scale=8, train_wall=175, gb_free=15.4, wall=49822
2023-10-19 18:55:20 | INFO | train_inner | epoch 001:  34759 / 1830643 loss=3.555, ppl=11.75, wps=18541.7, ups=0.57, wpb=32768, bsz=32, num_updates=34700, lr=0.0001306, gnorm=0.157, loss_scale=8, train_wall=176, gb_free=15.4, wall=49999
2023-10-19 18:58:16 | INFO | train_inner | epoch 001:  34859 / 1830643 loss=3.737, ppl=13.33, wps=18584.7, ups=0.57, wpb=32768, bsz=32, num_updates=34800, lr=0.0001304, gnorm=0.165, loss_scale=8, train_wall=176, gb_free=15.4, wall=50175
2023-10-19 19:01:12 | INFO | train_inner | epoch 001:  34959 / 1830643 loss=3.437, ppl=10.83, wps=18620.1, ups=0.57, wpb=32768, bsz=32, num_updates=34900, lr=0.0001302, gnorm=0.152, loss_scale=8, train_wall=176, gb_free=15.4, wall=50351
2023-10-19 19:04:08 | INFO | train_inner | epoch 001:  35059 / 1830643 loss=3.451, ppl=10.94, wps=18666.4, ups=0.57, wpb=32768, bsz=32, num_updates=35000, lr=0.00013, gnorm=0.149, loss_scale=16, train_wall=175, gb_free=15.4, wall=50527
2023-10-19 19:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 19:07:05 | INFO | train_inner | epoch 001:  35160 / 1830643 loss=3.435, ppl=10.81, wps=18462.1, ups=0.56, wpb=32768, bsz=32, num_updates=35100, lr=0.0001298, gnorm=0.156, loss_scale=8, train_wall=177, gb_free=15.4, wall=50704
2023-10-19 19:10:02 | INFO | train_inner | epoch 001:  35260 / 1830643 loss=3.253, ppl=9.53, wps=18550.2, ups=0.57, wpb=32768, bsz=32, num_updates=35200, lr=0.0001296, gnorm=0.162, loss_scale=8, train_wall=176, gb_free=15.4, wall=50881
2023-10-19 19:13:00 | INFO | train_inner | epoch 001:  35360 / 1830643 loss=3.477, ppl=11.13, wps=18415.7, ups=0.56, wpb=32768, bsz=32, num_updates=35300, lr=0.0001294, gnorm=0.158, loss_scale=8, train_wall=178, gb_free=15.4, wall=51059
2023-10-19 19:15:58 | INFO | train_inner | epoch 001:  35460 / 1830643 loss=3.239, ppl=9.44, wps=18363.4, ups=0.56, wpb=32768, bsz=32, num_updates=35400, lr=0.0001292, gnorm=0.17, loss_scale=8, train_wall=178, gb_free=15.4, wall=51237
2023-10-19 19:18:54 | INFO | train_inner | epoch 001:  35560 / 1830643 loss=3.481, ppl=11.16, wps=18682, ups=0.57, wpb=32768, bsz=32, num_updates=35500, lr=0.000129, gnorm=0.158, loss_scale=8, train_wall=175, gb_free=15.4, wall=51413
2023-10-19 19:21:50 | INFO | train_inner | epoch 001:  35660 / 1830643 loss=3.369, ppl=10.33, wps=18545.9, ups=0.57, wpb=32768, bsz=32, num_updates=35600, lr=0.0001288, gnorm=0.166, loss_scale=16, train_wall=176, gb_free=15.4, wall=51589
2023-10-19 19:24:48 | INFO | train_inner | epoch 001:  35760 / 1830643 loss=3.394, ppl=10.51, wps=18447.6, ups=0.56, wpb=32768, bsz=32, num_updates=35700, lr=0.0001286, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=51767
2023-10-19 19:27:45 | INFO | train_inner | epoch 001:  35860 / 1830643 loss=3.626, ppl=12.35, wps=18512.3, ups=0.56, wpb=32768, bsz=32, num_updates=35800, lr=0.0001284, gnorm=0.164, loss_scale=16, train_wall=177, gb_free=15.4, wall=51944
2023-10-19 19:30:40 | INFO | train_inner | epoch 001:  35960 / 1830643 loss=3.55, ppl=11.72, wps=18703.9, ups=0.57, wpb=32768, bsz=32, num_updates=35900, lr=0.0001282, gnorm=0.16, loss_scale=16, train_wall=175, gb_free=15.4, wall=52119
2023-10-19 19:33:37 | INFO | train_inner | epoch 001:  36060 / 1830643 loss=3.276, ppl=9.69, wps=18555.5, ups=0.57, wpb=32768, bsz=32, num_updates=36000, lr=0.000128, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=52296
2023-10-19 19:36:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 19:36:34 | INFO | train_inner | epoch 001:  36161 / 1830643 loss=3.565, ppl=11.83, wps=18470.6, ups=0.56, wpb=32768, bsz=32, num_updates=36100, lr=0.0001278, gnorm=0.168, loss_scale=16, train_wall=177, gb_free=15.4, wall=52473
2023-10-19 19:39:32 | INFO | train_inner | epoch 001:  36261 / 1830643 loss=3.433, ppl=10.8, wps=18390.2, ups=0.56, wpb=32768, bsz=32, num_updates=36200, lr=0.0001276, gnorm=0.165, loss_scale=16, train_wall=178, gb_free=15.4, wall=52651
2023-10-19 19:42:28 | INFO | train_inner | epoch 001:  36361 / 1830643 loss=3.543, ppl=11.66, wps=18604.5, ups=0.57, wpb=32768, bsz=32, num_updates=36300, lr=0.0001274, gnorm=0.164, loss_scale=16, train_wall=176, gb_free=15.4, wall=52828
2023-10-19 19:45:25 | INFO | train_inner | epoch 001:  36461 / 1830643 loss=3.283, ppl=9.73, wps=18536.7, ups=0.57, wpb=32768, bsz=32, num_updates=36400, lr=0.0001272, gnorm=0.16, loss_scale=16, train_wall=176, gb_free=15.4, wall=53004
2023-10-19 19:48:22 | INFO | train_inner | epoch 001:  36561 / 1830643 loss=3.506, ppl=11.36, wps=18549.1, ups=0.57, wpb=32768, bsz=32, num_updates=36500, lr=0.000127, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=53181
2023-10-19 19:51:19 | INFO | train_inner | epoch 001:  36661 / 1830643 loss=3.544, ppl=11.66, wps=18523.5, ups=0.57, wpb=32768, bsz=32, num_updates=36600, lr=0.0001268, gnorm=0.157, loss_scale=16, train_wall=177, gb_free=15.4, wall=53358
2023-10-19 19:52:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 19:54:16 | INFO | train_inner | epoch 001:  36762 / 1830643 loss=3.508, ppl=11.38, wps=18432.3, ups=0.56, wpb=32768, bsz=32, num_updates=36700, lr=0.0001266, gnorm=0.15, loss_scale=16, train_wall=177, gb_free=15.4, wall=53536
2023-10-19 19:57:13 | INFO | train_inner | epoch 001:  36862 / 1830643 loss=3.428, ppl=10.77, wps=18607.7, ups=0.57, wpb=32768, bsz=32, num_updates=36800, lr=0.0001264, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=53712
2023-10-19 19:57:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 20:00:11 | INFO | train_inner | epoch 001:  36963 / 1830643 loss=3.395, ppl=10.52, wps=18317.8, ups=0.56, wpb=32768, bsz=32, num_updates=36900, lr=0.0001262, gnorm=0.173, loss_scale=8, train_wall=179, gb_free=15.4, wall=53891
2023-10-19 20:03:08 | INFO | train_inner | epoch 001:  37063 / 1830643 loss=3.261, ppl=9.59, wps=18541.3, ups=0.57, wpb=32768, bsz=32, num_updates=37000, lr=0.000126, gnorm=0.164, loss_scale=8, train_wall=176, gb_free=15.4, wall=54067
2023-10-19 20:06:04 | INFO | train_inner | epoch 001:  37163 / 1830643 loss=3.434, ppl=10.81, wps=18644.7, ups=0.57, wpb=32768, bsz=32, num_updates=37100, lr=0.0001258, gnorm=0.154, loss_scale=8, train_wall=175, gb_free=15.4, wall=54243
2023-10-19 20:09:00 | INFO | train_inner | epoch 001:  37263 / 1830643 loss=3.549, ppl=11.7, wps=18596, ups=0.57, wpb=32768, bsz=32, num_updates=37200, lr=0.0001256, gnorm=0.154, loss_scale=8, train_wall=176, gb_free=15.4, wall=54419
2023-10-19 20:11:57 | INFO | train_inner | epoch 001:  37363 / 1830643 loss=3.359, ppl=10.26, wps=18486.9, ups=0.56, wpb=32768, bsz=32, num_updates=37300, lr=0.0001254, gnorm=0.156, loss_scale=8, train_wall=177, gb_free=15.4, wall=54597
2023-10-19 20:14:54 | INFO | train_inner | epoch 001:  37463 / 1830643 loss=3.505, ppl=11.35, wps=18581.4, ups=0.57, wpb=32768, bsz=32, num_updates=37400, lr=0.0001252, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=54773
2023-10-19 20:17:50 | INFO | train_inner | epoch 001:  37563 / 1830643 loss=3.342, ppl=10.14, wps=18548.7, ups=0.57, wpb=32768, bsz=32, num_updates=37500, lr=0.000125, gnorm=0.157, loss_scale=16, train_wall=176, gb_free=15.4, wall=54950
2023-10-19 20:20:47 | INFO | train_inner | epoch 001:  37663 / 1830643 loss=3.585, ppl=12, wps=18521.6, ups=0.57, wpb=32768, bsz=32, num_updates=37600, lr=0.0001248, gnorm=0.156, loss_scale=16, train_wall=177, gb_free=15.4, wall=55127
2023-10-19 20:23:44 | INFO | train_inner | epoch 001:  37763 / 1830643 loss=3.696, ppl=12.96, wps=18516.9, ups=0.57, wpb=32768, bsz=32, num_updates=37700, lr=0.0001246, gnorm=0.166, loss_scale=16, train_wall=177, gb_free=15.4, wall=55304
2023-10-19 20:26:40 | INFO | train_inner | epoch 001:  37863 / 1830643 loss=3.354, ppl=10.22, wps=18619.6, ups=0.57, wpb=32768, bsz=32, num_updates=37800, lr=0.0001244, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=55480
2023-10-19 20:28:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 20:29:38 | INFO | train_inner | epoch 001:  37964 / 1830643 loss=3.401, ppl=10.56, wps=18390.6, ups=0.56, wpb=32768, bsz=32, num_updates=37900, lr=0.0001242, gnorm=0.152, loss_scale=16, train_wall=178, gb_free=15.4, wall=55658
2023-10-19 20:32:35 | INFO | train_inner | epoch 001:  38064 / 1830643 loss=3.527, ppl=11.53, wps=18522.8, ups=0.57, wpb=32768, bsz=32, num_updates=38000, lr=0.000124, gnorm=0.149, loss_scale=16, train_wall=177, gb_free=15.4, wall=55835
2023-10-19 20:35:31 | INFO | train_inner | epoch 001:  38164 / 1830643 loss=3.529, ppl=11.54, wps=18632.8, ups=0.57, wpb=32768, bsz=32, num_updates=38100, lr=0.0001238, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=56011
2023-10-19 20:38:27 | INFO | train_inner | epoch 001:  38264 / 1830643 loss=3.498, ppl=11.3, wps=18603.6, ups=0.57, wpb=32768, bsz=32, num_updates=38200, lr=0.0001236, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=56187
2023-10-19 20:41:24 | INFO | train_inner | epoch 001:  38364 / 1830643 loss=3.556, ppl=11.77, wps=18554.3, ups=0.57, wpb=32768, bsz=32, num_updates=38300, lr=0.0001234, gnorm=0.163, loss_scale=16, train_wall=176, gb_free=15.4, wall=56363
2023-10-19 20:43:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 20:44:23 | INFO | train_inner | epoch 001:  38465 / 1830643 loss=3.282, ppl=9.73, wps=18302.6, ups=0.56, wpb=32768, bsz=32, num_updates=38400, lr=0.0001232, gnorm=0.147, loss_scale=16, train_wall=179, gb_free=15.4, wall=56542
2023-10-19 20:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 20:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-19 20:47:23 | INFO | train_inner | epoch 001:  38567 / 1830643 loss=3.472, ppl=11.09, wps=18210.8, ups=0.56, wpb=32768, bsz=32, num_updates=38500, lr=0.000123, gnorm=0.151, loss_scale=4, train_wall=180, gb_free=15.4, wall=56722
2023-10-19 20:50:20 | INFO | train_inner | epoch 001:  38667 / 1830643 loss=3.67, ppl=12.72, wps=18513.2, ups=0.56, wpb=32768, bsz=32, num_updates=38600, lr=0.0001228, gnorm=0.154, loss_scale=4, train_wall=177, gb_free=15.4, wall=56899
2023-10-19 20:53:16 | INFO | train_inner | epoch 001:  38767 / 1830643 loss=3.379, ppl=10.4, wps=18611.9, ups=0.57, wpb=32768, bsz=32, num_updates=38700, lr=0.0001226, gnorm=0.163, loss_scale=4, train_wall=176, gb_free=15.4, wall=57075
2023-10-19 20:56:12 | INFO | train_inner | epoch 001:  38867 / 1830643 loss=3.189, ppl=9.12, wps=18666.6, ups=0.57, wpb=32768, bsz=32, num_updates=38800, lr=0.0001224, gnorm=0.152, loss_scale=4, train_wall=175, gb_free=15.4, wall=57251
2023-10-19 20:59:07 | INFO | train_inner | epoch 001:  38967 / 1830643 loss=3.555, ppl=11.76, wps=18647.6, ups=0.57, wpb=32768, bsz=32, num_updates=38900, lr=0.0001222, gnorm=0.161, loss_scale=4, train_wall=175, gb_free=15.4, wall=57427
2023-10-19 21:02:04 | INFO | train_inner | epoch 001:  39067 / 1830643 loss=3.897, ppl=14.89, wps=18589.5, ups=0.57, wpb=32768, bsz=32, num_updates=39000, lr=0.000122, gnorm=0.161, loss_scale=8, train_wall=176, gb_free=15.4, wall=57603
2023-10-19 21:04:59 | INFO | train_inner | epoch 001:  39167 / 1830643 loss=3.528, ppl=11.53, wps=18695.9, ups=0.57, wpb=32768, bsz=32, num_updates=39100, lr=0.0001218, gnorm=0.164, loss_scale=8, train_wall=175, gb_free=15.4, wall=57778
2023-10-19 21:07:55 | INFO | train_inner | epoch 001:  39267 / 1830643 loss=3.579, ppl=11.95, wps=18634.4, ups=0.57, wpb=32768, bsz=32, num_updates=39200, lr=0.0001216, gnorm=0.165, loss_scale=8, train_wall=175, gb_free=15.4, wall=57954
2023-10-19 21:10:52 | INFO | train_inner | epoch 001:  39367 / 1830643 loss=3.321, ppl=9.99, wps=18507.3, ups=0.56, wpb=32768, bsz=32, num_updates=39300, lr=0.0001214, gnorm=0.151, loss_scale=8, train_wall=177, gb_free=15.4, wall=58131
2023-10-19 21:13:49 | INFO | train_inner | epoch 001:  39467 / 1830643 loss=3.443, ppl=10.87, wps=18459.8, ups=0.56, wpb=32768, bsz=32, num_updates=39400, lr=0.0001212, gnorm=0.149, loss_scale=8, train_wall=177, gb_free=15.4, wall=58309
2023-10-19 21:16:45 | INFO | train_inner | epoch 001:  39567 / 1830643 loss=3.5, ppl=11.32, wps=18640.1, ups=0.57, wpb=32768, bsz=32, num_updates=39500, lr=0.000121, gnorm=0.153, loss_scale=16, train_wall=175, gb_free=15.4, wall=58484
2023-10-19 21:19:41 | INFO | train_inner | epoch 001:  39667 / 1830643 loss=3.392, ppl=10.5, wps=18671.9, ups=0.57, wpb=32768, bsz=32, num_updates=39600, lr=0.0001208, gnorm=0.147, loss_scale=16, train_wall=175, gb_free=15.4, wall=58660
2023-10-19 21:22:37 | INFO | train_inner | epoch 001:  39767 / 1830643 loss=3.551, ppl=11.72, wps=18616.2, ups=0.57, wpb=32768, bsz=32, num_updates=39700, lr=0.0001206, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=58836
2023-10-19 21:25:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 21:25:34 | INFO | train_inner | epoch 001:  39868 / 1830643 loss=3.417, ppl=10.68, wps=18448.7, ups=0.56, wpb=32768, bsz=32, num_updates=39800, lr=0.0001204, gnorm=0.158, loss_scale=8, train_wall=177, gb_free=15.4, wall=59013
2023-10-19 21:28:30 | INFO | train_inner | epoch 001:  39968 / 1830643 loss=3.505, ppl=11.35, wps=18602.9, ups=0.57, wpb=32768, bsz=32, num_updates=39900, lr=0.0001202, gnorm=0.164, loss_scale=8, train_wall=176, gb_free=15.4, wall=59190
2023-10-19 21:31:26 | INFO | train_inner | epoch 001:  40068 / 1830643 loss=3.341, ppl=10.13, wps=18662, ups=0.57, wpb=32768, bsz=32, num_updates=40000, lr=0.00012, gnorm=0.157, loss_scale=8, train_wall=175, gb_free=15.4, wall=59365
2023-10-19 21:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 40000 updates
2023-10-19 21:31:26 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_40000.pt
2023-10-19 21:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_40000.pt
2023-10-19 21:31:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_40000.pt (epoch 1 @ 40000 updates, score None) (writing took 17.11664050607942 seconds)
2023-10-19 21:34:39 | INFO | train_inner | epoch 001:  40168 / 1830643 loss=3.364, ppl=10.3, wps=16983.2, ups=0.52, wpb=32768, bsz=32, num_updates=40100, lr=0.0001198, gnorm=0.163, loss_scale=8, train_wall=175, gb_free=15.4, wall=59558
2023-10-19 21:37:36 | INFO | train_inner | epoch 001:  40268 / 1830643 loss=3.539, ppl=11.62, wps=18543, ups=0.57, wpb=32768, bsz=32, num_updates=40200, lr=0.0001196, gnorm=0.15, loss_scale=8, train_wall=176, gb_free=15.4, wall=59735
2023-10-19 21:40:32 | INFO | train_inner | epoch 001:  40368 / 1830643 loss=3.367, ppl=10.31, wps=18593.2, ups=0.57, wpb=32768, bsz=32, num_updates=40300, lr=0.0001194, gnorm=0.158, loss_scale=8, train_wall=176, gb_free=15.4, wall=59911
2023-10-19 21:43:28 | INFO | train_inner | epoch 001:  40468 / 1830643 loss=3.431, ppl=10.79, wps=18613.9, ups=0.57, wpb=32768, bsz=32, num_updates=40400, lr=0.0001192, gnorm=0.157, loss_scale=16, train_wall=176, gb_free=15.4, wall=60087
2023-10-19 21:46:24 | INFO | train_inner | epoch 001:  40568 / 1830643 loss=3.552, ppl=11.73, wps=18606.9, ups=0.57, wpb=32768, bsz=32, num_updates=40500, lr=0.000119, gnorm=0.159, loss_scale=16, train_wall=176, gb_free=15.4, wall=60263
2023-10-19 21:49:19 | INFO | train_inner | epoch 001:  40668 / 1830643 loss=3.42, ppl=10.71, wps=18690.6, ups=0.57, wpb=32768, bsz=32, num_updates=40600, lr=0.0001188, gnorm=0.146, loss_scale=16, train_wall=175, gb_free=15.4, wall=60439
2023-10-19 21:52:15 | INFO | train_inner | epoch 001:  40768 / 1830643 loss=3.463, ppl=11.03, wps=18639.5, ups=0.57, wpb=32768, bsz=32, num_updates=40700, lr=0.0001186, gnorm=0.156, loss_scale=16, train_wall=175, gb_free=15.4, wall=60614
2023-10-19 21:55:11 | INFO | train_inner | epoch 001:  40868 / 1830643 loss=3.501, ppl=11.32, wps=18611.1, ups=0.57, wpb=32768, bsz=32, num_updates=40800, lr=0.0001184, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=60790
2023-10-19 21:55:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 21:58:09 | INFO | train_inner | epoch 001:  40969 / 1830643 loss=3.562, ppl=11.81, wps=18436.9, ups=0.56, wpb=32768, bsz=32, num_updates=40900, lr=0.0001182, gnorm=0.177, loss_scale=16, train_wall=177, gb_free=15.4, wall=60968
2023-10-19 22:01:05 | INFO | train_inner | epoch 001:  41069 / 1830643 loss=3.202, ppl=9.2, wps=18579.5, ups=0.57, wpb=32768, bsz=32, num_updates=41000, lr=0.000118, gnorm=0.163, loss_scale=16, train_wall=176, gb_free=15.4, wall=61145
2023-10-19 22:04:01 | INFO | train_inner | epoch 001:  41169 / 1830643 loss=3.465, ppl=11.05, wps=18620.9, ups=0.57, wpb=32768, bsz=32, num_updates=41100, lr=0.0001178, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=61320
2023-10-19 22:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 22:07:01 | INFO | train_inner | epoch 001:  41270 / 1830643 loss=3.363, ppl=10.29, wps=18250.6, ups=0.56, wpb=32768, bsz=32, num_updates=41200, lr=0.0001176, gnorm=0.147, loss_scale=8, train_wall=179, gb_free=15.4, wall=61500
2023-10-19 22:09:57 | INFO | train_inner | epoch 001:  41370 / 1830643 loss=3.628, ppl=12.37, wps=18622.3, ups=0.57, wpb=32768, bsz=32, num_updates=41300, lr=0.0001174, gnorm=0.158, loss_scale=8, train_wall=176, gb_free=15.4, wall=61676
2023-10-19 22:12:54 | INFO | train_inner | epoch 001:  41470 / 1830643 loss=3.32, ppl=9.99, wps=18532.1, ups=0.57, wpb=32768, bsz=32, num_updates=41400, lr=0.0001172, gnorm=0.158, loss_scale=8, train_wall=176, gb_free=15.4, wall=61853
2023-10-19 22:15:49 | INFO | train_inner | epoch 001:  41570 / 1830643 loss=3.489, ppl=11.23, wps=18715.6, ups=0.57, wpb=32768, bsz=32, num_updates=41500, lr=0.000117, gnorm=0.156, loss_scale=8, train_wall=175, gb_free=15.4, wall=62028
2023-10-19 22:18:44 | INFO | train_inner | epoch 001:  41670 / 1830643 loss=3.322, ppl=10, wps=18716.6, ups=0.57, wpb=32768, bsz=32, num_updates=41600, lr=0.0001168, gnorm=0.154, loss_scale=8, train_wall=175, gb_free=15.4, wall=62203
2023-10-19 22:21:40 | INFO | train_inner | epoch 001:  41770 / 1830643 loss=3.556, ppl=11.76, wps=18556, ups=0.57, wpb=32768, bsz=32, num_updates=41700, lr=0.0001166, gnorm=0.152, loss_scale=16, train_wall=176, gb_free=15.4, wall=62380
2023-10-19 22:24:37 | INFO | train_inner | epoch 001:  41870 / 1830643 loss=3.306, ppl=9.89, wps=18546.5, ups=0.57, wpb=32768, bsz=32, num_updates=41800, lr=0.0001164, gnorm=0.167, loss_scale=16, train_wall=176, gb_free=15.4, wall=62556
2023-10-19 22:27:34 | INFO | train_inner | epoch 001:  41970 / 1830643 loss=3.181, ppl=9.07, wps=18554.3, ups=0.57, wpb=32768, bsz=32, num_updates=41900, lr=0.0001162, gnorm=0.16, loss_scale=16, train_wall=176, gb_free=15.4, wall=62733
2023-10-19 22:30:30 | INFO | train_inner | epoch 001:  42070 / 1830643 loss=2.991, ppl=7.95, wps=18577, ups=0.57, wpb=32768, bsz=32, num_updates=42000, lr=0.000116, gnorm=0.156, loss_scale=16, train_wall=176, gb_free=15.4, wall=62909
2023-10-19 22:33:28 | INFO | train_inner | epoch 001:  42170 / 1830643 loss=3.069, ppl=8.39, wps=18454.2, ups=0.56, wpb=32768, bsz=32, num_updates=42100, lr=0.0001158, gnorm=0.153, loss_scale=16, train_wall=177, gb_free=15.4, wall=63087
2023-10-19 22:34:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 22:36:25 | INFO | train_inner | epoch 001:  42271 / 1830643 loss=3.072, ppl=8.41, wps=18454.4, ups=0.56, wpb=32768, bsz=32, num_updates=42200, lr=0.0001156, gnorm=0.16, loss_scale=16, train_wall=177, gb_free=15.4, wall=63264
2023-10-19 22:39:21 | INFO | train_inner | epoch 001:  42371 / 1830643 loss=3.313, ppl=9.94, wps=18596.2, ups=0.57, wpb=32768, bsz=32, num_updates=42300, lr=0.0001154, gnorm=0.162, loss_scale=16, train_wall=176, gb_free=15.4, wall=63441
2023-10-19 22:42:18 | INFO | train_inner | epoch 001:  42471 / 1830643 loss=3.585, ppl=12, wps=18580.9, ups=0.57, wpb=32768, bsz=32, num_updates=42400, lr=0.0001152, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=63617
2023-10-19 22:45:14 | INFO | train_inner | epoch 001:  42571 / 1830643 loss=3.392, ppl=10.5, wps=18622.4, ups=0.57, wpb=32768, bsz=32, num_updates=42500, lr=0.000115, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=63793
2023-10-19 22:48:09 | INFO | train_inner | epoch 001:  42671 / 1830643 loss=3.294, ppl=9.81, wps=18650.6, ups=0.57, wpb=32768, bsz=32, num_updates=42600, lr=0.0001148, gnorm=0.158, loss_scale=16, train_wall=175, gb_free=15.4, wall=63969
2023-10-19 22:50:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 22:51:08 | INFO | train_inner | epoch 001:  42772 / 1830643 loss=3.376, ppl=10.38, wps=18357.2, ups=0.56, wpb=32768, bsz=32, num_updates=42700, lr=0.0001146, gnorm=0.145, loss_scale=16, train_wall=178, gb_free=15.4, wall=64147
2023-10-19 22:54:06 | INFO | train_inner | epoch 001:  42872 / 1830643 loss=3.453, ppl=10.95, wps=18436, ups=0.56, wpb=32768, bsz=32, num_updates=42800, lr=0.0001144, gnorm=0.145, loss_scale=16, train_wall=177, gb_free=15.4, wall=64325
2023-10-19 22:57:02 | INFO | train_inner | epoch 001:  42972 / 1830643 loss=3.612, ppl=12.22, wps=18623.1, ups=0.57, wpb=32768, bsz=32, num_updates=42900, lr=0.0001142, gnorm=0.152, loss_scale=16, train_wall=176, gb_free=15.4, wall=64501
2023-10-19 22:59:57 | INFO | train_inner | epoch 001:  43072 / 1830643 loss=3.92, ppl=15.14, wps=18682.2, ups=0.57, wpb=32768, bsz=32, num_updates=43000, lr=0.000114, gnorm=0.148, loss_scale=16, train_wall=175, gb_free=15.4, wall=64676
2023-10-19 23:02:53 | INFO | train_inner | epoch 001:  43172 / 1830643 loss=3.362, ppl=10.28, wps=18633.4, ups=0.57, wpb=32768, bsz=32, num_updates=43100, lr=0.0001138, gnorm=0.148, loss_scale=16, train_wall=175, gb_free=15.4, wall=64852
2023-10-19 23:05:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-19 23:05:52 | INFO | train_inner | epoch 001:  43273 / 1830643 loss=3.432, ppl=10.79, wps=18300.1, ups=0.56, wpb=32768, bsz=32, num_updates=43200, lr=0.0001136, gnorm=0.153, loss_scale=16, train_wall=179, gb_free=15.4, wall=65031
2023-10-19 23:08:47 | INFO | train_inner | epoch 001:  43373 / 1830643 loss=3.383, ppl=10.43, wps=18693, ups=0.57, wpb=32768, bsz=32, num_updates=43300, lr=0.0001134, gnorm=0.152, loss_scale=16, train_wall=175, gb_free=15.4, wall=65206
2023-10-19 23:11:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 23:11:44 | INFO | train_inner | epoch 001:  43474 / 1830643 loss=3.477, ppl=11.13, wps=18489.2, ups=0.56, wpb=32768, bsz=32, num_updates=43400, lr=0.0001132, gnorm=0.175, loss_scale=8, train_wall=177, gb_free=15.4, wall=65384
2023-10-19 23:14:42 | INFO | train_inner | epoch 001:  43574 / 1830643 loss=3.486, ppl=11.2, wps=18455.1, ups=0.56, wpb=32768, bsz=32, num_updates=43500, lr=0.000113, gnorm=0.15, loss_scale=8, train_wall=177, gb_free=15.4, wall=65561
2023-10-19 23:17:39 | INFO | train_inner | epoch 001:  43674 / 1830643 loss=3.405, ppl=10.59, wps=18553, ups=0.57, wpb=32768, bsz=32, num_updates=43600, lr=0.0001128, gnorm=0.162, loss_scale=8, train_wall=176, gb_free=15.4, wall=65738
2023-10-19 23:20:35 | INFO | train_inner | epoch 001:  43774 / 1830643 loss=3.357, ppl=10.25, wps=18572.2, ups=0.57, wpb=32768, bsz=32, num_updates=43700, lr=0.0001126, gnorm=0.157, loss_scale=8, train_wall=176, gb_free=15.4, wall=65914
2023-10-19 23:23:31 | INFO | train_inner | epoch 001:  43874 / 1830643 loss=3.377, ppl=10.39, wps=18636.5, ups=0.57, wpb=32768, bsz=32, num_updates=43800, lr=0.0001124, gnorm=0.143, loss_scale=8, train_wall=175, gb_free=15.4, wall=66090
2023-10-19 23:26:27 | INFO | train_inner | epoch 001:  43974 / 1830643 loss=3.472, ppl=11.1, wps=18616.2, ups=0.57, wpb=32768, bsz=32, num_updates=43900, lr=0.0001122, gnorm=0.164, loss_scale=16, train_wall=176, gb_free=15.4, wall=66266
2023-10-19 23:29:23 | INFO | train_inner | epoch 001:  44074 / 1830643 loss=3.534, ppl=11.59, wps=18651.5, ups=0.57, wpb=32768, bsz=32, num_updates=44000, lr=0.000112, gnorm=0.149, loss_scale=16, train_wall=175, gb_free=15.4, wall=66442
2023-10-19 23:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-19 23:32:21 | INFO | train_inner | epoch 001:  44175 / 1830643 loss=3.443, ppl=10.88, wps=18386.8, ups=0.56, wpb=32768, bsz=32, num_updates=44100, lr=0.0001118, gnorm=0.154, loss_scale=8, train_wall=178, gb_free=15.4, wall=66620
2023-10-19 23:35:17 | INFO | train_inner | epoch 001:  44275 / 1830643 loss=3.454, ppl=10.96, wps=18556.8, ups=0.57, wpb=32768, bsz=32, num_updates=44200, lr=0.0001116, gnorm=0.17, loss_scale=8, train_wall=176, gb_free=15.4, wall=66797
2023-10-19 23:38:14 | INFO | train_inner | epoch 001:  44375 / 1830643 loss=3.417, ppl=10.68, wps=18512.6, ups=0.56, wpb=32768, bsz=32, num_updates=44300, lr=0.0001114, gnorm=0.148, loss_scale=8, train_wall=177, gb_free=15.4, wall=66974
2023-10-19 23:41:12 | INFO | train_inner | epoch 001:  44475 / 1830643 loss=3.344, ppl=10.15, wps=18452.2, ups=0.56, wpb=32768, bsz=32, num_updates=44400, lr=0.0001112, gnorm=0.149, loss_scale=8, train_wall=177, gb_free=15.4, wall=67151
2023-10-19 23:44:08 | INFO | train_inner | epoch 001:  44575 / 1830643 loss=3.402, ppl=10.57, wps=18641.2, ups=0.57, wpb=32768, bsz=32, num_updates=44500, lr=0.000111, gnorm=0.16, loss_scale=8, train_wall=175, gb_free=15.4, wall=67327
2023-10-19 23:47:03 | INFO | train_inner | epoch 001:  44675 / 1830643 loss=3.314, ppl=9.95, wps=18723.1, ups=0.57, wpb=32768, bsz=32, num_updates=44600, lr=0.0001108, gnorm=0.147, loss_scale=16, train_wall=175, gb_free=15.4, wall=67502
2023-10-19 23:49:58 | INFO | train_inner | epoch 001:  44775 / 1830643 loss=3.461, ppl=11.01, wps=18698.1, ups=0.57, wpb=32768, bsz=32, num_updates=44700, lr=0.0001106, gnorm=0.15, loss_scale=16, train_wall=175, gb_free=15.4, wall=67677
2023-10-19 23:52:54 | INFO | train_inner | epoch 001:  44875 / 1830643 loss=3.334, ppl=10.08, wps=18653.9, ups=0.57, wpb=32768, bsz=32, num_updates=44800, lr=0.0001104, gnorm=0.164, loss_scale=16, train_wall=175, gb_free=15.4, wall=67853
2023-10-19 23:55:51 | INFO | train_inner | epoch 001:  44975 / 1830643 loss=3.486, ppl=11.2, wps=18503.9, ups=0.56, wpb=32768, bsz=32, num_updates=44900, lr=0.0001102, gnorm=0.144, loss_scale=16, train_wall=177, gb_free=15.4, wall=68030
2023-10-19 23:58:47 | INFO | train_inner | epoch 001:  45075 / 1830643 loss=3.479, ppl=11.15, wps=18563.2, ups=0.57, wpb=32768, bsz=32, num_updates=45000, lr=0.00011, gnorm=0.168, loss_scale=16, train_wall=176, gb_free=15.4, wall=68207
2023-10-20 00:01:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 00:01:44 | INFO | train_inner | epoch 001:  45176 / 1830643 loss=3.513, ppl=11.42, wps=18517.4, ups=0.57, wpb=32768, bsz=32, num_updates=45100, lr=0.0001098, gnorm=0.158, loss_scale=16, train_wall=177, gb_free=15.4, wall=68383
2023-10-20 00:04:40 | INFO | train_inner | epoch 001:  45276 / 1830643 loss=3.516, ppl=11.44, wps=18595.6, ups=0.57, wpb=32768, bsz=32, num_updates=45200, lr=0.0001096, gnorm=0.162, loss_scale=16, train_wall=176, gb_free=15.4, wall=68560
2023-10-20 00:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 00:07:38 | INFO | train_inner | epoch 001:  45377 / 1830643 loss=3.211, ppl=9.26, wps=18484.4, ups=0.56, wpb=32768, bsz=32, num_updates=45300, lr=0.0001094, gnorm=0.152, loss_scale=8, train_wall=177, gb_free=15.4, wall=68737
2023-10-20 00:10:34 | INFO | train_inner | epoch 001:  45477 / 1830643 loss=2.862, ppl=7.27, wps=18545.2, ups=0.57, wpb=32768, bsz=32, num_updates=45400, lr=0.0001092, gnorm=0.162, loss_scale=8, train_wall=176, gb_free=15.4, wall=68914
2023-10-20 00:13:31 | INFO | train_inner | epoch 001:  45577 / 1830643 loss=3.307, ppl=9.9, wps=18601.1, ups=0.57, wpb=32768, bsz=32, num_updates=45500, lr=0.000109, gnorm=0.156, loss_scale=8, train_wall=176, gb_free=15.4, wall=69090
2023-10-20 00:16:28 | INFO | train_inner | epoch 001:  45677 / 1830643 loss=3.682, ppl=12.84, wps=18518, ups=0.57, wpb=32768, bsz=32, num_updates=45600, lr=0.0001088, gnorm=0.164, loss_scale=8, train_wall=177, gb_free=15.4, wall=69267
2023-10-20 00:19:25 | INFO | train_inner | epoch 001:  45777 / 1830643 loss=3.708, ppl=13.07, wps=18513.5, ups=0.56, wpb=32768, bsz=32, num_updates=45700, lr=0.0001086, gnorm=0.152, loss_scale=8, train_wall=177, gb_free=15.4, wall=69444
2023-10-20 00:22:21 | INFO | train_inner | epoch 001:  45877 / 1830643 loss=3.453, ppl=10.95, wps=18541.3, ups=0.57, wpb=32768, bsz=32, num_updates=45800, lr=0.0001084, gnorm=0.148, loss_scale=16, train_wall=176, gb_free=15.4, wall=69621
2023-10-20 00:25:18 | INFO | train_inner | epoch 001:  45977 / 1830643 loss=3.343, ppl=10.15, wps=18551.9, ups=0.57, wpb=32768, bsz=32, num_updates=45900, lr=0.0001082, gnorm=0.156, loss_scale=16, train_wall=176, gb_free=15.4, wall=69797
2023-10-20 00:28:13 | INFO | train_inner | epoch 001:  46077 / 1830643 loss=3.294, ppl=9.81, wps=18670.3, ups=0.57, wpb=32768, bsz=32, num_updates=46000, lr=0.000108, gnorm=0.153, loss_scale=16, train_wall=175, gb_free=15.4, wall=69973
2023-10-20 00:31:10 | INFO | train_inner | epoch 001:  46177 / 1830643 loss=3.351, ppl=10.2, wps=18582.5, ups=0.57, wpb=32768, bsz=32, num_updates=46100, lr=0.0001078, gnorm=0.157, loss_scale=16, train_wall=176, gb_free=15.4, wall=70149
2023-10-20 00:34:07 | INFO | train_inner | epoch 001:  46277 / 1830643 loss=3.285, ppl=9.75, wps=18528.6, ups=0.57, wpb=32768, bsz=32, num_updates=46200, lr=0.0001076, gnorm=0.158, loss_scale=16, train_wall=176, gb_free=15.4, wall=70326
2023-10-20 00:37:03 | INFO | train_inner | epoch 001:  46377 / 1830643 loss=3.516, ppl=11.44, wps=18583.2, ups=0.57, wpb=32768, bsz=32, num_updates=46300, lr=0.0001074, gnorm=0.149, loss_scale=32, train_wall=176, gb_free=15.4, wall=70502
2023-10-20 00:37:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 00:40:01 | INFO | train_inner | epoch 001:  46478 / 1830643 loss=3.564, ppl=11.83, wps=18358.3, ups=0.56, wpb=32768, bsz=32, num_updates=46400, lr=0.0001072, gnorm=0.186, loss_scale=16, train_wall=178, gb_free=15.4, wall=70681
2023-10-20 00:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 00:43:01 | INFO | train_inner | epoch 001:  46579 / 1830643 loss=3.446, ppl=10.9, wps=18256.4, ups=0.56, wpb=32768, bsz=32, num_updates=46500, lr=0.000107, gnorm=0.171, loss_scale=8, train_wall=179, gb_free=15.4, wall=70860
2023-10-20 00:45:57 | INFO | train_inner | epoch 001:  46679 / 1830643 loss=3.345, ppl=10.16, wps=18620.6, ups=0.57, wpb=32768, bsz=32, num_updates=46600, lr=0.0001068, gnorm=0.15, loss_scale=8, train_wall=176, gb_free=15.4, wall=71036
2023-10-20 00:48:53 | INFO | train_inner | epoch 001:  46779 / 1830643 loss=3.406, ppl=10.6, wps=18600, ups=0.57, wpb=32768, bsz=32, num_updates=46700, lr=0.0001066, gnorm=0.152, loss_scale=8, train_wall=176, gb_free=15.4, wall=71212
2023-10-20 00:51:48 | INFO | train_inner | epoch 001:  46879 / 1830643 loss=3.151, ppl=8.88, wps=18696.1, ups=0.57, wpb=32768, bsz=32, num_updates=46800, lr=0.0001064, gnorm=0.14, loss_scale=8, train_wall=175, gb_free=15.4, wall=71388
2023-10-20 00:54:45 | INFO | train_inner | epoch 001:  46979 / 1830643 loss=3.519, ppl=11.46, wps=18583.8, ups=0.57, wpb=32768, bsz=32, num_updates=46900, lr=0.0001062, gnorm=0.152, loss_scale=8, train_wall=176, gb_free=15.4, wall=71564
2023-10-20 00:57:41 | INFO | train_inner | epoch 001:  47079 / 1830643 loss=3.348, ppl=10.18, wps=18536.9, ups=0.57, wpb=32768, bsz=32, num_updates=47000, lr=0.000106, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=71741
2023-10-20 01:00:37 | INFO | train_inner | epoch 001:  47179 / 1830643 loss=3.459, ppl=11, wps=18659.1, ups=0.57, wpb=32768, bsz=32, num_updates=47100, lr=0.0001058, gnorm=0.147, loss_scale=16, train_wall=175, gb_free=15.4, wall=71916
2023-10-20 01:03:32 | INFO | train_inner | epoch 001:  47279 / 1830643 loss=3.487, ppl=11.21, wps=18767.8, ups=0.57, wpb=32768, bsz=32, num_updates=47200, lr=0.0001056, gnorm=0.146, loss_scale=16, train_wall=174, gb_free=15.4, wall=72091
2023-10-20 01:06:29 | INFO | train_inner | epoch 001:  47379 / 1830643 loss=3.424, ppl=10.74, wps=18469.2, ups=0.56, wpb=32768, bsz=32, num_updates=47300, lr=0.0001054, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=72268
2023-10-20 01:09:26 | INFO | train_inner | epoch 001:  47479 / 1830643 loss=3.394, ppl=10.51, wps=18536.8, ups=0.57, wpb=32768, bsz=32, num_updates=47400, lr=0.0001052, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=72445
2023-10-20 01:12:23 | INFO | train_inner | epoch 001:  47579 / 1830643 loss=3.535, ppl=11.59, wps=18444.2, ups=0.56, wpb=32768, bsz=32, num_updates=47500, lr=0.000105, gnorm=0.165, loss_scale=32, train_wall=177, gb_free=15.4, wall=72623
2023-10-20 01:12:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 01:15:22 | INFO | train_inner | epoch 001:  47680 / 1830643 loss=3.364, ppl=10.3, wps=18389.2, ups=0.56, wpb=32768, bsz=32, num_updates=47600, lr=0.0001048, gnorm=0.158, loss_scale=16, train_wall=178, gb_free=15.4, wall=72801
2023-10-20 01:16:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 01:18:19 | INFO | train_inner | epoch 001:  47781 / 1830643 loss=3.415, ppl=10.67, wps=18499.4, ups=0.56, wpb=32768, bsz=32, num_updates=47700, lr=0.0001046, gnorm=0.164, loss_scale=8, train_wall=177, gb_free=15.4, wall=72978
2023-10-20 01:21:14 | INFO | train_inner | epoch 001:  47881 / 1830643 loss=3.434, ppl=10.81, wps=18653.6, ups=0.57, wpb=32768, bsz=32, num_updates=47800, lr=0.0001044, gnorm=0.157, loss_scale=8, train_wall=175, gb_free=15.4, wall=73154
2023-10-20 01:24:08 | INFO | train_inner | epoch 001:  47981 / 1830643 loss=3.405, ppl=10.59, wps=18847.3, ups=0.58, wpb=32768, bsz=32, num_updates=47900, lr=0.0001042, gnorm=0.151, loss_scale=8, train_wall=173, gb_free=15.4, wall=73328
2023-10-20 01:27:05 | INFO | train_inner | epoch 001:  48081 / 1830643 loss=3.372, ppl=10.35, wps=18569.2, ups=0.57, wpb=32768, bsz=32, num_updates=48000, lr=0.000104, gnorm=0.152, loss_scale=8, train_wall=176, gb_free=15.4, wall=73504
2023-10-20 01:30:01 | INFO | train_inner | epoch 001:  48181 / 1830643 loss=3.621, ppl=12.3, wps=18598.1, ups=0.57, wpb=32768, bsz=32, num_updates=48100, lr=0.0001038, gnorm=0.158, loss_scale=8, train_wall=176, gb_free=15.4, wall=73680
2023-10-20 01:32:59 | INFO | train_inner | epoch 001:  48281 / 1830643 loss=3.376, ppl=10.38, wps=18440, ups=0.56, wpb=32768, bsz=32, num_updates=48200, lr=0.0001036, gnorm=0.154, loss_scale=16, train_wall=177, gb_free=15.4, wall=73858
2023-10-20 01:35:56 | INFO | train_inner | epoch 001:  48381 / 1830643 loss=3.449, ppl=10.92, wps=18511.7, ups=0.56, wpb=32768, bsz=32, num_updates=48300, lr=0.0001034, gnorm=0.153, loss_scale=16, train_wall=177, gb_free=15.4, wall=74035
2023-10-20 01:38:53 | INFO | train_inner | epoch 001:  48481 / 1830643 loss=3.519, ppl=11.46, wps=18530.6, ups=0.57, wpb=32768, bsz=32, num_updates=48400, lr=0.0001032, gnorm=0.16, loss_scale=16, train_wall=176, gb_free=15.4, wall=74212
2023-10-20 01:41:49 | INFO | train_inner | epoch 001:  48581 / 1830643 loss=3.66, ppl=12.64, wps=18588.6, ups=0.57, wpb=32768, bsz=32, num_updates=48500, lr=0.000103, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=74388
2023-10-20 01:44:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 01:44:47 | INFO | train_inner | epoch 001:  48682 / 1830643 loss=3.459, ppl=11, wps=18431.8, ups=0.56, wpb=32768, bsz=32, num_updates=48600, lr=0.0001028, gnorm=0.163, loss_scale=8, train_wall=177, gb_free=15.4, wall=74566
2023-10-20 01:47:43 | INFO | train_inner | epoch 001:  48782 / 1830643 loss=3.449, ppl=10.92, wps=18610.8, ups=0.57, wpb=32768, bsz=32, num_updates=48700, lr=0.0001026, gnorm=0.17, loss_scale=8, train_wall=176, gb_free=15.4, wall=74742
2023-10-20 01:50:37 | INFO | train_inner | epoch 001:  48882 / 1830643 loss=3.436, ppl=10.82, wps=18828, ups=0.57, wpb=32768, bsz=32, num_updates=48800, lr=0.0001024, gnorm=0.152, loss_scale=8, train_wall=174, gb_free=15.4, wall=74916
2023-10-20 01:53:31 | INFO | train_inner | epoch 001:  48982 / 1830643 loss=3.39, ppl=10.48, wps=18828.6, ups=0.57, wpb=32768, bsz=32, num_updates=48900, lr=0.0001022, gnorm=0.152, loss_scale=8, train_wall=174, gb_free=15.4, wall=75090
2023-10-20 01:56:26 | INFO | train_inner | epoch 001:  49082 / 1830643 loss=3.456, ppl=10.98, wps=18669.5, ups=0.57, wpb=32768, bsz=32, num_updates=49000, lr=0.000102, gnorm=0.162, loss_scale=8, train_wall=175, gb_free=15.4, wall=75266
2023-10-20 01:59:23 | INFO | train_inner | epoch 001:  49182 / 1830643 loss=3.159, ppl=8.93, wps=18588.9, ups=0.57, wpb=32768, bsz=32, num_updates=49100, lr=0.0001018, gnorm=0.147, loss_scale=16, train_wall=176, gb_free=15.4, wall=75442
2023-10-20 02:00:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 02:02:20 | INFO | train_inner | epoch 001:  49283 / 1830643 loss=3.38, ppl=10.41, wps=18506.9, ups=0.56, wpb=32768, bsz=32, num_updates=49200, lr=0.0001016, gnorm=0.154, loss_scale=8, train_wall=177, gb_free=15.4, wall=75619
2023-10-20 02:05:14 | INFO | train_inner | epoch 001:  49383 / 1830643 loss=3.458, ppl=10.99, wps=18755.1, ups=0.57, wpb=32768, bsz=32, num_updates=49300, lr=0.0001014, gnorm=0.146, loss_scale=8, train_wall=174, gb_free=15.4, wall=75794
2023-10-20 02:08:08 | INFO | train_inner | epoch 001:  49483 / 1830643 loss=3.431, ppl=10.79, wps=18819.1, ups=0.57, wpb=32768, bsz=32, num_updates=49400, lr=0.0001012, gnorm=0.151, loss_scale=8, train_wall=174, gb_free=15.4, wall=75968
2023-10-20 02:11:04 | INFO | train_inner | epoch 001:  49583 / 1830643 loss=3.404, ppl=10.58, wps=18633.8, ups=0.57, wpb=32768, bsz=32, num_updates=49500, lr=0.000101, gnorm=0.151, loss_scale=8, train_wall=175, gb_free=15.4, wall=76144
2023-10-20 02:13:58 | INFO | train_inner | epoch 001:  49683 / 1830643 loss=3.374, ppl=10.37, wps=18860.7, ups=0.58, wpb=32768, bsz=32, num_updates=49600, lr=0.0001008, gnorm=0.159, loss_scale=8, train_wall=173, gb_free=15.4, wall=76317
2023-10-20 02:16:54 | INFO | train_inner | epoch 001:  49783 / 1830643 loss=3.325, ppl=10.02, wps=18646.5, ups=0.57, wpb=32768, bsz=32, num_updates=49700, lr=0.0001006, gnorm=0.148, loss_scale=16, train_wall=175, gb_free=15.4, wall=76493
2023-10-20 02:19:50 | INFO | train_inner | epoch 001:  49883 / 1830643 loss=3.383, ppl=10.44, wps=18568.9, ups=0.57, wpb=32768, bsz=32, num_updates=49800, lr=0.0001004, gnorm=0.152, loss_scale=16, train_wall=176, gb_free=15.4, wall=76670
2023-10-20 02:22:46 | INFO | train_inner | epoch 001:  49983 / 1830643 loss=3.435, ppl=10.82, wps=18680.9, ups=0.57, wpb=32768, bsz=32, num_updates=49900, lr=0.0001002, gnorm=0.148, loss_scale=16, train_wall=175, gb_free=15.4, wall=76845
2023-10-20 02:25:40 | INFO | train_inner | epoch 001:  50083 / 1830643 loss=3.19, ppl=9.13, wps=18756.8, ups=0.57, wpb=32768, bsz=32, num_updates=50000, lr=0.0001, gnorm=0.147, loss_scale=16, train_wall=174, gb_free=15.4, wall=77020
2023-10-20 02:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 50000 updates
2023-10-20 02:25:40 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_50000.pt
2023-10-20 02:25:45 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_50000.pt
2023-10-20 02:25:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_50000.pt (epoch 1 @ 50000 updates, score None) (writing took 14.876193909207359 seconds)
2023-10-20 02:28:52 | INFO | train_inner | epoch 001:  50183 / 1830643 loss=3.395, ppl=10.52, wps=17102.3, ups=0.52, wpb=32768, bsz=32, num_updates=50100, lr=9.98e-05, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=77211
2023-10-20 02:31:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 02:31:51 | INFO | train_inner | epoch 001:  50284 / 1830643 loss=3.286, ppl=9.75, wps=18352.4, ups=0.56, wpb=32768, bsz=32, num_updates=50200, lr=9.96e-05, gnorm=0.147, loss_scale=16, train_wall=178, gb_free=15.4, wall=77390
2023-10-20 02:32:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 02:32:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 02:34:51 | INFO | train_inner | epoch 001:  50386 / 1830643 loss=3.489, ppl=11.23, wps=18139.7, ups=0.55, wpb=32768, bsz=32, num_updates=50300, lr=9.94e-05, gnorm=0.15, loss_scale=4, train_wall=180, gb_free=15.4, wall=77570
2023-10-20 02:37:48 | INFO | train_inner | epoch 001:  50486 / 1830643 loss=3.494, ppl=11.26, wps=18579.5, ups=0.57, wpb=32768, bsz=32, num_updates=50400, lr=9.92e-05, gnorm=0.156, loss_scale=4, train_wall=176, gb_free=15.4, wall=77747
2023-10-20 02:40:43 | INFO | train_inner | epoch 001:  50586 / 1830643 loss=3.406, ppl=10.6, wps=18663.1, ups=0.57, wpb=32768, bsz=32, num_updates=50500, lr=9.9e-05, gnorm=0.153, loss_scale=4, train_wall=175, gb_free=15.4, wall=77922
2023-10-20 02:43:40 | INFO | train_inner | epoch 001:  50686 / 1830643 loss=3.376, ppl=10.38, wps=18538, ups=0.57, wpb=32768, bsz=32, num_updates=50600, lr=9.88e-05, gnorm=0.144, loss_scale=4, train_wall=176, gb_free=15.4, wall=78099
2023-10-20 02:46:37 | INFO | train_inner | epoch 001:  50786 / 1830643 loss=3.439, ppl=10.84, wps=18492.3, ups=0.56, wpb=32768, bsz=32, num_updates=50700, lr=9.86e-05, gnorm=0.144, loss_scale=4, train_wall=177, gb_free=15.4, wall=78276
2023-10-20 02:49:32 | INFO | train_inner | epoch 001:  50886 / 1830643 loss=3.602, ppl=12.14, wps=18702.2, ups=0.57, wpb=32768, bsz=32, num_updates=50800, lr=9.84e-05, gnorm=0.148, loss_scale=8, train_wall=175, gb_free=15.4, wall=78452
2023-10-20 02:52:26 | INFO | train_inner | epoch 001:  50986 / 1830643 loss=3.386, ppl=10.45, wps=18850.8, ups=0.58, wpb=32768, bsz=32, num_updates=50900, lr=9.82e-05, gnorm=0.152, loss_scale=8, train_wall=173, gb_free=15.4, wall=78625
2023-10-20 02:55:20 | INFO | train_inner | epoch 001:  51086 / 1830643 loss=3.436, ppl=10.82, wps=18792.1, ups=0.57, wpb=32768, bsz=32, num_updates=51000, lr=9.8e-05, gnorm=0.147, loss_scale=8, train_wall=174, gb_free=15.4, wall=78800
2023-10-20 02:58:14 | INFO | train_inner | epoch 001:  51186 / 1830643 loss=3.419, ppl=10.69, wps=18896, ups=0.58, wpb=32768, bsz=32, num_updates=51100, lr=9.78e-05, gnorm=0.145, loss_scale=8, train_wall=173, gb_free=15.4, wall=78973
2023-10-20 03:01:08 | INFO | train_inner | epoch 001:  51286 / 1830643 loss=3.377, ppl=10.39, wps=18803.1, ups=0.57, wpb=32768, bsz=32, num_updates=51200, lr=9.76e-05, gnorm=0.149, loss_scale=8, train_wall=174, gb_free=15.4, wall=79147
2023-10-20 03:04:02 | INFO | train_inner | epoch 001:  51386 / 1830643 loss=3.466, ppl=11.05, wps=18898.6, ups=0.58, wpb=32768, bsz=32, num_updates=51300, lr=9.74e-05, gnorm=0.146, loss_scale=16, train_wall=173, gb_free=15.4, wall=79321
2023-10-20 03:06:57 | INFO | train_inner | epoch 001:  51486 / 1830643 loss=3.39, ppl=10.48, wps=18662.1, ups=0.57, wpb=32768, bsz=32, num_updates=51400, lr=9.72e-05, gnorm=0.149, loss_scale=16, train_wall=175, gb_free=15.4, wall=79496
2023-10-20 03:09:53 | INFO | train_inner | epoch 001:  51586 / 1830643 loss=3.438, ppl=10.84, wps=18665.2, ups=0.57, wpb=32768, bsz=32, num_updates=51500, lr=9.7e-05, gnorm=0.142, loss_scale=16, train_wall=175, gb_free=15.4, wall=79672
2023-10-20 03:12:48 | INFO | train_inner | epoch 001:  51686 / 1830643 loss=3.386, ppl=10.45, wps=18644.4, ups=0.57, wpb=32768, bsz=32, num_updates=51600, lr=9.68e-05, gnorm=0.152, loss_scale=16, train_wall=175, gb_free=15.4, wall=79848
2023-10-20 03:15:44 | INFO | train_inner | epoch 001:  51786 / 1830643 loss=3.317, ppl=9.97, wps=18660.8, ups=0.57, wpb=32768, bsz=32, num_updates=51700, lr=9.66e-05, gnorm=0.141, loss_scale=16, train_wall=175, gb_free=15.4, wall=80023
2023-10-20 03:17:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 03:18:41 | INFO | train_inner | epoch 001:  51887 / 1830643 loss=3.403, ppl=10.58, wps=18504, ups=0.56, wpb=32768, bsz=32, num_updates=51800, lr=9.64e-05, gnorm=0.157, loss_scale=8, train_wall=177, gb_free=15.4, wall=80200
2023-10-20 03:21:39 | INFO | train_inner | epoch 001:  51987 / 1830643 loss=3.513, ppl=11.42, wps=18437, ups=0.56, wpb=32768, bsz=32, num_updates=51900, lr=9.62e-05, gnorm=0.155, loss_scale=8, train_wall=177, gb_free=15.4, wall=80378
2023-10-20 03:24:35 | INFO | train_inner | epoch 001:  52087 / 1830643 loss=3.418, ppl=10.69, wps=18640.2, ups=0.57, wpb=32768, bsz=32, num_updates=52000, lr=9.6e-05, gnorm=0.142, loss_scale=8, train_wall=175, gb_free=15.4, wall=80554
2023-10-20 03:27:29 | INFO | train_inner | epoch 001:  52187 / 1830643 loss=3.229, ppl=9.38, wps=18758.6, ups=0.57, wpb=32768, bsz=32, num_updates=52100, lr=9.58e-05, gnorm=0.146, loss_scale=8, train_wall=174, gb_free=15.4, wall=80729
2023-10-20 03:30:26 | INFO | train_inner | epoch 001:  52287 / 1830643 loss=3.442, ppl=10.87, wps=18601, ups=0.57, wpb=32768, bsz=32, num_updates=52200, lr=9.56e-05, gnorm=0.15, loss_scale=8, train_wall=176, gb_free=15.4, wall=80905
2023-10-20 03:33:21 | INFO | train_inner | epoch 001:  52387 / 1830643 loss=3.55, ppl=11.72, wps=18675.9, ups=0.57, wpb=32768, bsz=32, num_updates=52300, lr=9.54e-05, gnorm=0.154, loss_scale=16, train_wall=175, gb_free=15.4, wall=81080
2023-10-20 03:36:17 | INFO | train_inner | epoch 001:  52487 / 1830643 loss=3.41, ppl=10.63, wps=18587.1, ups=0.57, wpb=32768, bsz=32, num_updates=52400, lr=9.52e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=81257
2023-10-20 03:39:13 | INFO | train_inner | epoch 001:  52587 / 1830643 loss=3.449, ppl=10.92, wps=18677.3, ups=0.57, wpb=32768, bsz=32, num_updates=52500, lr=9.5e-05, gnorm=0.154, loss_scale=16, train_wall=175, gb_free=15.4, wall=81432
2023-10-20 03:42:09 | INFO | train_inner | epoch 001:  52687 / 1830643 loss=3.374, ppl=10.37, wps=18556.7, ups=0.57, wpb=32768, bsz=32, num_updates=52600, lr=9.48e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=81609
2023-10-20 03:45:06 | INFO | train_inner | epoch 001:  52787 / 1830643 loss=3.339, ppl=10.12, wps=18592.7, ups=0.57, wpb=32768, bsz=32, num_updates=52700, lr=9.46e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=81785
2023-10-20 03:48:02 | INFO | train_inner | epoch 001:  52887 / 1830643 loss=3.405, ppl=10.59, wps=18607, ups=0.57, wpb=32768, bsz=32, num_updates=52800, lr=9.44e-05, gnorm=0.146, loss_scale=32, train_wall=176, gb_free=15.4, wall=81961
2023-10-20 03:49:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 03:50:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 03:51:02 | INFO | train_inner | epoch 001:  52989 / 1830643 loss=3.349, ppl=10.19, wps=18172.2, ups=0.55, wpb=32768, bsz=32, num_updates=52900, lr=9.42e-05, gnorm=0.156, loss_scale=8, train_wall=180, gb_free=15.4, wall=82141
2023-10-20 03:53:58 | INFO | train_inner | epoch 001:  53089 / 1830643 loss=3.206, ppl=9.23, wps=18593, ups=0.57, wpb=32768, bsz=32, num_updates=53000, lr=9.4e-05, gnorm=0.156, loss_scale=8, train_wall=176, gb_free=15.4, wall=82317
2023-10-20 03:56:54 | INFO | train_inner | epoch 001:  53189 / 1830643 loss=3.316, ppl=9.96, wps=18626.9, ups=0.57, wpb=32768, bsz=32, num_updates=53100, lr=9.38e-05, gnorm=0.157, loss_scale=8, train_wall=176, gb_free=15.4, wall=82493
2023-10-20 03:59:51 | INFO | train_inner | epoch 001:  53289 / 1830643 loss=3.571, ppl=11.89, wps=18546.1, ups=0.57, wpb=32768, bsz=32, num_updates=53200, lr=9.36e-05, gnorm=0.154, loss_scale=8, train_wall=176, gb_free=15.4, wall=82670
2023-10-20 04:02:47 | INFO | train_inner | epoch 001:  53389 / 1830643 loss=3.432, ppl=10.79, wps=18592.7, ups=0.57, wpb=32768, bsz=32, num_updates=53300, lr=9.34e-05, gnorm=0.151, loss_scale=8, train_wall=176, gb_free=15.4, wall=82846
2023-10-20 04:05:45 | INFO | train_inner | epoch 001:  53489 / 1830643 loss=3.421, ppl=10.71, wps=18443.5, ups=0.56, wpb=32768, bsz=32, num_updates=53400, lr=9.32e-05, gnorm=0.147, loss_scale=16, train_wall=177, gb_free=15.4, wall=83024
2023-10-20 04:08:40 | INFO | train_inner | epoch 001:  53589 / 1830643 loss=3.632, ppl=12.4, wps=18686.8, ups=0.57, wpb=32768, bsz=32, num_updates=53500, lr=9.3e-05, gnorm=0.146, loss_scale=16, train_wall=175, gb_free=15.4, wall=83199
2023-10-20 04:11:38 | INFO | train_inner | epoch 001:  53689 / 1830643 loss=3.695, ppl=12.95, wps=18451.8, ups=0.56, wpb=32768, bsz=32, num_updates=53600, lr=9.28e-05, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=83377
2023-10-20 04:14:34 | INFO | train_inner | epoch 001:  53789 / 1830643 loss=3.611, ppl=12.22, wps=18627.4, ups=0.57, wpb=32768, bsz=32, num_updates=53700, lr=9.26e-05, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=83553
2023-10-20 04:17:30 | INFO | train_inner | epoch 001:  53889 / 1830643 loss=3.456, ppl=10.97, wps=18595.6, ups=0.57, wpb=32768, bsz=32, num_updates=53800, lr=9.24e-05, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=83729
2023-10-20 04:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 04:20:27 | INFO | train_inner | epoch 001:  53990 / 1830643 loss=3.558, ppl=11.78, wps=18464.4, ups=0.56, wpb=32768, bsz=32, num_updates=53900, lr=9.22e-05, gnorm=0.167, loss_scale=8, train_wall=177, gb_free=15.4, wall=83907
2023-10-20 04:23:23 | INFO | train_inner | epoch 001:  54090 / 1830643 loss=3.575, ppl=11.92, wps=18601, ups=0.57, wpb=32768, bsz=32, num_updates=54000, lr=9.2e-05, gnorm=0.149, loss_scale=8, train_wall=176, gb_free=15.4, wall=84083
2023-10-20 04:26:20 | INFO | train_inner | epoch 001:  54190 / 1830643 loss=3.405, ppl=10.59, wps=18521.4, ups=0.57, wpb=32768, bsz=32, num_updates=54100, lr=9.18e-05, gnorm=0.15, loss_scale=8, train_wall=177, gb_free=15.4, wall=84260
2023-10-20 04:29:17 | INFO | train_inner | epoch 001:  54290 / 1830643 loss=3.544, ppl=11.66, wps=18561.5, ups=0.57, wpb=32768, bsz=32, num_updates=54200, lr=9.16e-05, gnorm=0.151, loss_scale=8, train_wall=176, gb_free=15.4, wall=84436
2023-10-20 04:32:12 | INFO | train_inner | epoch 001:  54390 / 1830643 loss=3.519, ppl=11.46, wps=18664.1, ups=0.57, wpb=32768, bsz=32, num_updates=54300, lr=9.14e-05, gnorm=0.148, loss_scale=8, train_wall=175, gb_free=15.4, wall=84612
2023-10-20 04:35:09 | INFO | train_inner | epoch 001:  54490 / 1830643 loss=3.632, ppl=12.4, wps=18603.6, ups=0.57, wpb=32768, bsz=32, num_updates=54400, lr=9.12e-05, gnorm=0.159, loss_scale=16, train_wall=176, gb_free=15.4, wall=84788
2023-10-20 04:38:04 | INFO | train_inner | epoch 001:  54590 / 1830643 loss=3.468, ppl=11.07, wps=18630.5, ups=0.57, wpb=32768, bsz=32, num_updates=54500, lr=9.1e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=84964
2023-10-20 04:41:01 | INFO | train_inner | epoch 001:  54690 / 1830643 loss=3.55, ppl=11.71, wps=18551.9, ups=0.57, wpb=32768, bsz=32, num_updates=54600, lr=9.08e-05, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=85140
2023-10-20 04:43:57 | INFO | train_inner | epoch 001:  54790 / 1830643 loss=3.537, ppl=11.61, wps=18591.5, ups=0.57, wpb=32768, bsz=32, num_updates=54700, lr=9.06e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=85317
2023-10-20 04:46:53 | INFO | train_inner | epoch 001:  54890 / 1830643 loss=3.333, ppl=10.08, wps=18634.4, ups=0.57, wpb=32768, bsz=32, num_updates=54800, lr=9.04e-05, gnorm=0.145, loss_scale=16, train_wall=175, gb_free=15.4, wall=85492
2023-10-20 04:47:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 04:49:51 | INFO | train_inner | epoch 001:  54991 / 1830643 loss=3.386, ppl=10.45, wps=18434.2, ups=0.56, wpb=32768, bsz=32, num_updates=54900, lr=9.02e-05, gnorm=0.155, loss_scale=16, train_wall=177, gb_free=15.4, wall=85670
2023-10-20 04:52:47 | INFO | train_inner | epoch 001:  55091 / 1830643 loss=3.351, ppl=10.2, wps=18629.7, ups=0.57, wpb=32768, bsz=32, num_updates=55000, lr=9e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=85846
2023-10-20 04:55:43 | INFO | train_inner | epoch 001:  55191 / 1830643 loss=3.454, ppl=10.96, wps=18606.8, ups=0.57, wpb=32768, bsz=32, num_updates=55100, lr=8.98e-05, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=86022
2023-10-20 04:58:40 | INFO | train_inner | epoch 001:  55291 / 1830643 loss=3.507, ppl=11.37, wps=18541.4, ups=0.57, wpb=32768, bsz=32, num_updates=55200, lr=8.96e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=86199
2023-10-20 05:01:36 | INFO | train_inner | epoch 001:  55391 / 1830643 loss=3.463, ppl=11.03, wps=18540.2, ups=0.57, wpb=32768, bsz=32, num_updates=55300, lr=8.94e-05, gnorm=0.155, loss_scale=16, train_wall=176, gb_free=15.4, wall=86376
2023-10-20 05:03:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 05:04:35 | INFO | train_inner | epoch 001:  55492 / 1830643 loss=3.285, ppl=9.75, wps=18403.9, ups=0.56, wpb=32768, bsz=32, num_updates=55400, lr=8.92e-05, gnorm=0.164, loss_scale=16, train_wall=178, gb_free=15.4, wall=86554
2023-10-20 05:07:31 | INFO | train_inner | epoch 001:  55592 / 1830643 loss=3.387, ppl=10.46, wps=18536.2, ups=0.57, wpb=32768, bsz=32, num_updates=55500, lr=8.9e-05, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=86731
2023-10-20 05:10:29 | INFO | train_inner | epoch 001:  55692 / 1830643 loss=3.478, ppl=11.14, wps=18483.8, ups=0.56, wpb=32768, bsz=32, num_updates=55600, lr=8.88e-05, gnorm=0.149, loss_scale=16, train_wall=177, gb_free=15.4, wall=86908
2023-10-20 05:13:25 | INFO | train_inner | epoch 001:  55792 / 1830643 loss=3.374, ppl=10.37, wps=18606.1, ups=0.57, wpb=32768, bsz=32, num_updates=55700, lr=8.86e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=87084
2023-10-20 05:16:21 | INFO | train_inner | epoch 001:  55892 / 1830643 loss=3.326, ppl=10.03, wps=18613.6, ups=0.57, wpb=32768, bsz=32, num_updates=55800, lr=8.84e-05, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=87260
2023-10-20 05:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 05:19:19 | INFO | train_inner | epoch 001:  55993 / 1830643 loss=3.677, ppl=12.79, wps=18332.6, ups=0.56, wpb=32768, bsz=32, num_updates=55900, lr=8.82e-05, gnorm=0.154, loss_scale=16, train_wall=178, gb_free=15.4, wall=87439
2023-10-20 05:22:16 | INFO | train_inner | epoch 001:  56093 / 1830643 loss=3.475, ppl=11.12, wps=18531.3, ups=0.57, wpb=32768, bsz=32, num_updates=56000, lr=8.8e-05, gnorm=0.148, loss_scale=16, train_wall=176, gb_free=15.4, wall=87616
2023-10-20 05:25:14 | INFO | train_inner | epoch 001:  56193 / 1830643 loss=3.674, ppl=12.76, wps=18481.3, ups=0.56, wpb=32768, bsz=32, num_updates=56100, lr=8.78e-05, gnorm=0.151, loss_scale=16, train_wall=177, gb_free=15.4, wall=87793
2023-10-20 05:28:11 | INFO | train_inner | epoch 001:  56293 / 1830643 loss=3.708, ppl=13.07, wps=18475.6, ups=0.56, wpb=32768, bsz=32, num_updates=56200, lr=8.76e-05, gnorm=0.16, loss_scale=16, train_wall=177, gb_free=15.4, wall=87970
2023-10-20 05:31:07 | INFO | train_inner | epoch 001:  56393 / 1830643 loss=3.485, ppl=11.19, wps=18619.6, ups=0.57, wpb=32768, bsz=32, num_updates=56300, lr=8.74e-05, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=88146
2023-10-20 05:34:03 | INFO | train_inner | epoch 001:  56493 / 1830643 loss=3.332, ppl=10.07, wps=18608.7, ups=0.57, wpb=32768, bsz=32, num_updates=56400, lr=8.72e-05, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=88322
2023-10-20 05:36:59 | INFO | train_inner | epoch 001:  56593 / 1830643 loss=3.337, ppl=10.11, wps=18660.1, ups=0.57, wpb=32768, bsz=32, num_updates=56500, lr=8.7e-05, gnorm=0.144, loss_scale=32, train_wall=175, gb_free=15.4, wall=88498
2023-10-20 05:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 05:39:57 | INFO | train_inner | epoch 001:  56694 / 1830643 loss=3.389, ppl=10.48, wps=18399.4, ups=0.56, wpb=32768, bsz=32, num_updates=56600, lr=8.68e-05, gnorm=0.146, loss_scale=16, train_wall=178, gb_free=15.4, wall=88676
2023-10-20 05:42:52 | INFO | train_inner | epoch 001:  56794 / 1830643 loss=3.615, ppl=12.25, wps=18703.3, ups=0.57, wpb=32768, bsz=32, num_updates=56700, lr=8.66e-05, gnorm=0.159, loss_scale=16, train_wall=175, gb_free=15.4, wall=88851
2023-10-20 05:45:48 | INFO | train_inner | epoch 001:  56894 / 1830643 loss=3.547, ppl=11.69, wps=18649.1, ups=0.57, wpb=32768, bsz=32, num_updates=56800, lr=8.64e-05, gnorm=0.149, loss_scale=16, train_wall=175, gb_free=15.4, wall=89027
2023-10-20 05:48:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 05:48:46 | INFO | train_inner | epoch 001:  56995 / 1830643 loss=3.344, ppl=10.15, wps=18373.5, ups=0.56, wpb=32768, bsz=32, num_updates=56900, lr=8.62e-05, gnorm=0.147, loss_scale=8, train_wall=178, gb_free=15.4, wall=89205
2023-10-20 05:51:42 | INFO | train_inner | epoch 001:  57095 / 1830643 loss=3.33, ppl=10.06, wps=18664.4, ups=0.57, wpb=32768, bsz=32, num_updates=57000, lr=8.6e-05, gnorm=0.155, loss_scale=8, train_wall=175, gb_free=15.4, wall=89381
2023-10-20 05:54:38 | INFO | train_inner | epoch 001:  57195 / 1830643 loss=3.315, ppl=9.95, wps=18525.7, ups=0.57, wpb=32768, bsz=32, num_updates=57100, lr=8.58e-05, gnorm=0.155, loss_scale=8, train_wall=176, gb_free=15.4, wall=89558
2023-10-20 05:57:35 | INFO | train_inner | epoch 001:  57295 / 1830643 loss=3.263, ppl=9.6, wps=18590.1, ups=0.57, wpb=32768, bsz=32, num_updates=57200, lr=8.56e-05, gnorm=0.138, loss_scale=8, train_wall=176, gb_free=15.4, wall=89734
2023-10-20 06:00:30 | INFO | train_inner | epoch 001:  57395 / 1830643 loss=3.418, ppl=10.69, wps=18644.7, ups=0.57, wpb=32768, bsz=32, num_updates=57300, lr=8.54e-05, gnorm=0.155, loss_scale=8, train_wall=175, gb_free=15.4, wall=89910
2023-10-20 06:03:26 | INFO | train_inner | epoch 001:  57495 / 1830643 loss=3.335, ppl=10.09, wps=18656.4, ups=0.57, wpb=32768, bsz=32, num_updates=57400, lr=8.52e-05, gnorm=0.157, loss_scale=8, train_wall=175, gb_free=15.4, wall=90085
2023-10-20 06:06:22 | INFO | train_inner | epoch 001:  57595 / 1830643 loss=3.448, ppl=10.91, wps=18604.9, ups=0.57, wpb=32768, bsz=32, num_updates=57500, lr=8.5e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=90261
2023-10-20 06:09:19 | INFO | train_inner | epoch 001:  57695 / 1830643 loss=3.423, ppl=10.72, wps=18500.2, ups=0.56, wpb=32768, bsz=32, num_updates=57600, lr=8.48e-05, gnorm=0.15, loss_scale=16, train_wall=177, gb_free=15.4, wall=90439
2023-10-20 06:12:15 | INFO | train_inner | epoch 001:  57795 / 1830643 loss=3.232, ppl=9.39, wps=18647.7, ups=0.57, wpb=32768, bsz=32, num_updates=57700, lr=8.46e-05, gnorm=0.149, loss_scale=16, train_wall=175, gb_free=15.4, wall=90614
2023-10-20 06:15:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 06:15:12 | INFO | train_inner | epoch 001:  57896 / 1830643 loss=3.552, ppl=11.73, wps=18487.3, ups=0.56, wpb=32768, bsz=32, num_updates=57800, lr=8.44e-05, gnorm=0.15, loss_scale=8, train_wall=177, gb_free=15.4, wall=90792
2023-10-20 06:18:09 | INFO | train_inner | epoch 001:  57996 / 1830643 loss=3.494, ppl=11.26, wps=18575.6, ups=0.57, wpb=32768, bsz=32, num_updates=57900, lr=8.42e-05, gnorm=0.146, loss_scale=8, train_wall=176, gb_free=15.4, wall=90968
2023-10-20 06:21:03 | INFO | train_inner | epoch 001:  58096 / 1830643 loss=3.334, ppl=10.09, wps=18823.7, ups=0.57, wpb=32768, bsz=32, num_updates=58000, lr=8.4e-05, gnorm=0.139, loss_scale=8, train_wall=174, gb_free=15.4, wall=91142
2023-10-20 06:23:59 | INFO | train_inner | epoch 001:  58196 / 1830643 loss=3.504, ppl=11.34, wps=18567.8, ups=0.57, wpb=32768, bsz=32, num_updates=58100, lr=8.38e-05, gnorm=0.156, loss_scale=8, train_wall=176, gb_free=15.4, wall=91319
2023-10-20 06:26:53 | INFO | train_inner | epoch 001:  58296 / 1830643 loss=3.512, ppl=11.41, wps=18891.1, ups=0.58, wpb=32768, bsz=32, num_updates=58200, lr=8.36e-05, gnorm=0.156, loss_scale=8, train_wall=173, gb_free=15.4, wall=91492
2023-10-20 06:29:47 | INFO | train_inner | epoch 001:  58396 / 1830643 loss=3.429, ppl=10.77, wps=18776, ups=0.57, wpb=32768, bsz=32, num_updates=58300, lr=8.34e-05, gnorm=0.149, loss_scale=8, train_wall=174, gb_free=15.4, wall=91667
2023-10-20 06:32:41 | INFO | train_inner | epoch 001:  58496 / 1830643 loss=3.152, ppl=8.89, wps=18837, ups=0.57, wpb=32768, bsz=32, num_updates=58400, lr=8.32e-05, gnorm=0.162, loss_scale=16, train_wall=174, gb_free=15.4, wall=91841
2023-10-20 06:35:36 | INFO | train_inner | epoch 001:  58596 / 1830643 loss=3.218, ppl=9.31, wps=18733.8, ups=0.57, wpb=32768, bsz=32, num_updates=58500, lr=8.3e-05, gnorm=0.151, loss_scale=16, train_wall=175, gb_free=15.4, wall=92015
2023-10-20 06:38:31 | INFO | train_inner | epoch 001:  58696 / 1830643 loss=3.237, ppl=9.43, wps=18772.6, ups=0.57, wpb=32768, bsz=32, num_updates=58600, lr=8.28e-05, gnorm=0.16, loss_scale=16, train_wall=174, gb_free=15.4, wall=92190
2023-10-20 06:41:26 | INFO | train_inner | epoch 001:  58796 / 1830643 loss=3.092, ppl=8.53, wps=18695.4, ups=0.57, wpb=32768, bsz=32, num_updates=58700, lr=8.26e-05, gnorm=0.15, loss_scale=16, train_wall=175, gb_free=15.4, wall=92365
2023-10-20 06:44:22 | INFO | train_inner | epoch 001:  58896 / 1830643 loss=3.242, ppl=9.46, wps=18605.4, ups=0.57, wpb=32768, bsz=32, num_updates=58800, lr=8.24e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=92541
2023-10-20 06:45:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 06:47:20 | INFO | train_inner | epoch 001:  58997 / 1830643 loss=3.661, ppl=12.65, wps=18450.2, ups=0.56, wpb=32768, bsz=32, num_updates=58900, lr=8.22e-05, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=92719
2023-10-20 06:50:17 | INFO | train_inner | epoch 001:  59097 / 1830643 loss=3.485, ppl=11.2, wps=18535.4, ups=0.57, wpb=32768, bsz=32, num_updates=59000, lr=8.2e-05, gnorm=0.143, loss_scale=16, train_wall=176, gb_free=15.4, wall=92896
2023-10-20 06:50:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 06:53:15 | INFO | train_inner | epoch 001:  59198 / 1830643 loss=3.647, ppl=12.53, wps=18330.7, ups=0.56, wpb=32768, bsz=32, num_updates=59100, lr=8.18e-05, gnorm=0.148, loss_scale=8, train_wall=178, gb_free=15.4, wall=93075
2023-10-20 06:56:11 | INFO | train_inner | epoch 001:  59298 / 1830643 loss=3.418, ppl=10.69, wps=18657.9, ups=0.57, wpb=32768, bsz=32, num_updates=59200, lr=8.16e-05, gnorm=0.145, loss_scale=8, train_wall=175, gb_free=15.4, wall=93250
2023-10-20 06:59:05 | INFO | train_inner | epoch 001:  59398 / 1830643 loss=3.162, ppl=8.95, wps=18780.2, ups=0.57, wpb=32768, bsz=32, num_updates=59300, lr=8.14e-05, gnorm=0.147, loss_scale=8, train_wall=174, gb_free=15.4, wall=93425
2023-10-20 07:02:02 | INFO | train_inner | epoch 001:  59498 / 1830643 loss=3.526, ppl=11.52, wps=18551.4, ups=0.57, wpb=32768, bsz=32, num_updates=59400, lr=8.12e-05, gnorm=0.149, loss_scale=8, train_wall=176, gb_free=15.4, wall=93601
2023-10-20 07:04:58 | INFO | train_inner | epoch 001:  59598 / 1830643 loss=3.463, ppl=11.03, wps=18592.4, ups=0.57, wpb=32768, bsz=32, num_updates=59500, lr=8.1e-05, gnorm=0.146, loss_scale=8, train_wall=176, gb_free=15.4, wall=93778
2023-10-20 07:07:54 | INFO | train_inner | epoch 001:  59698 / 1830643 loss=3.379, ppl=10.4, wps=18644.1, ups=0.57, wpb=32768, bsz=32, num_updates=59600, lr=8.08e-05, gnorm=0.152, loss_scale=16, train_wall=175, gb_free=15.4, wall=93953
2023-10-20 07:10:49 | INFO | train_inner | epoch 001:  59798 / 1830643 loss=3.442, ppl=10.87, wps=18762, ups=0.57, wpb=32768, bsz=32, num_updates=59700, lr=8.06e-05, gnorm=0.156, loss_scale=16, train_wall=174, gb_free=15.4, wall=94128
2023-10-20 07:13:43 | INFO | train_inner | epoch 001:  59898 / 1830643 loss=3.309, ppl=9.91, wps=18743.7, ups=0.57, wpb=32768, bsz=32, num_updates=59800, lr=8.04e-05, gnorm=0.145, loss_scale=16, train_wall=174, gb_free=15.4, wall=94303
2023-10-20 07:16:39 | INFO | train_inner | epoch 001:  59998 / 1830643 loss=3.31, ppl=9.91, wps=18709.4, ups=0.57, wpb=32768, bsz=32, num_updates=59900, lr=8.02e-05, gnorm=0.143, loss_scale=16, train_wall=175, gb_free=15.4, wall=94478
2023-10-20 07:19:35 | INFO | train_inner | epoch 001:  60098 / 1830643 loss=3.496, ppl=11.28, wps=18544.5, ups=0.57, wpb=32768, bsz=32, num_updates=60000, lr=8e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=94655
2023-10-20 07:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 60000 updates
2023-10-20 07:19:35 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_60000.pt
2023-10-20 07:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_60000.pt
2023-10-20 07:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_60000.pt (epoch 1 @ 60000 updates, score None) (writing took 14.901557720964774 seconds)
2023-10-20 07:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 07:22:48 | INFO | train_inner | epoch 001:  60199 / 1830643 loss=3.293, ppl=9.8, wps=17003.8, ups=0.52, wpb=32768, bsz=32, num_updates=60100, lr=7.98e-05, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=94847
2023-10-20 07:25:44 | INFO | train_inner | epoch 001:  60299 / 1830643 loss=3.511, ppl=11.4, wps=18577.1, ups=0.57, wpb=32768, bsz=32, num_updates=60200, lr=7.96e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=95024
2023-10-20 07:28:41 | INFO | train_inner | epoch 001:  60399 / 1830643 loss=3.347, ppl=10.17, wps=18594.4, ups=0.57, wpb=32768, bsz=32, num_updates=60300, lr=7.94e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=95200
2023-10-20 07:31:37 | INFO | train_inner | epoch 001:  60499 / 1830643 loss=3.357, ppl=10.24, wps=18606.5, ups=0.57, wpb=32768, bsz=32, num_updates=60400, lr=7.92e-05, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=95376
2023-10-20 07:34:33 | INFO | train_inner | epoch 001:  60599 / 1830643 loss=2.717, ppl=6.58, wps=18577.7, ups=0.57, wpb=32768, bsz=32, num_updates=60500, lr=7.9e-05, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=95552
2023-10-20 07:37:29 | INFO | train_inner | epoch 001:  60699 / 1830643 loss=2.914, ppl=7.54, wps=18616.8, ups=0.57, wpb=32768, bsz=32, num_updates=60600, lr=7.88e-05, gnorm=0.157, loss_scale=32, train_wall=176, gb_free=15.4, wall=95728
2023-10-20 07:39:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 07:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 07:40:27 | INFO | train_inner | epoch 001:  60801 / 1830643 loss=3.336, ppl=10.1, wps=18406.7, ups=0.56, wpb=32768, bsz=32, num_updates=60700, lr=7.86e-05, gnorm=0.142, loss_scale=8, train_wall=178, gb_free=15.4, wall=95906
2023-10-20 07:43:21 | INFO | train_inner | epoch 001:  60901 / 1830643 loss=3.452, ppl=10.94, wps=18855.7, ups=0.58, wpb=32768, bsz=32, num_updates=60800, lr=7.84e-05, gnorm=0.152, loss_scale=8, train_wall=173, gb_free=15.4, wall=96080
2023-10-20 07:46:17 | INFO | train_inner | epoch 001:  61001 / 1830643 loss=3.394, ppl=10.51, wps=18615.9, ups=0.57, wpb=32768, bsz=32, num_updates=60900, lr=7.82e-05, gnorm=0.157, loss_scale=8, train_wall=176, gb_free=15.4, wall=96256
2023-10-20 07:49:14 | INFO | train_inner | epoch 001:  61101 / 1830643 loss=3.478, ppl=11.14, wps=18551.7, ups=0.57, wpb=32768, bsz=32, num_updates=61000, lr=7.8e-05, gnorm=0.147, loss_scale=8, train_wall=176, gb_free=15.4, wall=96433
2023-10-20 07:52:11 | INFO | train_inner | epoch 001:  61201 / 1830643 loss=3.209, ppl=9.24, wps=18494.8, ups=0.56, wpb=32768, bsz=32, num_updates=61100, lr=7.78e-05, gnorm=0.158, loss_scale=8, train_wall=177, gb_free=15.4, wall=96610
2023-10-20 07:55:08 | INFO | train_inner | epoch 001:  61301 / 1830643 loss=2.766, ppl=6.8, wps=18496.5, ups=0.56, wpb=32768, bsz=32, num_updates=61200, lr=7.76e-05, gnorm=0.148, loss_scale=8, train_wall=177, gb_free=15.4, wall=96787
2023-10-20 07:58:05 | INFO | train_inner | epoch 001:  61401 / 1830643 loss=2.775, ppl=6.84, wps=18551.3, ups=0.57, wpb=32768, bsz=32, num_updates=61300, lr=7.74e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=96964
2023-10-20 08:01:01 | INFO | train_inner | epoch 001:  61501 / 1830643 loss=3.34, ppl=10.13, wps=18539.1, ups=0.57, wpb=32768, bsz=32, num_updates=61400, lr=7.72e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=97141
2023-10-20 08:03:58 | INFO | train_inner | epoch 001:  61601 / 1830643 loss=3.44, ppl=10.86, wps=18558.3, ups=0.57, wpb=32768, bsz=32, num_updates=61500, lr=7.7e-05, gnorm=0.147, loss_scale=16, train_wall=176, gb_free=15.4, wall=97317
2023-10-20 08:06:56 | INFO | train_inner | epoch 001:  61701 / 1830643 loss=3.173, ppl=9.02, wps=18447.9, ups=0.56, wpb=32768, bsz=32, num_updates=61600, lr=7.68e-05, gnorm=0.142, loss_scale=16, train_wall=177, gb_free=15.4, wall=97495
2023-10-20 08:09:53 | INFO | train_inner | epoch 001:  61801 / 1830643 loss=3.369, ppl=10.33, wps=18495, ups=0.56, wpb=32768, bsz=32, num_updates=61700, lr=7.66e-05, gnorm=0.15, loss_scale=16, train_wall=177, gb_free=15.4, wall=97672
2023-10-20 08:12:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 08:12:51 | INFO | train_inner | epoch 001:  61902 / 1830643 loss=3.495, ppl=11.27, wps=18353.3, ups=0.56, wpb=32768, bsz=32, num_updates=61800, lr=7.64e-05, gnorm=0.163, loss_scale=16, train_wall=178, gb_free=15.4, wall=97851
2023-10-20 08:15:48 | INFO | train_inner | epoch 001:  62002 / 1830643 loss=3.529, ppl=11.54, wps=18548.3, ups=0.57, wpb=32768, bsz=32, num_updates=61900, lr=7.62e-05, gnorm=0.154, loss_scale=16, train_wall=176, gb_free=15.4, wall=98027
2023-10-20 08:18:42 | INFO | train_inner | epoch 001:  62102 / 1830643 loss=3.345, ppl=10.16, wps=18779.7, ups=0.57, wpb=32768, bsz=32, num_updates=62000, lr=7.6e-05, gnorm=0.15, loss_scale=16, train_wall=174, gb_free=15.4, wall=98202
2023-10-20 08:21:37 | INFO | train_inner | epoch 001:  62202 / 1830643 loss=3.253, ppl=9.54, wps=18771.4, ups=0.57, wpb=32768, bsz=32, num_updates=62100, lr=7.58e-05, gnorm=0.152, loss_scale=16, train_wall=174, gb_free=15.4, wall=98376
2023-10-20 08:24:33 | INFO | train_inner | epoch 001:  62302 / 1830643 loss=3.408, ppl=10.61, wps=18600.2, ups=0.57, wpb=32768, bsz=32, num_updates=62200, lr=7.56e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=98552
2023-10-20 08:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 08:27:31 | INFO | train_inner | epoch 001:  62403 / 1830643 loss=3.462, ppl=11.02, wps=18446.2, ups=0.56, wpb=32768, bsz=32, num_updates=62300, lr=7.54e-05, gnorm=0.146, loss_scale=8, train_wall=177, gb_free=15.4, wall=98730
2023-10-20 08:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 08:28:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-20 08:30:32 | INFO | train_inner | epoch 001:  62505 / 1830643 loss=3.423, ppl=10.72, wps=18072.1, ups=0.55, wpb=32768, bsz=32, num_updates=62400, lr=7.52e-05, gnorm=0.165, loss_scale=2, train_wall=181, gb_free=15.4, wall=98911
2023-10-20 08:33:29 | INFO | train_inner | epoch 001:  62605 / 1830643 loss=3.42, ppl=10.7, wps=18537.2, ups=0.57, wpb=32768, bsz=32, num_updates=62500, lr=7.5e-05, gnorm=0.15, loss_scale=2, train_wall=176, gb_free=15.4, wall=99088
2023-10-20 08:36:26 | INFO | train_inner | epoch 001:  62705 / 1830643 loss=3.422, ppl=10.72, wps=18495.6, ups=0.56, wpb=32768, bsz=32, num_updates=62600, lr=7.48e-05, gnorm=0.155, loss_scale=2, train_wall=177, gb_free=15.4, wall=99265
2023-10-20 08:39:23 | INFO | train_inner | epoch 001:  62805 / 1830643 loss=3.36, ppl=10.27, wps=18486.5, ups=0.56, wpb=32768, bsz=32, num_updates=62700, lr=7.46e-05, gnorm=0.151, loss_scale=2, train_wall=177, gb_free=15.4, wall=99443
2023-10-20 08:42:20 | INFO | train_inner | epoch 001:  62905 / 1830643 loss=3.457, ppl=10.98, wps=18522.8, ups=0.57, wpb=32768, bsz=32, num_updates=62800, lr=7.44e-05, gnorm=0.139, loss_scale=2, train_wall=177, gb_free=15.4, wall=99619
2023-10-20 08:45:16 | INFO | train_inner | epoch 001:  63005 / 1830643 loss=3.414, ppl=10.66, wps=18642.1, ups=0.57, wpb=32768, bsz=32, num_updates=62900, lr=7.42e-05, gnorm=0.163, loss_scale=4, train_wall=175, gb_free=15.4, wall=99795
2023-10-20 08:48:13 | INFO | train_inner | epoch 001:  63105 / 1830643 loss=3.306, ppl=9.89, wps=18547.4, ups=0.57, wpb=32768, bsz=32, num_updates=63000, lr=7.4e-05, gnorm=0.151, loss_scale=4, train_wall=176, gb_free=15.4, wall=99972
2023-10-20 08:51:08 | INFO | train_inner | epoch 001:  63205 / 1830643 loss=3.307, ppl=9.9, wps=18650.5, ups=0.57, wpb=32768, bsz=32, num_updates=63100, lr=7.38e-05, gnorm=0.15, loss_scale=4, train_wall=175, gb_free=15.4, wall=100148
2023-10-20 08:54:03 | INFO | train_inner | epoch 001:  63305 / 1830643 loss=3.4, ppl=10.55, wps=18804, ups=0.57, wpb=32768, bsz=32, num_updates=63200, lr=7.36e-05, gnorm=0.158, loss_scale=4, train_wall=174, gb_free=15.4, wall=100322
2023-10-20 08:56:57 | INFO | train_inner | epoch 001:  63405 / 1830643 loss=3.486, ppl=11.2, wps=18831.9, ups=0.57, wpb=32768, bsz=32, num_updates=63300, lr=7.34e-05, gnorm=0.154, loss_scale=4, train_wall=174, gb_free=15.4, wall=100496
2023-10-20 08:59:51 | INFO | train_inner | epoch 001:  63505 / 1830643 loss=3.355, ppl=10.23, wps=18747.6, ups=0.57, wpb=32768, bsz=32, num_updates=63400, lr=7.32e-05, gnorm=0.141, loss_scale=8, train_wall=174, gb_free=15.4, wall=100671
2023-10-20 09:02:49 | INFO | train_inner | epoch 001:  63605 / 1830643 loss=3.317, ppl=9.97, wps=18473.5, ups=0.56, wpb=32768, bsz=32, num_updates=63500, lr=7.3e-05, gnorm=0.148, loss_scale=8, train_wall=177, gb_free=15.4, wall=100848
2023-10-20 09:05:45 | INFO | train_inner | epoch 001:  63705 / 1830643 loss=3.323, ppl=10.01, wps=18566.5, ups=0.57, wpb=32768, bsz=32, num_updates=63600, lr=7.28e-05, gnorm=0.143, loss_scale=8, train_wall=176, gb_free=15.4, wall=101025
2023-10-20 09:08:39 | INFO | train_inner | epoch 001:  63805 / 1830643 loss=3.358, ppl=10.26, wps=18861.5, ups=0.58, wpb=32768, bsz=32, num_updates=63700, lr=7.26e-05, gnorm=0.147, loss_scale=8, train_wall=173, gb_free=15.4, wall=101198
2023-10-20 09:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 09:11:37 | INFO | train_inner | epoch 001:  63906 / 1830643 loss=3.548, ppl=11.69, wps=18444.6, ups=0.56, wpb=32768, bsz=32, num_updates=63800, lr=7.24e-05, gnorm=0.163, loss_scale=4, train_wall=177, gb_free=15.4, wall=101376
2023-10-20 09:14:32 | INFO | train_inner | epoch 001:  64006 / 1830643 loss=3.435, ppl=10.82, wps=18696.2, ups=0.57, wpb=32768, bsz=32, num_updates=63900, lr=7.22e-05, gnorm=0.145, loss_scale=4, train_wall=175, gb_free=15.4, wall=101551
2023-10-20 09:17:27 | INFO | train_inner | epoch 001:  64106 / 1830643 loss=3.322, ppl=10, wps=18745.7, ups=0.57, wpb=32768, bsz=32, num_updates=64000, lr=7.2e-05, gnorm=0.139, loss_scale=4, train_wall=174, gb_free=15.4, wall=101726
2023-10-20 09:20:22 | INFO | train_inner | epoch 001:  64206 / 1830643 loss=3.372, ppl=10.35, wps=18738.6, ups=0.57, wpb=32768, bsz=32, num_updates=64100, lr=7.18e-05, gnorm=0.139, loss_scale=4, train_wall=174, gb_free=15.4, wall=101901
2023-10-20 09:23:18 | INFO | train_inner | epoch 001:  64306 / 1830643 loss=3.605, ppl=12.17, wps=18583.8, ups=0.57, wpb=32768, bsz=32, num_updates=64200, lr=7.16e-05, gnorm=0.149, loss_scale=4, train_wall=176, gb_free=15.4, wall=102077
2023-10-20 09:26:12 | INFO | train_inner | epoch 001:  64406 / 1830643 loss=3.401, ppl=10.56, wps=18833.8, ups=0.57, wpb=32768, bsz=32, num_updates=64300, lr=7.14e-05, gnorm=0.143, loss_scale=4, train_wall=174, gb_free=15.4, wall=102251
2023-10-20 09:29:07 | INFO | train_inner | epoch 001:  64506 / 1830643 loss=3.454, ppl=10.96, wps=18693.1, ups=0.57, wpb=32768, bsz=32, num_updates=64400, lr=7.12e-05, gnorm=0.151, loss_scale=8, train_wall=175, gb_free=15.4, wall=102426
2023-10-20 09:32:04 | INFO | train_inner | epoch 001:  64606 / 1830643 loss=3.687, ppl=12.88, wps=18565.8, ups=0.57, wpb=32768, bsz=32, num_updates=64500, lr=7.1e-05, gnorm=0.162, loss_scale=8, train_wall=176, gb_free=15.4, wall=102603
2023-10-20 09:34:59 | INFO | train_inner | epoch 001:  64706 / 1830643 loss=3.382, ppl=10.42, wps=18667.2, ups=0.57, wpb=32768, bsz=32, num_updates=64600, lr=7.08e-05, gnorm=0.151, loss_scale=8, train_wall=175, gb_free=15.4, wall=102779
2023-10-20 09:37:56 | INFO | train_inner | epoch 001:  64806 / 1830643 loss=3.269, ppl=9.64, wps=18493.1, ups=0.56, wpb=32768, bsz=32, num_updates=64700, lr=7.06e-05, gnorm=0.166, loss_scale=8, train_wall=177, gb_free=15.4, wall=102956
2023-10-20 09:40:53 | INFO | train_inner | epoch 001:  64906 / 1830643 loss=3.396, ppl=10.53, wps=18531.4, ups=0.57, wpb=32768, bsz=32, num_updates=64800, lr=7.04e-05, gnorm=0.167, loss_scale=8, train_wall=176, gb_free=15.4, wall=103133
2023-10-20 09:43:49 | INFO | train_inner | epoch 001:  65006 / 1830643 loss=3.345, ppl=10.16, wps=18636.9, ups=0.57, wpb=32768, bsz=32, num_updates=64900, lr=7.02e-05, gnorm=0.158, loss_scale=16, train_wall=175, gb_free=15.4, wall=103308
2023-10-20 09:46:43 | INFO | train_inner | epoch 001:  65106 / 1830643 loss=3.234, ppl=9.41, wps=18876.8, ups=0.58, wpb=32768, bsz=32, num_updates=65000, lr=7e-05, gnorm=0.15, loss_scale=16, train_wall=173, gb_free=15.4, wall=103482
2023-10-20 09:46:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 09:46:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 09:49:43 | INFO | train_inner | epoch 001:  65208 / 1830643 loss=3.23, ppl=9.39, wps=18167.5, ups=0.55, wpb=32768, bsz=32, num_updates=65100, lr=6.98e-05, gnorm=0.157, loss_scale=4, train_wall=180, gb_free=15.4, wall=103662
2023-10-20 09:52:40 | INFO | train_inner | epoch 001:  65308 / 1830643 loss=3.382, ppl=10.42, wps=18553.6, ups=0.57, wpb=32768, bsz=32, num_updates=65200, lr=6.96e-05, gnorm=0.157, loss_scale=4, train_wall=176, gb_free=15.4, wall=103839
2023-10-20 09:55:36 | INFO | train_inner | epoch 001:  65408 / 1830643 loss=3.221, ppl=9.32, wps=18551.9, ups=0.57, wpb=32768, bsz=32, num_updates=65300, lr=6.94e-05, gnorm=0.157, loss_scale=4, train_wall=176, gb_free=15.4, wall=104016
2023-10-20 09:58:32 | INFO | train_inner | epoch 001:  65508 / 1830643 loss=3.279, ppl=9.71, wps=18636.4, ups=0.57, wpb=32768, bsz=32, num_updates=65400, lr=6.92e-05, gnorm=0.156, loss_scale=4, train_wall=175, gb_free=15.4, wall=104191
2023-10-20 10:01:28 | INFO | train_inner | epoch 001:  65608 / 1830643 loss=3.421, ppl=10.71, wps=18598.1, ups=0.57, wpb=32768, bsz=32, num_updates=65500, lr=6.9e-05, gnorm=0.152, loss_scale=4, train_wall=176, gb_free=15.4, wall=104368
2023-10-20 10:04:25 | INFO | train_inner | epoch 001:  65708 / 1830643 loss=3.487, ppl=11.21, wps=18513.8, ups=0.56, wpb=32768, bsz=32, num_updates=65600, lr=6.88e-05, gnorm=0.145, loss_scale=8, train_wall=177, gb_free=15.4, wall=104545
2023-10-20 10:07:23 | INFO | train_inner | epoch 001:  65808 / 1830643 loss=3.437, ppl=10.83, wps=18486.4, ups=0.56, wpb=32768, bsz=32, num_updates=65700, lr=6.86e-05, gnorm=0.141, loss_scale=8, train_wall=177, gb_free=15.4, wall=104722
2023-10-20 10:10:20 | INFO | train_inner | epoch 001:  65908 / 1830643 loss=3.564, ppl=11.83, wps=18512.4, ups=0.56, wpb=32768, bsz=32, num_updates=65800, lr=6.84e-05, gnorm=0.156, loss_scale=8, train_wall=177, gb_free=15.4, wall=104899
2023-10-20 10:11:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 10:11:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-20 10:13:20 | INFO | train_inner | epoch 001:  66010 / 1830643 loss=3.927, ppl=15.21, wps=18165.4, ups=0.55, wpb=32768, bsz=32, num_updates=65900, lr=6.82e-05, gnorm=0.156, loss_scale=2, train_wall=180, gb_free=15.4, wall=105079
2023-10-20 10:16:14 | INFO | train_inner | epoch 001:  66110 / 1830643 loss=3.683, ppl=12.84, wps=18803.6, ups=0.57, wpb=32768, bsz=32, num_updates=66000, lr=6.8e-05, gnorm=0.161, loss_scale=2, train_wall=174, gb_free=15.4, wall=105254
2023-10-20 10:19:10 | INFO | train_inner | epoch 001:  66210 / 1830643 loss=3.389, ppl=10.47, wps=18681.5, ups=0.57, wpb=32768, bsz=32, num_updates=66100, lr=6.78e-05, gnorm=0.144, loss_scale=2, train_wall=175, gb_free=15.4, wall=105429
2023-10-20 10:22:06 | INFO | train_inner | epoch 001:  66310 / 1830643 loss=3.518, ppl=11.45, wps=18572.7, ups=0.57, wpb=32768, bsz=32, num_updates=66200, lr=6.76e-05, gnorm=0.156, loss_scale=2, train_wall=176, gb_free=15.4, wall=105605
2023-10-20 10:25:01 | INFO | train_inner | epoch 001:  66410 / 1830643 loss=3.405, ppl=10.6, wps=18763.4, ups=0.57, wpb=32768, bsz=32, num_updates=66300, lr=6.74e-05, gnorm=0.154, loss_scale=2, train_wall=174, gb_free=15.4, wall=105780
2023-10-20 10:27:55 | INFO | train_inner | epoch 001:  66510 / 1830643 loss=3.237, ppl=9.43, wps=18824.5, ups=0.57, wpb=32768, bsz=32, num_updates=66400, lr=6.72e-05, gnorm=0.152, loss_scale=4, train_wall=174, gb_free=15.4, wall=105954
2023-10-20 10:30:49 | INFO | train_inner | epoch 001:  66610 / 1830643 loss=3.7, ppl=13, wps=18774.5, ups=0.57, wpb=32768, bsz=32, num_updates=66500, lr=6.7e-05, gnorm=0.162, loss_scale=4, train_wall=174, gb_free=15.4, wall=106129
2023-10-20 10:33:47 | INFO | train_inner | epoch 001:  66710 / 1830643 loss=3.653, ppl=12.58, wps=18478.8, ups=0.56, wpb=32768, bsz=32, num_updates=66600, lr=6.68e-05, gnorm=0.153, loss_scale=4, train_wall=177, gb_free=15.4, wall=106306
2023-10-20 10:36:43 | INFO | train_inner | epoch 001:  66810 / 1830643 loss=3.57, ppl=11.87, wps=18545.5, ups=0.57, wpb=32768, bsz=32, num_updates=66700, lr=6.66e-05, gnorm=0.149, loss_scale=4, train_wall=176, gb_free=15.4, wall=106483
2023-10-20 10:39:40 | INFO | train_inner | epoch 001:  66910 / 1830643 loss=3.343, ppl=10.14, wps=18576.6, ups=0.57, wpb=32768, bsz=32, num_updates=66800, lr=6.64e-05, gnorm=0.143, loss_scale=4, train_wall=176, gb_free=15.4, wall=106659
2023-10-20 10:42:36 | INFO | train_inner | epoch 001:  67010 / 1830643 loss=3.34, ppl=10.13, wps=18611.5, ups=0.57, wpb=32768, bsz=32, num_updates=66900, lr=6.62e-05, gnorm=0.151, loss_scale=8, train_wall=176, gb_free=15.4, wall=106835
2023-10-20 10:45:32 | INFO | train_inner | epoch 001:  67110 / 1830643 loss=3.39, ppl=10.48, wps=18597.3, ups=0.57, wpb=32768, bsz=32, num_updates=67000, lr=6.6e-05, gnorm=0.142, loss_scale=8, train_wall=176, gb_free=15.4, wall=107011
2023-10-20 10:48:27 | INFO | train_inner | epoch 001:  67210 / 1830643 loss=3.405, ppl=10.59, wps=18719.9, ups=0.57, wpb=32768, bsz=32, num_updates=67100, lr=6.58e-05, gnorm=0.148, loss_scale=8, train_wall=175, gb_free=15.4, wall=107186
2023-10-20 10:51:23 | INFO | train_inner | epoch 001:  67310 / 1830643 loss=3.532, ppl=11.57, wps=18617.6, ups=0.57, wpb=32768, bsz=32, num_updates=67200, lr=6.56e-05, gnorm=0.146, loss_scale=8, train_wall=176, gb_free=15.4, wall=107362
2023-10-20 10:54:20 | INFO | train_inner | epoch 001:  67410 / 1830643 loss=3.409, ppl=10.62, wps=18535.8, ups=0.57, wpb=32768, bsz=32, num_updates=67300, lr=6.54e-05, gnorm=0.143, loss_scale=8, train_wall=176, gb_free=15.4, wall=107539
2023-10-20 10:57:16 | INFO | train_inner | epoch 001:  67510 / 1830643 loss=3.492, ppl=11.25, wps=18648.3, ups=0.57, wpb=32768, bsz=32, num_updates=67400, lr=6.52e-05, gnorm=0.142, loss_scale=16, train_wall=175, gb_free=15.4, wall=107715
2023-10-20 10:57:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 11:00:14 | INFO | train_inner | epoch 001:  67611 / 1830643 loss=3.392, ppl=10.5, wps=18356.6, ups=0.56, wpb=32768, bsz=32, num_updates=67500, lr=6.5e-05, gnorm=0.16, loss_scale=8, train_wall=178, gb_free=15.4, wall=107893
2023-10-20 11:03:10 | INFO | train_inner | epoch 001:  67711 / 1830643 loss=3.374, ppl=10.37, wps=18672.8, ups=0.57, wpb=32768, bsz=32, num_updates=67600, lr=6.48e-05, gnorm=0.143, loss_scale=8, train_wall=175, gb_free=15.4, wall=108069
2023-10-20 11:06:06 | INFO | train_inner | epoch 001:  67811 / 1830643 loss=3.292, ppl=9.79, wps=18550.2, ups=0.57, wpb=32768, bsz=32, num_updates=67700, lr=6.46e-05, gnorm=0.143, loss_scale=8, train_wall=176, gb_free=15.4, wall=108245
2023-10-20 11:09:03 | INFO | train_inner | epoch 001:  67911 / 1830643 loss=3.444, ppl=10.88, wps=18518, ups=0.57, wpb=32768, bsz=32, num_updates=67800, lr=6.44e-05, gnorm=0.143, loss_scale=8, train_wall=177, gb_free=15.4, wall=108422
2023-10-20 11:11:59 | INFO | train_inner | epoch 001:  68011 / 1830643 loss=3.375, ppl=10.37, wps=18629.3, ups=0.57, wpb=32768, bsz=32, num_updates=67900, lr=6.42e-05, gnorm=0.156, loss_scale=8, train_wall=176, gb_free=15.4, wall=108598
2023-10-20 11:14:56 | INFO | train_inner | epoch 001:  68111 / 1830643 loss=3.187, ppl=9.1, wps=18552.9, ups=0.57, wpb=32768, bsz=32, num_updates=68000, lr=6.4e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=108775
2023-10-20 11:17:52 | INFO | train_inner | epoch 001:  68211 / 1830643 loss=3.526, ppl=11.52, wps=18591.4, ups=0.57, wpb=32768, bsz=32, num_updates=68100, lr=6.38e-05, gnorm=0.162, loss_scale=16, train_wall=176, gb_free=15.4, wall=108951
2023-10-20 11:20:47 | INFO | train_inner | epoch 001:  68311 / 1830643 loss=3.471, ppl=11.09, wps=18675.7, ups=0.57, wpb=32768, bsz=32, num_updates=68200, lr=6.36e-05, gnorm=0.154, loss_scale=16, train_wall=175, gb_free=15.4, wall=109127
2023-10-20 11:23:42 | INFO | train_inner | epoch 001:  68411 / 1830643 loss=3.35, ppl=10.19, wps=18717.9, ups=0.57, wpb=32768, bsz=32, num_updates=68300, lr=6.34e-05, gnorm=0.142, loss_scale=16, train_wall=175, gb_free=15.4, wall=109302
2023-10-20 11:26:36 | INFO | train_inner | epoch 001:  68511 / 1830643 loss=2.785, ppl=6.89, wps=18902.4, ups=0.58, wpb=32768, bsz=32, num_updates=68400, lr=6.32e-05, gnorm=0.146, loss_scale=16, train_wall=173, gb_free=15.4, wall=109475
2023-10-20 11:29:32 | INFO | train_inner | epoch 001:  68611 / 1830643 loss=3.487, ppl=11.21, wps=18622, ups=0.57, wpb=32768, bsz=32, num_updates=68500, lr=6.3e-05, gnorm=0.147, loss_scale=32, train_wall=176, gb_free=15.4, wall=109651
2023-10-20 11:32:27 | INFO | train_inner | epoch 001:  68711 / 1830643 loss=3.538, ppl=11.62, wps=18726.8, ups=0.57, wpb=32768, bsz=32, num_updates=68600, lr=6.28e-05, gnorm=0.144, loss_scale=32, train_wall=175, gb_free=15.4, wall=109826
2023-10-20 11:35:23 | INFO | train_inner | epoch 001:  68811 / 1830643 loss=3.628, ppl=12.36, wps=18638.3, ups=0.57, wpb=32768, bsz=32, num_updates=68700, lr=6.26e-05, gnorm=0.143, loss_scale=32, train_wall=175, gb_free=15.4, wall=110002
2023-10-20 11:38:16 | INFO | train_inner | epoch 001:  68911 / 1830643 loss=3.625, ppl=12.34, wps=18868.5, ups=0.58, wpb=32768, bsz=32, num_updates=68800, lr=6.24e-05, gnorm=0.145, loss_scale=32, train_wall=173, gb_free=15.4, wall=110175
2023-10-20 11:41:12 | INFO | train_inner | epoch 001:  69011 / 1830643 loss=3.485, ppl=11.2, wps=18631.5, ups=0.57, wpb=32768, bsz=32, num_updates=68900, lr=6.22e-05, gnorm=0.146, loss_scale=32, train_wall=176, gb_free=15.4, wall=110351
2023-10-20 11:41:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 11:44:07 | INFO | train_inner | epoch 001:  69112 / 1830643 loss=3.463, ppl=11.03, wps=18720.9, ups=0.57, wpb=32768, bsz=32, num_updates=69000, lr=6.2e-05, gnorm=0.146, loss_scale=16, train_wall=175, gb_free=15.4, wall=110526
2023-10-20 11:47:02 | INFO | train_inner | epoch 001:  69212 / 1830643 loss=3.554, ppl=11.75, wps=18723.5, ups=0.57, wpb=32768, bsz=32, num_updates=69100, lr=6.18e-05, gnorm=0.146, loss_scale=16, train_wall=175, gb_free=15.4, wall=110701
2023-10-20 11:49:58 | INFO | train_inner | epoch 001:  69312 / 1830643 loss=3.571, ppl=11.88, wps=18658.6, ups=0.57, wpb=32768, bsz=32, num_updates=69200, lr=6.16e-05, gnorm=0.143, loss_scale=16, train_wall=175, gb_free=15.4, wall=110877
2023-10-20 11:52:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 11:52:54 | INFO | train_inner | epoch 001:  69413 / 1830643 loss=3.451, ppl=10.94, wps=18645.9, ups=0.57, wpb=32768, bsz=32, num_updates=69300, lr=6.14e-05, gnorm=0.145, loss_scale=8, train_wall=175, gb_free=15.4, wall=111053
2023-10-20 11:55:48 | INFO | train_inner | epoch 001:  69513 / 1830643 loss=3.576, ppl=11.93, wps=18759.8, ups=0.57, wpb=32768, bsz=32, num_updates=69400, lr=6.12e-05, gnorm=0.148, loss_scale=8, train_wall=174, gb_free=15.4, wall=111227
2023-10-20 11:58:44 | INFO | train_inner | epoch 001:  69613 / 1830643 loss=3.459, ppl=11, wps=18678.5, ups=0.57, wpb=32768, bsz=32, num_updates=69500, lr=6.1e-05, gnorm=0.143, loss_scale=8, train_wall=175, gb_free=15.4, wall=111403
2023-10-20 12:01:40 | INFO | train_inner | epoch 001:  69713 / 1830643 loss=3.597, ppl=12.1, wps=18599.7, ups=0.57, wpb=32768, bsz=32, num_updates=69600, lr=6.08e-05, gnorm=0.147, loss_scale=8, train_wall=176, gb_free=15.4, wall=111579
2023-10-20 12:04:35 | INFO | train_inner | epoch 001:  69813 / 1830643 loss=3.463, ppl=11.03, wps=18674.4, ups=0.57, wpb=32768, bsz=32, num_updates=69700, lr=6.06e-05, gnorm=0.149, loss_scale=8, train_wall=175, gb_free=15.4, wall=111755
2023-10-20 12:05:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 12:05:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-20 12:07:34 | INFO | train_inner | epoch 001:  69915 / 1830643 loss=3.512, ppl=11.41, wps=18360.6, ups=0.56, wpb=32768, bsz=32, num_updates=69800, lr=6.04e-05, gnorm=0.15, loss_scale=2, train_wall=178, gb_free=15.4, wall=111933
2023-10-20 12:10:28 | INFO | train_inner | epoch 001:  70015 / 1830643 loss=3.482, ppl=11.17, wps=18838.4, ups=0.57, wpb=32768, bsz=32, num_updates=69900, lr=6.02e-05, gnorm=0.149, loss_scale=2, train_wall=174, gb_free=15.4, wall=112107
2023-10-20 12:13:23 | INFO | train_inner | epoch 001:  70115 / 1830643 loss=3.502, ppl=11.33, wps=18713.9, ups=0.57, wpb=32768, bsz=32, num_updates=70000, lr=6e-05, gnorm=0.139, loss_scale=2, train_wall=175, gb_free=15.4, wall=112282
2023-10-20 12:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 70000 updates
2023-10-20 12:13:23 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_70000.pt
2023-10-20 12:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_70000.pt
2023-10-20 12:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_70000.pt (epoch 1 @ 70000 updates, score None) (writing took 15.01331734098494 seconds)
2023-10-20 12:16:34 | INFO | train_inner | epoch 001:  70215 / 1830643 loss=3.48, ppl=11.16, wps=17128.9, ups=0.52, wpb=32768, bsz=32, num_updates=70100, lr=5.98e-05, gnorm=0.14, loss_scale=2, train_wall=176, gb_free=15.4, wall=112473
2023-10-20 12:19:30 | INFO | train_inner | epoch 001:  70315 / 1830643 loss=3.522, ppl=11.49, wps=18616.1, ups=0.57, wpb=32768, bsz=32, num_updates=70200, lr=5.96e-05, gnorm=0.144, loss_scale=2, train_wall=176, gb_free=15.4, wall=112649
2023-10-20 12:22:26 | INFO | train_inner | epoch 001:  70415 / 1830643 loss=3.399, ppl=10.55, wps=18599.1, ups=0.57, wpb=32768, bsz=32, num_updates=70300, lr=5.94e-05, gnorm=0.152, loss_scale=4, train_wall=176, gb_free=15.4, wall=112826
2023-10-20 12:25:22 | INFO | train_inner | epoch 001:  70515 / 1830643 loss=3.324, ppl=10.02, wps=18631.4, ups=0.57, wpb=32768, bsz=32, num_updates=70400, lr=5.92e-05, gnorm=0.154, loss_scale=4, train_wall=176, gb_free=15.4, wall=113001
2023-10-20 12:28:18 | INFO | train_inner | epoch 001:  70615 / 1830643 loss=3.523, ppl=11.5, wps=18648.6, ups=0.57, wpb=32768, bsz=32, num_updates=70500, lr=5.9e-05, gnorm=0.147, loss_scale=4, train_wall=175, gb_free=15.4, wall=113177
2023-10-20 12:31:14 | INFO | train_inner | epoch 001:  70715 / 1830643 loss=3.478, ppl=11.14, wps=18639.3, ups=0.57, wpb=32768, bsz=32, num_updates=70600, lr=5.88e-05, gnorm=0.149, loss_scale=4, train_wall=175, gb_free=15.4, wall=113353
2023-10-20 12:34:09 | INFO | train_inner | epoch 001:  70815 / 1830643 loss=3.059, ppl=8.33, wps=18741.1, ups=0.57, wpb=32768, bsz=32, num_updates=70700, lr=5.86e-05, gnorm=0.146, loss_scale=4, train_wall=174, gb_free=15.4, wall=113528
2023-10-20 12:37:04 | INFO | train_inner | epoch 001:  70915 / 1830643 loss=3.443, ppl=10.87, wps=18635, ups=0.57, wpb=32768, bsz=32, num_updates=70800, lr=5.84e-05, gnorm=0.144, loss_scale=8, train_wall=175, gb_free=15.4, wall=113704
2023-10-20 12:40:00 | INFO | train_inner | epoch 001:  71015 / 1830643 loss=3.365, ppl=10.3, wps=18664, ups=0.57, wpb=32768, bsz=32, num_updates=70900, lr=5.82e-05, gnorm=0.141, loss_scale=8, train_wall=175, gb_free=15.4, wall=113879
2023-10-20 12:42:56 | INFO | train_inner | epoch 001:  71115 / 1830643 loss=3.493, ppl=11.26, wps=18614.7, ups=0.57, wpb=32768, bsz=32, num_updates=71000, lr=5.8e-05, gnorm=0.142, loss_scale=8, train_wall=176, gb_free=15.4, wall=114055
2023-10-20 12:45:52 | INFO | train_inner | epoch 001:  71215 / 1830643 loss=3.796, ppl=13.89, wps=18642.3, ups=0.57, wpb=32768, bsz=32, num_updates=71100, lr=5.78e-05, gnorm=0.138, loss_scale=8, train_wall=175, gb_free=15.4, wall=114231
2023-10-20 12:48:48 | INFO | train_inner | epoch 001:  71315 / 1830643 loss=3.306, ppl=9.89, wps=18589.2, ups=0.57, wpb=32768, bsz=32, num_updates=71200, lr=5.76e-05, gnorm=0.15, loss_scale=8, train_wall=176, gb_free=15.4, wall=114407
2023-10-20 12:51:44 | INFO | train_inner | epoch 001:  71415 / 1830643 loss=3.162, ppl=8.95, wps=18604.2, ups=0.57, wpb=32768, bsz=32, num_updates=71300, lr=5.74e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=114583
2023-10-20 12:54:38 | INFO | train_inner | epoch 001:  71515 / 1830643 loss=3.433, ppl=10.8, wps=18806.9, ups=0.57, wpb=32768, bsz=32, num_updates=71400, lr=5.72e-05, gnorm=0.143, loss_scale=16, train_wall=174, gb_free=15.4, wall=114758
2023-10-20 12:57:34 | INFO | train_inner | epoch 001:  71615 / 1830643 loss=3.427, ppl=10.76, wps=18652.9, ups=0.57, wpb=32768, bsz=32, num_updates=71500, lr=5.7e-05, gnorm=0.139, loss_scale=16, train_wall=175, gb_free=15.4, wall=114933
2023-10-20 13:00:30 | INFO | train_inner | epoch 001:  71715 / 1830643 loss=3.289, ppl=9.77, wps=18609.4, ups=0.57, wpb=32768, bsz=32, num_updates=71600, lr=5.68e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=115109
2023-10-20 13:03:25 | INFO | train_inner | epoch 001:  71815 / 1830643 loss=3.441, ppl=10.86, wps=18787.4, ups=0.57, wpb=32768, bsz=32, num_updates=71700, lr=5.66e-05, gnorm=0.151, loss_scale=16, train_wall=174, gb_free=15.4, wall=115284
2023-10-20 13:06:19 | INFO | train_inner | epoch 001:  71915 / 1830643 loss=3.219, ppl=9.31, wps=18771.1, ups=0.57, wpb=32768, bsz=32, num_updates=71800, lr=5.64e-05, gnorm=0.152, loss_scale=32, train_wall=174, gb_free=15.4, wall=115458
2023-10-20 13:09:15 | INFO | train_inner | epoch 001:  72015 / 1830643 loss=3.231, ppl=9.39, wps=18601, ups=0.57, wpb=32768, bsz=32, num_updates=71900, lr=5.62e-05, gnorm=0.145, loss_scale=32, train_wall=176, gb_free=15.4, wall=115635
2023-10-20 13:12:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 13:12:11 | INFO | train_inner | epoch 001:  72116 / 1830643 loss=3.337, ppl=10.1, wps=18623.7, ups=0.57, wpb=32768, bsz=32, num_updates=72000, lr=5.6e-05, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=115810
2023-10-20 13:15:08 | INFO | train_inner | epoch 001:  72216 / 1830643 loss=3.409, ppl=10.62, wps=18565.8, ups=0.57, wpb=32768, bsz=32, num_updates=72100, lr=5.58e-05, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=115987
2023-10-20 13:18:04 | INFO | train_inner | epoch 001:  72316 / 1830643 loss=3.453, ppl=10.95, wps=18542, ups=0.57, wpb=32768, bsz=32, num_updates=72200, lr=5.56e-05, gnorm=0.143, loss_scale=16, train_wall=176, gb_free=15.4, wall=116164
2023-10-20 13:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 13:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 13:21:05 | INFO | train_inner | epoch 001:  72418 / 1830643 loss=3.511, ppl=11.4, wps=18143.7, ups=0.55, wpb=32768, bsz=32, num_updates=72300, lr=5.54e-05, gnorm=0.158, loss_scale=4, train_wall=180, gb_free=15.4, wall=116344
2023-10-20 13:24:02 | INFO | train_inner | epoch 001:  72518 / 1830643 loss=3.246, ppl=9.49, wps=18513.7, ups=0.56, wpb=32768, bsz=32, num_updates=72400, lr=5.52e-05, gnorm=0.144, loss_scale=4, train_wall=177, gb_free=15.4, wall=116521
2023-10-20 13:26:58 | INFO | train_inner | epoch 001:  72618 / 1830643 loss=3.354, ppl=10.22, wps=18608.9, ups=0.57, wpb=32768, bsz=32, num_updates=72500, lr=5.5e-05, gnorm=0.142, loss_scale=4, train_wall=176, gb_free=15.4, wall=116697
2023-10-20 13:29:55 | INFO | train_inner | epoch 001:  72718 / 1830643 loss=3.218, ppl=9.31, wps=18480.5, ups=0.56, wpb=32768, bsz=32, num_updates=72600, lr=5.48e-05, gnorm=0.146, loss_scale=4, train_wall=177, gb_free=15.4, wall=116875
2023-10-20 13:32:51 | INFO | train_inner | epoch 001:  72818 / 1830643 loss=3.233, ppl=9.4, wps=18716.6, ups=0.57, wpb=32768, bsz=32, num_updates=72700, lr=5.46e-05, gnorm=0.147, loss_scale=4, train_wall=175, gb_free=15.4, wall=117050
2023-10-20 13:35:46 | INFO | train_inner | epoch 001:  72918 / 1830643 loss=3.43, ppl=10.78, wps=18631.9, ups=0.57, wpb=32768, bsz=32, num_updates=72800, lr=5.44e-05, gnorm=0.15, loss_scale=8, train_wall=175, gb_free=15.4, wall=117226
2023-10-20 13:38:42 | INFO | train_inner | epoch 001:  73018 / 1830643 loss=3.388, ppl=10.47, wps=18699.3, ups=0.57, wpb=32768, bsz=32, num_updates=72900, lr=5.42e-05, gnorm=0.152, loss_scale=8, train_wall=175, gb_free=15.4, wall=117401
2023-10-20 13:41:39 | INFO | train_inner | epoch 001:  73118 / 1830643 loss=3.382, ppl=10.43, wps=18444.5, ups=0.56, wpb=32768, bsz=32, num_updates=73000, lr=5.4e-05, gnorm=0.146, loss_scale=8, train_wall=177, gb_free=15.4, wall=117579
2023-10-20 13:44:35 | INFO | train_inner | epoch 001:  73218 / 1830643 loss=3.484, ppl=11.19, wps=18636.2, ups=0.57, wpb=32768, bsz=32, num_updates=73100, lr=5.38e-05, gnorm=0.145, loss_scale=8, train_wall=175, gb_free=15.4, wall=117754
2023-10-20 13:47:32 | INFO | train_inner | epoch 001:  73318 / 1830643 loss=3.352, ppl=10.21, wps=18540.2, ups=0.57, wpb=32768, bsz=32, num_updates=73200, lr=5.36e-05, gnorm=0.149, loss_scale=8, train_wall=176, gb_free=15.4, wall=117931
2023-10-20 13:50:28 | INFO | train_inner | epoch 001:  73418 / 1830643 loss=3.53, ppl=11.55, wps=18602.4, ups=0.57, wpb=32768, bsz=32, num_updates=73300, lr=5.34e-05, gnorm=0.151, loss_scale=16, train_wall=176, gb_free=15.4, wall=118107
2023-10-20 13:52:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 13:53:26 | INFO | train_inner | epoch 001:  73519 / 1830643 loss=3.287, ppl=9.76, wps=18402.1, ups=0.56, wpb=32768, bsz=32, num_updates=73400, lr=5.32e-05, gnorm=0.139, loss_scale=8, train_wall=178, gb_free=15.4, wall=118285
2023-10-20 13:56:22 | INFO | train_inner | epoch 001:  73619 / 1830643 loss=3.364, ppl=10.3, wps=18627, ups=0.57, wpb=32768, bsz=32, num_updates=73500, lr=5.3e-05, gnorm=0.148, loss_scale=8, train_wall=176, gb_free=15.4, wall=118461
2023-10-20 13:59:19 | INFO | train_inner | epoch 001:  73719 / 1830643 loss=3.456, ppl=10.97, wps=18540.8, ups=0.57, wpb=32768, bsz=32, num_updates=73600, lr=5.28e-05, gnorm=0.146, loss_scale=8, train_wall=176, gb_free=15.4, wall=118638
2023-10-20 14:02:14 | INFO | train_inner | epoch 001:  73819 / 1830643 loss=3.283, ppl=9.73, wps=18661.9, ups=0.57, wpb=32768, bsz=32, num_updates=73700, lr=5.26e-05, gnorm=0.149, loss_scale=8, train_wall=175, gb_free=15.4, wall=118814
2023-10-20 14:05:11 | INFO | train_inner | epoch 001:  73919 / 1830643 loss=3.424, ppl=10.74, wps=18523.2, ups=0.57, wpb=32768, bsz=32, num_updates=73800, lr=5.24e-05, gnorm=0.188, loss_scale=8, train_wall=177, gb_free=15.4, wall=118991
2023-10-20 14:08:08 | INFO | train_inner | epoch 001:  74019 / 1830643 loss=3.55, ppl=11.71, wps=18535.7, ups=0.57, wpb=32768, bsz=32, num_updates=73900, lr=5.22e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=119167
2023-10-20 14:11:04 | INFO | train_inner | epoch 001:  74119 / 1830643 loss=3.356, ppl=10.24, wps=18642.4, ups=0.57, wpb=32768, bsz=32, num_updates=74000, lr=5.2e-05, gnorm=0.144, loss_scale=16, train_wall=175, gb_free=15.4, wall=119343
2023-10-20 14:14:00 | INFO | train_inner | epoch 001:  74219 / 1830643 loss=3.266, ppl=9.62, wps=18547.3, ups=0.57, wpb=32768, bsz=32, num_updates=74100, lr=5.18e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=119520
2023-10-20 14:14:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 14:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 14:17:00 | INFO | train_inner | epoch 001:  74321 / 1830643 loss=3.421, ppl=10.71, wps=18301, ups=0.56, wpb=32768, bsz=32, num_updates=74200, lr=5.16e-05, gnorm=0.152, loss_scale=4, train_wall=179, gb_free=15.4, wall=119699
2023-10-20 14:19:56 | INFO | train_inner | epoch 001:  74421 / 1830643 loss=3.185, ppl=9.09, wps=18551.8, ups=0.57, wpb=32768, bsz=32, num_updates=74300, lr=5.14e-05, gnorm=0.143, loss_scale=4, train_wall=176, gb_free=15.4, wall=119875
2023-10-20 14:22:52 | INFO | train_inner | epoch 001:  74521 / 1830643 loss=3.36, ppl=10.26, wps=18624.7, ups=0.57, wpb=32768, bsz=32, num_updates=74400, lr=5.12e-05, gnorm=0.144, loss_scale=4, train_wall=176, gb_free=15.4, wall=120051
2023-10-20 14:25:48 | INFO | train_inner | epoch 001:  74621 / 1830643 loss=3.395, ppl=10.52, wps=18586.5, ups=0.57, wpb=32768, bsz=32, num_updates=74500, lr=5.1e-05, gnorm=0.15, loss_scale=4, train_wall=176, gb_free=15.4, wall=120228
2023-10-20 14:28:44 | INFO | train_inner | epoch 001:  74721 / 1830643 loss=3.178, ppl=9.05, wps=18631.9, ups=0.57, wpb=32768, bsz=32, num_updates=74600, lr=5.08e-05, gnorm=0.143, loss_scale=4, train_wall=176, gb_free=15.4, wall=120404
2023-10-20 14:31:40 | INFO | train_inner | epoch 001:  74821 / 1830643 loss=3.315, ppl=9.95, wps=18615.5, ups=0.57, wpb=32768, bsz=32, num_updates=74700, lr=5.06e-05, gnorm=0.143, loss_scale=8, train_wall=176, gb_free=15.4, wall=120580
2023-10-20 14:34:36 | INFO | train_inner | epoch 001:  74921 / 1830643 loss=3.245, ppl=9.48, wps=18618.1, ups=0.57, wpb=32768, bsz=32, num_updates=74800, lr=5.04e-05, gnorm=0.146, loss_scale=8, train_wall=176, gb_free=15.4, wall=120756
2023-10-20 14:37:33 | INFO | train_inner | epoch 001:  75021 / 1830643 loss=3.151, ppl=8.89, wps=18537.5, ups=0.57, wpb=32768, bsz=32, num_updates=74900, lr=5.02e-05, gnorm=0.133, loss_scale=8, train_wall=176, gb_free=15.4, wall=120932
2023-10-20 14:40:29 | INFO | train_inner | epoch 001:  75121 / 1830643 loss=3.357, ppl=10.25, wps=18576.4, ups=0.57, wpb=32768, bsz=32, num_updates=75000, lr=5e-05, gnorm=0.144, loss_scale=8, train_wall=176, gb_free=15.4, wall=121109
2023-10-20 14:43:25 | INFO | train_inner | epoch 001:  75221 / 1830643 loss=3.333, ppl=10.08, wps=18656.4, ups=0.57, wpb=32768, bsz=32, num_updates=75100, lr=4.98e-05, gnorm=0.144, loss_scale=8, train_wall=175, gb_free=15.4, wall=121284
2023-10-20 14:46:21 | INFO | train_inner | epoch 001:  75321 / 1830643 loss=3.512, ppl=11.41, wps=18589, ups=0.57, wpb=32768, bsz=32, num_updates=75200, lr=4.96e-05, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=121461
2023-10-20 14:49:17 | INFO | train_inner | epoch 001:  75421 / 1830643 loss=3.334, ppl=10.08, wps=18629.2, ups=0.57, wpb=32768, bsz=32, num_updates=75300, lr=4.94e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=121637
2023-10-20 14:52:14 | INFO | train_inner | epoch 001:  75521 / 1830643 loss=3.386, ppl=10.45, wps=18590.9, ups=0.57, wpb=32768, bsz=32, num_updates=75400, lr=4.92e-05, gnorm=0.149, loss_scale=16, train_wall=176, gb_free=15.4, wall=121813
2023-10-20 14:55:09 | INFO | train_inner | epoch 001:  75621 / 1830643 loss=3.317, ppl=9.97, wps=18638.6, ups=0.57, wpb=32768, bsz=32, num_updates=75500, lr=4.9e-05, gnorm=0.138, loss_scale=16, train_wall=175, gb_free=15.4, wall=121989
2023-10-20 14:58:05 | INFO | train_inner | epoch 001:  75721 / 1830643 loss=3.409, ppl=10.63, wps=18635.3, ups=0.57, wpb=32768, bsz=32, num_updates=75600, lr=4.88e-05, gnorm=0.137, loss_scale=16, train_wall=175, gb_free=15.4, wall=122164
2023-10-20 15:00:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 15:01:03 | INFO | train_inner | epoch 001:  75822 / 1830643 loss=3.27, ppl=9.65, wps=18414.4, ups=0.56, wpb=32768, bsz=32, num_updates=75700, lr=4.86e-05, gnorm=0.145, loss_scale=16, train_wall=178, gb_free=15.4, wall=122342
2023-10-20 15:03:59 | INFO | train_inner | epoch 001:  75922 / 1830643 loss=3.328, ppl=10.04, wps=18635.2, ups=0.57, wpb=32768, bsz=32, num_updates=75800, lr=4.84e-05, gnorm=0.145, loss_scale=16, train_wall=175, gb_free=15.4, wall=122518
2023-10-20 15:06:55 | INFO | train_inner | epoch 001:  76022 / 1830643 loss=3.416, ppl=10.67, wps=18653, ups=0.57, wpb=32768, bsz=32, num_updates=75900, lr=4.82e-05, gnorm=0.151, loss_scale=16, train_wall=175, gb_free=15.4, wall=122694
2023-10-20 15:09:52 | INFO | train_inner | epoch 001:  76122 / 1830643 loss=3.31, ppl=9.92, wps=18507.4, ups=0.56, wpb=32768, bsz=32, num_updates=76000, lr=4.8e-05, gnorm=0.141, loss_scale=16, train_wall=177, gb_free=15.4, wall=122871
2023-10-20 15:12:49 | INFO | train_inner | epoch 001:  76222 / 1830643 loss=3.547, ppl=11.69, wps=18440.8, ups=0.56, wpb=32768, bsz=32, num_updates=76100, lr=4.78e-05, gnorm=0.145, loss_scale=16, train_wall=177, gb_free=15.4, wall=123049
2023-10-20 15:15:47 | INFO | train_inner | epoch 001:  76322 / 1830643 loss=3.392, ppl=10.49, wps=18504.3, ups=0.56, wpb=32768, bsz=32, num_updates=76200, lr=4.76e-05, gnorm=0.14, loss_scale=32, train_wall=177, gb_free=15.4, wall=123226
2023-10-20 15:16:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 15:18:44 | INFO | train_inner | epoch 001:  76423 / 1830643 loss=3.382, ppl=10.43, wps=18449.4, ups=0.56, wpb=32768, bsz=32, num_updates=76300, lr=4.74e-05, gnorm=0.14, loss_scale=16, train_wall=177, gb_free=15.4, wall=123403
2023-10-20 15:21:42 | INFO | train_inner | epoch 001:  76523 / 1830643 loss=3.487, ppl=11.21, wps=18435.3, ups=0.56, wpb=32768, bsz=32, num_updates=76400, lr=4.72e-05, gnorm=0.148, loss_scale=16, train_wall=177, gb_free=15.4, wall=123581
2023-10-20 15:24:39 | INFO | train_inner | epoch 001:  76623 / 1830643 loss=3.328, ppl=10.04, wps=18544.9, ups=0.57, wpb=32768, bsz=32, num_updates=76500, lr=4.7e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=123758
2023-10-20 15:27:34 | INFO | train_inner | epoch 001:  76723 / 1830643 loss=3.45, ppl=10.93, wps=18674.7, ups=0.57, wpb=32768, bsz=32, num_updates=76600, lr=4.68e-05, gnorm=0.15, loss_scale=16, train_wall=175, gb_free=15.4, wall=123933
2023-10-20 15:30:31 | INFO | train_inner | epoch 001:  76823 / 1830643 loss=3.359, ppl=10.26, wps=18479.8, ups=0.56, wpb=32768, bsz=32, num_updates=76700, lr=4.66e-05, gnorm=0.144, loss_scale=16, train_wall=177, gb_free=15.4, wall=124111
2023-10-20 15:33:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 15:33:29 | INFO | train_inner | epoch 001:  76924 / 1830643 loss=3.399, ppl=10.55, wps=18491.4, ups=0.56, wpb=32768, bsz=32, num_updates=76800, lr=4.64e-05, gnorm=0.147, loss_scale=16, train_wall=177, gb_free=15.4, wall=124288
2023-10-20 15:36:24 | INFO | train_inner | epoch 001:  77024 / 1830643 loss=3.259, ppl=9.57, wps=18666.2, ups=0.57, wpb=32768, bsz=32, num_updates=76900, lr=4.62e-05, gnorm=0.139, loss_scale=16, train_wall=175, gb_free=15.4, wall=124463
2023-10-20 15:39:21 | INFO | train_inner | epoch 001:  77124 / 1830643 loss=3.244, ppl=9.47, wps=18499.7, ups=0.56, wpb=32768, bsz=32, num_updates=77000, lr=4.6e-05, gnorm=0.138, loss_scale=16, train_wall=177, gb_free=15.4, wall=124641
2023-10-20 15:42:18 | INFO | train_inner | epoch 001:  77224 / 1830643 loss=3.359, ppl=10.26, wps=18551.2, ups=0.57, wpb=32768, bsz=32, num_updates=77100, lr=4.58e-05, gnorm=0.15, loss_scale=16, train_wall=176, gb_free=15.4, wall=124817
2023-10-20 15:45:14 | INFO | train_inner | epoch 001:  77324 / 1830643 loss=3.457, ppl=10.98, wps=18578.5, ups=0.57, wpb=32768, bsz=32, num_updates=77200, lr=4.56e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=124994
2023-10-20 15:48:11 | INFO | train_inner | epoch 001:  77424 / 1830643 loss=3.496, ppl=11.28, wps=18546.9, ups=0.57, wpb=32768, bsz=32, num_updates=77300, lr=4.54e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=125170
2023-10-20 15:49:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 15:51:10 | INFO | train_inner | epoch 001:  77525 / 1830643 loss=3.362, ppl=10.28, wps=18350.7, ups=0.56, wpb=32768, bsz=32, num_updates=77400, lr=4.52e-05, gnorm=0.142, loss_scale=16, train_wall=178, gb_free=15.4, wall=125349
2023-10-20 15:54:06 | INFO | train_inner | epoch 001:  77625 / 1830643 loss=3.325, ppl=10.02, wps=18575.1, ups=0.57, wpb=32768, bsz=32, num_updates=77500, lr=4.5e-05, gnorm=0.148, loss_scale=16, train_wall=176, gb_free=15.4, wall=125525
2023-10-20 15:57:02 | INFO | train_inner | epoch 001:  77725 / 1830643 loss=3.511, ppl=11.4, wps=18589.2, ups=0.57, wpb=32768, bsz=32, num_updates=77600, lr=4.48e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=125701
2023-10-20 15:59:59 | INFO | train_inner | epoch 001:  77825 / 1830643 loss=3.693, ppl=12.94, wps=18559.8, ups=0.57, wpb=32768, bsz=32, num_updates=77700, lr=4.46e-05, gnorm=0.153, loss_scale=16, train_wall=176, gb_free=15.4, wall=125878
2023-10-20 16:02:55 | INFO | train_inner | epoch 001:  77925 / 1830643 loss=3.477, ppl=11.14, wps=18607.2, ups=0.57, wpb=32768, bsz=32, num_updates=77800, lr=4.44e-05, gnorm=0.147, loss_scale=16, train_wall=176, gb_free=15.4, wall=126054
2023-10-20 16:05:51 | INFO | train_inner | epoch 001:  78025 / 1830643 loss=3.186, ppl=9.1, wps=18590.7, ups=0.57, wpb=32768, bsz=32, num_updates=77900, lr=4.42e-05, gnorm=0.138, loss_scale=32, train_wall=176, gb_free=15.4, wall=126230
2023-10-20 16:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 16:08:50 | INFO | train_inner | epoch 001:  78126 / 1830643 loss=3.553, ppl=11.73, wps=18299.7, ups=0.56, wpb=32768, bsz=32, num_updates=78000, lr=4.4e-05, gnorm=0.15, loss_scale=16, train_wall=179, gb_free=15.4, wall=126409
2023-10-20 16:11:47 | INFO | train_inner | epoch 001:  78226 / 1830643 loss=3.224, ppl=9.34, wps=18516.8, ups=0.57, wpb=32768, bsz=32, num_updates=78100, lr=4.38e-05, gnorm=0.137, loss_scale=16, train_wall=177, gb_free=15.4, wall=126586
2023-10-20 16:14:43 | INFO | train_inner | epoch 001:  78326 / 1830643 loss=3.4, ppl=10.56, wps=18612, ups=0.57, wpb=32768, bsz=32, num_updates=78200, lr=4.36e-05, gnorm=0.143, loss_scale=16, train_wall=176, gb_free=15.4, wall=126762
2023-10-20 16:17:39 | INFO | train_inner | epoch 001:  78426 / 1830643 loss=3.51, ppl=11.39, wps=18648, ups=0.57, wpb=32768, bsz=32, num_updates=78300, lr=4.34e-05, gnorm=0.146, loss_scale=16, train_wall=175, gb_free=15.4, wall=126938
2023-10-20 16:20:35 | INFO | train_inner | epoch 001:  78526 / 1830643 loss=3.482, ppl=11.17, wps=18632.4, ups=0.57, wpb=32768, bsz=32, num_updates=78400, lr=4.32e-05, gnorm=0.143, loss_scale=16, train_wall=175, gb_free=15.4, wall=127114
2023-10-20 16:23:31 | INFO | train_inner | epoch 001:  78626 / 1830643 loss=3.628, ppl=12.37, wps=18594.6, ups=0.57, wpb=32768, bsz=32, num_updates=78500, lr=4.3e-05, gnorm=0.14, loss_scale=32, train_wall=176, gb_free=15.4, wall=127290
2023-10-20 16:24:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 16:26:30 | INFO | train_inner | epoch 001:  78727 / 1830643 loss=3.432, ppl=10.79, wps=18282.1, ups=0.56, wpb=32768, bsz=32, num_updates=78600, lr=4.28e-05, gnorm=0.14, loss_scale=16, train_wall=179, gb_free=15.4, wall=127470
2023-10-20 16:28:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 16:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 16:29:29 | INFO | train_inner | epoch 001:  78829 / 1830643 loss=3.321, ppl=9.99, wps=18297.9, ups=0.56, wpb=32768, bsz=32, num_updates=78700, lr=4.26e-05, gnorm=0.144, loss_scale=4, train_wall=179, gb_free=15.4, wall=127649
2023-10-20 16:32:26 | INFO | train_inner | epoch 001:  78929 / 1830643 loss=3.587, ppl=12.02, wps=18514.6, ups=0.57, wpb=32768, bsz=32, num_updates=78800, lr=4.24e-05, gnorm=0.145, loss_scale=4, train_wall=177, gb_free=15.4, wall=127826
2023-10-20 16:35:23 | INFO | train_inner | epoch 001:  79029 / 1830643 loss=3.522, ppl=11.49, wps=18543.9, ups=0.57, wpb=32768, bsz=32, num_updates=78900, lr=4.22e-05, gnorm=0.15, loss_scale=4, train_wall=176, gb_free=15.4, wall=128002
2023-10-20 16:38:20 | INFO | train_inner | epoch 001:  79129 / 1830643 loss=3.272, ppl=9.66, wps=18550, ups=0.57, wpb=32768, bsz=32, num_updates=79000, lr=4.2e-05, gnorm=0.141, loss_scale=4, train_wall=176, gb_free=15.4, wall=128179
2023-10-20 16:41:17 | INFO | train_inner | epoch 001:  79229 / 1830643 loss=3.458, ppl=10.99, wps=18511.8, ups=0.56, wpb=32768, bsz=32, num_updates=79100, lr=4.18e-05, gnorm=0.139, loss_scale=4, train_wall=177, gb_free=15.4, wall=128356
2023-10-20 16:44:13 | INFO | train_inner | epoch 001:  79329 / 1830643 loss=3.528, ppl=11.53, wps=18604.5, ups=0.57, wpb=32768, bsz=32, num_updates=79200, lr=4.16e-05, gnorm=0.147, loss_scale=8, train_wall=176, gb_free=15.4, wall=128532
2023-10-20 16:47:09 | INFO | train_inner | epoch 001:  79429 / 1830643 loss=3.409, ppl=10.62, wps=18601.1, ups=0.57, wpb=32768, bsz=32, num_updates=79300, lr=4.14e-05, gnorm=0.145, loss_scale=8, train_wall=176, gb_free=15.4, wall=128708
2023-10-20 16:50:07 | INFO | train_inner | epoch 001:  79529 / 1830643 loss=3.428, ppl=10.76, wps=18455.2, ups=0.56, wpb=32768, bsz=32, num_updates=79400, lr=4.12e-05, gnorm=0.137, loss_scale=8, train_wall=177, gb_free=15.4, wall=128886
2023-10-20 16:53:03 | INFO | train_inner | epoch 001:  79629 / 1830643 loss=3.279, ppl=9.71, wps=18595.6, ups=0.57, wpb=32768, bsz=32, num_updates=79500, lr=4.1e-05, gnorm=0.142, loss_scale=8, train_wall=176, gb_free=15.4, wall=129062
2023-10-20 16:55:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 16:56:00 | INFO | train_inner | epoch 001:  79730 / 1830643 loss=3.381, ppl=10.42, wps=18492.4, ups=0.56, wpb=32768, bsz=32, num_updates=79600, lr=4.08e-05, gnorm=0.161, loss_scale=4, train_wall=177, gb_free=15.4, wall=129239
2023-10-20 16:58:57 | INFO | train_inner | epoch 001:  79830 / 1830643 loss=3.482, ppl=11.18, wps=18455.7, ups=0.56, wpb=32768, bsz=32, num_updates=79700, lr=4.06e-05, gnorm=0.147, loss_scale=4, train_wall=177, gb_free=15.4, wall=129417
2023-10-20 17:01:53 | INFO | train_inner | epoch 001:  79930 / 1830643 loss=3.519, ppl=11.47, wps=18645, ups=0.57, wpb=32768, bsz=32, num_updates=79800, lr=4.04e-05, gnorm=0.145, loss_scale=4, train_wall=175, gb_free=15.4, wall=129592
2023-10-20 17:04:50 | INFO | train_inner | epoch 001:  80030 / 1830643 loss=3.331, ppl=10.06, wps=18588, ups=0.57, wpb=32768, bsz=32, num_updates=79900, lr=4.02e-05, gnorm=0.146, loss_scale=4, train_wall=176, gb_free=15.4, wall=129769
2023-10-20 17:07:46 | INFO | train_inner | epoch 001:  80130 / 1830643 loss=3.445, ppl=10.89, wps=18578.1, ups=0.57, wpb=32768, bsz=32, num_updates=80000, lr=4e-05, gnorm=0.141, loss_scale=4, train_wall=176, gb_free=15.4, wall=129945
2023-10-20 17:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 80000 updates
2023-10-20 17:07:46 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_80000.pt
2023-10-20 17:07:51 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_80000.pt
2023-10-20 17:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_80000.pt (epoch 1 @ 80000 updates, score None) (writing took 15.623881485080346 seconds)
2023-10-20 17:10:58 | INFO | train_inner | epoch 001:  80230 / 1830643 loss=3.433, ppl=10.8, wps=17028.5, ups=0.52, wpb=32768, bsz=32, num_updates=80100, lr=3.98e-05, gnorm=0.148, loss_scale=8, train_wall=176, gb_free=15.4, wall=130138
2023-10-20 17:13:54 | INFO | train_inner | epoch 001:  80330 / 1830643 loss=3.475, ppl=11.12, wps=18680.6, ups=0.57, wpb=32768, bsz=32, num_updates=80200, lr=3.96e-05, gnorm=0.146, loss_scale=8, train_wall=175, gb_free=15.4, wall=130313
2023-10-20 17:16:50 | INFO | train_inner | epoch 001:  80430 / 1830643 loss=3.352, ppl=10.21, wps=18571.9, ups=0.57, wpb=32768, bsz=32, num_updates=80300, lr=3.94e-05, gnorm=0.14, loss_scale=8, train_wall=176, gb_free=15.4, wall=130489
2023-10-20 17:19:46 | INFO | train_inner | epoch 001:  80530 / 1830643 loss=3.399, ppl=10.55, wps=18672.6, ups=0.57, wpb=32768, bsz=32, num_updates=80400, lr=3.92e-05, gnorm=0.15, loss_scale=8, train_wall=175, gb_free=15.4, wall=130665
2023-10-20 17:22:43 | INFO | train_inner | epoch 001:  80630 / 1830643 loss=3.397, ppl=10.54, wps=18502, ups=0.56, wpb=32768, bsz=32, num_updates=80500, lr=3.9e-05, gnorm=0.141, loss_scale=8, train_wall=177, gb_free=15.4, wall=130842
2023-10-20 17:25:39 | INFO | train_inner | epoch 001:  80730 / 1830643 loss=3.443, ppl=10.88, wps=18597.3, ups=0.57, wpb=32768, bsz=32, num_updates=80600, lr=3.88e-05, gnorm=0.14, loss_scale=8, train_wall=176, gb_free=15.4, wall=131018
2023-10-20 17:28:36 | INFO | train_inner | epoch 001:  80830 / 1830643 loss=3.455, ppl=10.97, wps=18547.6, ups=0.57, wpb=32768, bsz=32, num_updates=80700, lr=3.86e-05, gnorm=0.145, loss_scale=16, train_wall=176, gb_free=15.4, wall=131195
2023-10-20 17:31:33 | INFO | train_inner | epoch 001:  80930 / 1830643 loss=3.252, ppl=9.53, wps=18495.8, ups=0.56, wpb=32768, bsz=32, num_updates=80800, lr=3.84e-05, gnorm=0.138, loss_scale=16, train_wall=177, gb_free=15.4, wall=131372
2023-10-20 17:34:29 | INFO | train_inner | epoch 001:  81030 / 1830643 loss=3.351, ppl=10.2, wps=18591.2, ups=0.57, wpb=32768, bsz=32, num_updates=80900, lr=3.82e-05, gnorm=0.139, loss_scale=16, train_wall=176, gb_free=15.4, wall=131548
2023-10-20 17:37:26 | INFO | train_inner | epoch 001:  81130 / 1830643 loss=3.315, ppl=9.95, wps=18560.6, ups=0.57, wpb=32768, bsz=32, num_updates=81000, lr=3.8e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=131725
2023-10-20 17:40:22 | INFO | train_inner | epoch 001:  81230 / 1830643 loss=3.378, ppl=10.4, wps=18602.9, ups=0.57, wpb=32768, bsz=32, num_updates=81100, lr=3.78e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=131901
2023-10-20 17:43:17 | INFO | train_inner | epoch 001:  81330 / 1830643 loss=3.257, ppl=9.56, wps=18713.3, ups=0.57, wpb=32768, bsz=32, num_updates=81200, lr=3.76e-05, gnorm=0.137, loss_scale=32, train_wall=175, gb_free=15.4, wall=132076
2023-10-20 17:46:13 | INFO | train_inner | epoch 001:  81430 / 1830643 loss=3.269, ppl=9.64, wps=18582.2, ups=0.57, wpb=32768, bsz=32, num_updates=81300, lr=3.74e-05, gnorm=0.141, loss_scale=32, train_wall=176, gb_free=15.4, wall=132253
2023-10-20 17:49:10 | INFO | train_inner | epoch 001:  81530 / 1830643 loss=3.452, ppl=10.94, wps=18551.9, ups=0.57, wpb=32768, bsz=32, num_updates=81400, lr=3.72e-05, gnorm=0.143, loss_scale=32, train_wall=176, gb_free=15.4, wall=132429
2023-10-20 17:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 17:52:08 | INFO | train_inner | epoch 001:  81631 / 1830643 loss=3.373, ppl=10.36, wps=18357.2, ups=0.56, wpb=32768, bsz=32, num_updates=81500, lr=3.7e-05, gnorm=0.146, loss_scale=16, train_wall=178, gb_free=15.4, wall=132608
2023-10-20 17:55:03 | INFO | train_inner | epoch 001:  81731 / 1830643 loss=3.346, ppl=10.17, wps=18753.6, ups=0.57, wpb=32768, bsz=32, num_updates=81600, lr=3.68e-05, gnorm=0.14, loss_scale=16, train_wall=174, gb_free=15.4, wall=132782
2023-10-20 17:57:59 | INFO | train_inner | epoch 001:  81831 / 1830643 loss=3.376, ppl=10.38, wps=18601.3, ups=0.57, wpb=32768, bsz=32, num_updates=81700, lr=3.66e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=132959
2023-10-20 18:00:56 | INFO | train_inner | epoch 001:  81931 / 1830643 loss=3.414, ppl=10.66, wps=18583.1, ups=0.57, wpb=32768, bsz=32, num_updates=81800, lr=3.64e-05, gnorm=0.145, loss_scale=16, train_wall=176, gb_free=15.4, wall=133135
2023-10-20 18:02:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 18:02:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 18:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-20 18:03:57 | INFO | train_inner | epoch 001:  82034 / 1830643 loss=3.431, ppl=10.79, wps=18071, ups=0.55, wpb=32768, bsz=32, num_updates=81900, lr=3.62e-05, gnorm=0.154, loss_scale=2, train_wall=181, gb_free=15.4, wall=133316
2023-10-20 18:06:53 | INFO | train_inner | epoch 001:  82134 / 1830643 loss=3.295, ppl=9.82, wps=18580.1, ups=0.57, wpb=32768, bsz=32, num_updates=82000, lr=3.6e-05, gnorm=0.141, loss_scale=2, train_wall=176, gb_free=15.4, wall=133493
2023-10-20 18:09:49 | INFO | train_inner | epoch 001:  82234 / 1830643 loss=3.401, ppl=10.56, wps=18635.7, ups=0.57, wpb=32768, bsz=32, num_updates=82100, lr=3.58e-05, gnorm=0.141, loss_scale=2, train_wall=175, gb_free=15.4, wall=133668
2023-10-20 18:12:46 | INFO | train_inner | epoch 001:  82334 / 1830643 loss=3.189, ppl=9.12, wps=18540, ups=0.57, wpb=32768, bsz=32, num_updates=82200, lr=3.56e-05, gnorm=0.147, loss_scale=2, train_wall=176, gb_free=15.4, wall=133845
2023-10-20 18:15:41 | INFO | train_inner | epoch 001:  82434 / 1830643 loss=3.472, ppl=11.1, wps=18714.3, ups=0.57, wpb=32768, bsz=32, num_updates=82300, lr=3.54e-05, gnorm=0.143, loss_scale=2, train_wall=175, gb_free=15.4, wall=134020
2023-10-20 18:18:37 | INFO | train_inner | epoch 001:  82534 / 1830643 loss=3.441, ppl=10.86, wps=18611.4, ups=0.57, wpb=32768, bsz=32, num_updates=82400, lr=3.52e-05, gnorm=0.146, loss_scale=4, train_wall=176, gb_free=15.4, wall=134196
2023-10-20 18:21:34 | INFO | train_inner | epoch 001:  82634 / 1830643 loss=3.372, ppl=10.35, wps=18487.6, ups=0.56, wpb=32768, bsz=32, num_updates=82500, lr=3.5e-05, gnorm=0.14, loss_scale=4, train_wall=177, gb_free=15.4, wall=134374
2023-10-20 18:24:31 | INFO | train_inner | epoch 001:  82734 / 1830643 loss=3.338, ppl=10.11, wps=18569, ups=0.57, wpb=32768, bsz=32, num_updates=82600, lr=3.48e-05, gnorm=0.144, loss_scale=4, train_wall=176, gb_free=15.4, wall=134550
2023-10-20 18:27:27 | INFO | train_inner | epoch 001:  82834 / 1830643 loss=3.266, ppl=9.62, wps=18639, ups=0.57, wpb=32768, bsz=32, num_updates=82700, lr=3.46e-05, gnorm=0.139, loss_scale=4, train_wall=175, gb_free=15.4, wall=134726
2023-10-20 18:30:23 | INFO | train_inner | epoch 001:  82934 / 1830643 loss=3.368, ppl=10.32, wps=18549.2, ups=0.57, wpb=32768, bsz=32, num_updates=82800, lr=3.44e-05, gnorm=0.143, loss_scale=4, train_wall=176, gb_free=15.4, wall=134902
2023-10-20 18:33:20 | INFO | train_inner | epoch 001:  83034 / 1830643 loss=3.456, ppl=10.97, wps=18584.5, ups=0.57, wpb=32768, bsz=32, num_updates=82900, lr=3.42e-05, gnorm=0.139, loss_scale=8, train_wall=176, gb_free=15.4, wall=135079
2023-10-20 18:36:16 | INFO | train_inner | epoch 001:  83134 / 1830643 loss=3.397, ppl=10.53, wps=18575.8, ups=0.57, wpb=32768, bsz=32, num_updates=83000, lr=3.4e-05, gnorm=0.14, loss_scale=8, train_wall=176, gb_free=15.4, wall=135255
2023-10-20 18:39:13 | INFO | train_inner | epoch 001:  83234 / 1830643 loss=3.372, ppl=10.35, wps=18554.2, ups=0.57, wpb=32768, bsz=32, num_updates=83100, lr=3.38e-05, gnorm=0.149, loss_scale=8, train_wall=176, gb_free=15.4, wall=135432
2023-10-20 18:42:09 | INFO | train_inner | epoch 001:  83334 / 1830643 loss=3.39, ppl=10.48, wps=18550.3, ups=0.57, wpb=32768, bsz=32, num_updates=83200, lr=3.36e-05, gnorm=0.141, loss_scale=8, train_wall=176, gb_free=15.4, wall=135608
2023-10-20 18:45:06 | INFO | train_inner | epoch 001:  83434 / 1830643 loss=3.359, ppl=10.26, wps=18510.6, ups=0.56, wpb=32768, bsz=32, num_updates=83300, lr=3.34e-05, gnorm=0.14, loss_scale=8, train_wall=177, gb_free=15.4, wall=135785
2023-10-20 18:48:01 | INFO | train_inner | epoch 001:  83534 / 1830643 loss=3.298, ppl=9.83, wps=18709.7, ups=0.57, wpb=32768, bsz=32, num_updates=83400, lr=3.32e-05, gnorm=0.14, loss_scale=16, train_wall=175, gb_free=15.4, wall=135961
2023-10-20 18:50:57 | INFO | train_inner | epoch 001:  83634 / 1830643 loss=3.419, ppl=10.69, wps=18620.5, ups=0.57, wpb=32768, bsz=32, num_updates=83500, lr=3.3e-05, gnorm=0.148, loss_scale=16, train_wall=176, gb_free=15.4, wall=136137
2023-10-20 18:53:53 | INFO | train_inner | epoch 001:  83734 / 1830643 loss=3.394, ppl=10.51, wps=18648.4, ups=0.57, wpb=32768, bsz=32, num_updates=83600, lr=3.28e-05, gnorm=0.138, loss_scale=16, train_wall=175, gb_free=15.4, wall=136312
2023-10-20 18:56:49 | INFO | train_inner | epoch 001:  83834 / 1830643 loss=3.302, ppl=9.86, wps=18587.6, ups=0.57, wpb=32768, bsz=32, num_updates=83700, lr=3.26e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=136489
2023-10-20 18:59:46 | INFO | train_inner | epoch 001:  83934 / 1830643 loss=3.204, ppl=9.22, wps=18599.3, ups=0.57, wpb=32768, bsz=32, num_updates=83800, lr=3.24e-05, gnorm=0.135, loss_scale=16, train_wall=176, gb_free=15.4, wall=136665
2023-10-20 19:02:43 | INFO | train_inner | epoch 001:  84034 / 1830643 loss=3.522, ppl=11.49, wps=18456.6, ups=0.56, wpb=32768, bsz=32, num_updates=83900, lr=3.22e-05, gnorm=0.145, loss_scale=32, train_wall=177, gb_free=15.4, wall=136842
2023-10-20 19:05:38 | INFO | train_inner | epoch 001:  84134 / 1830643 loss=3.59, ppl=12.04, wps=18679, ups=0.57, wpb=32768, bsz=32, num_updates=84000, lr=3.2e-05, gnorm=0.143, loss_scale=32, train_wall=175, gb_free=15.4, wall=137018
2023-10-20 19:05:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 19:08:36 | INFO | train_inner | epoch 001:  84235 / 1830643 loss=3.387, ppl=10.46, wps=18484.5, ups=0.56, wpb=32768, bsz=32, num_updates=84100, lr=3.18e-05, gnorm=0.144, loss_scale=16, train_wall=177, gb_free=15.4, wall=137195
2023-10-20 19:11:32 | INFO | train_inner | epoch 001:  84335 / 1830643 loss=3.393, ppl=10.5, wps=18592.2, ups=0.57, wpb=32768, bsz=32, num_updates=84200, lr=3.16e-05, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=137371
2023-10-20 19:14:28 | INFO | train_inner | epoch 001:  84435 / 1830643 loss=3.133, ppl=8.77, wps=18659.7, ups=0.57, wpb=32768, bsz=32, num_updates=84300, lr=3.14e-05, gnorm=0.136, loss_scale=16, train_wall=175, gb_free=15.4, wall=137547
2023-10-20 19:17:23 | INFO | train_inner | epoch 001:  84535 / 1830643 loss=3.381, ppl=10.42, wps=18646.3, ups=0.57, wpb=32768, bsz=32, num_updates=84400, lr=3.12e-05, gnorm=0.155, loss_scale=16, train_wall=175, gb_free=15.4, wall=137723
2023-10-20 19:20:19 | INFO | train_inner | epoch 001:  84635 / 1830643 loss=3.396, ppl=10.53, wps=18674.5, ups=0.57, wpb=32768, bsz=32, num_updates=84500, lr=3.1e-05, gnorm=0.142, loss_scale=16, train_wall=175, gb_free=15.4, wall=137898
2023-10-20 19:20:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 19:23:18 | INFO | train_inner | epoch 001:  84736 / 1830643 loss=3.543, ppl=11.66, wps=18258.1, ups=0.56, wpb=32768, bsz=32, num_updates=84600, lr=3.08e-05, gnorm=0.139, loss_scale=16, train_wall=179, gb_free=15.4, wall=138078
2023-10-20 19:26:15 | INFO | train_inner | epoch 001:  84836 / 1830643 loss=3.432, ppl=10.79, wps=18560.4, ups=0.57, wpb=32768, bsz=32, num_updates=84700, lr=3.06e-05, gnorm=0.145, loss_scale=16, train_wall=176, gb_free=15.4, wall=138254
2023-10-20 19:29:11 | INFO | train_inner | epoch 001:  84936 / 1830643 loss=3.276, ppl=9.69, wps=18615.7, ups=0.57, wpb=32768, bsz=32, num_updates=84800, lr=3.04e-05, gnorm=0.139, loss_scale=16, train_wall=176, gb_free=15.4, wall=138430
2023-10-20 19:32:07 | INFO | train_inner | epoch 001:  85036 / 1830643 loss=3.345, ppl=10.16, wps=18570, ups=0.57, wpb=32768, bsz=32, num_updates=84900, lr=3.02e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=138607
2023-10-20 19:35:03 | INFO | train_inner | epoch 001:  85136 / 1830643 loss=3.299, ppl=9.84, wps=18691.6, ups=0.57, wpb=32768, bsz=32, num_updates=85000, lr=3e-05, gnorm=0.14, loss_scale=16, train_wall=175, gb_free=15.4, wall=138782
2023-10-20 19:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 19:38:02 | INFO | train_inner | epoch 001:  85237 / 1830643 loss=3.394, ppl=10.51, wps=18264.9, ups=0.56, wpb=32768, bsz=32, num_updates=85100, lr=2.98e-05, gnorm=0.139, loss_scale=16, train_wall=179, gb_free=15.4, wall=138961
2023-10-20 19:40:58 | INFO | train_inner | epoch 001:  85337 / 1830643 loss=3.282, ppl=9.73, wps=18648.7, ups=0.57, wpb=32768, bsz=32, num_updates=85200, lr=2.96e-05, gnorm=0.139, loss_scale=16, train_wall=175, gb_free=15.4, wall=139137
2023-10-20 19:43:54 | INFO | train_inner | epoch 001:  85437 / 1830643 loss=3.534, ppl=11.58, wps=18619.9, ups=0.57, wpb=32768, bsz=32, num_updates=85300, lr=2.94e-05, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=139313
2023-10-20 19:46:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 19:46:52 | INFO | train_inner | epoch 001:  85538 / 1830643 loss=3.213, ppl=9.27, wps=18389.2, ups=0.56, wpb=32768, bsz=32, num_updates=85400, lr=2.92e-05, gnorm=0.136, loss_scale=8, train_wall=178, gb_free=15.4, wall=139491
2023-10-20 19:49:47 | INFO | train_inner | epoch 001:  85638 / 1830643 loss=3.589, ppl=12.04, wps=18676.5, ups=0.57, wpb=32768, bsz=32, num_updates=85500, lr=2.9e-05, gnorm=0.137, loss_scale=8, train_wall=175, gb_free=15.4, wall=139667
2023-10-20 19:52:44 | INFO | train_inner | epoch 001:  85738 / 1830643 loss=3.538, ppl=11.62, wps=18533.4, ups=0.57, wpb=32768, bsz=32, num_updates=85600, lr=2.88e-05, gnorm=0.143, loss_scale=8, train_wall=176, gb_free=15.4, wall=139843
2023-10-20 19:55:40 | INFO | train_inner | epoch 001:  85838 / 1830643 loss=3.408, ppl=10.61, wps=18644.7, ups=0.57, wpb=32768, bsz=32, num_updates=85700, lr=2.86e-05, gnorm=0.144, loss_scale=8, train_wall=175, gb_free=15.4, wall=140019
2023-10-20 19:58:35 | INFO | train_inner | epoch 001:  85938 / 1830643 loss=3.5, ppl=11.31, wps=18737.1, ups=0.57, wpb=32768, bsz=32, num_updates=85800, lr=2.84e-05, gnorm=0.149, loss_scale=8, train_wall=175, gb_free=15.4, wall=140194
2023-10-20 20:01:31 | INFO | train_inner | epoch 001:  86038 / 1830643 loss=3.495, ppl=11.28, wps=18614.3, ups=0.57, wpb=32768, bsz=32, num_updates=85900, lr=2.82e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=140370
2023-10-20 20:04:27 | INFO | train_inner | epoch 001:  86138 / 1830643 loss=3.483, ppl=11.18, wps=18622, ups=0.57, wpb=32768, bsz=32, num_updates=86000, lr=2.8e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=140546
2023-10-20 20:07:23 | INFO | train_inner | epoch 001:  86238 / 1830643 loss=3.325, ppl=10.02, wps=18589.6, ups=0.57, wpb=32768, bsz=32, num_updates=86100, lr=2.78e-05, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=140722
2023-10-20 20:10:19 | INFO | train_inner | epoch 001:  86338 / 1830643 loss=3.268, ppl=9.64, wps=18638.3, ups=0.57, wpb=32768, bsz=32, num_updates=86200, lr=2.76e-05, gnorm=0.142, loss_scale=16, train_wall=175, gb_free=15.4, wall=140898
2023-10-20 20:13:16 | INFO | train_inner | epoch 001:  86438 / 1830643 loss=3.164, ppl=8.96, wps=18549.8, ups=0.57, wpb=32768, bsz=32, num_updates=86300, lr=2.74e-05, gnorm=0.134, loss_scale=16, train_wall=176, gb_free=15.4, wall=141075
2023-10-20 20:16:12 | INFO | train_inner | epoch 001:  86538 / 1830643 loss=3.348, ppl=10.18, wps=18577.4, ups=0.57, wpb=32768, bsz=32, num_updates=86400, lr=2.72e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=141251
2023-10-20 20:19:08 | INFO | train_inner | epoch 001:  86638 / 1830643 loss=3.054, ppl=8.3, wps=18582.4, ups=0.57, wpb=32768, bsz=32, num_updates=86500, lr=2.7e-05, gnorm=0.136, loss_scale=32, train_wall=176, gb_free=15.4, wall=141428
2023-10-20 20:22:04 | INFO | train_inner | epoch 001:  86738 / 1830643 loss=3.345, ppl=10.16, wps=18601.7, ups=0.57, wpb=32768, bsz=32, num_updates=86600, lr=2.68e-05, gnorm=0.142, loss_scale=32, train_wall=176, gb_free=15.4, wall=141604
2023-10-20 20:23:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 20:25:02 | INFO | train_inner | epoch 001:  86839 / 1830643 loss=3.342, ppl=10.14, wps=18459.6, ups=0.56, wpb=32768, bsz=32, num_updates=86700, lr=2.66e-05, gnorm=0.137, loss_scale=16, train_wall=177, gb_free=15.4, wall=141781
2023-10-20 20:27:58 | INFO | train_inner | epoch 001:  86939 / 1830643 loss=3.483, ppl=11.18, wps=18586.6, ups=0.57, wpb=32768, bsz=32, num_updates=86800, lr=2.64e-05, gnorm=0.145, loss_scale=16, train_wall=176, gb_free=15.4, wall=141958
2023-10-20 20:30:54 | INFO | train_inner | epoch 001:  87039 / 1830643 loss=3.417, ppl=10.68, wps=18672.3, ups=0.57, wpb=32768, bsz=32, num_updates=86900, lr=2.62e-05, gnorm=0.141, loss_scale=16, train_wall=175, gb_free=15.4, wall=142133
2023-10-20 20:33:50 | INFO | train_inner | epoch 001:  87139 / 1830643 loss=3.402, ppl=10.57, wps=18571.7, ups=0.57, wpb=32768, bsz=32, num_updates=87000, lr=2.6e-05, gnorm=0.146, loss_scale=16, train_wall=176, gb_free=15.4, wall=142309
2023-10-20 20:36:46 | INFO | train_inner | epoch 001:  87239 / 1830643 loss=3.342, ppl=10.14, wps=18641.8, ups=0.57, wpb=32768, bsz=32, num_updates=87100, lr=2.58e-05, gnorm=0.141, loss_scale=16, train_wall=175, gb_free=15.4, wall=142485
2023-10-20 20:39:43 | INFO | train_inner | epoch 001:  87339 / 1830643 loss=3.187, ppl=9.11, wps=18482.7, ups=0.56, wpb=32768, bsz=32, num_updates=87200, lr=2.56e-05, gnorm=0.135, loss_scale=32, train_wall=177, gb_free=15.4, wall=142663
2023-10-20 20:40:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 20:42:42 | INFO | train_inner | epoch 001:  87440 / 1830643 loss=3.401, ppl=10.56, wps=18335.9, ups=0.56, wpb=32768, bsz=32, num_updates=87300, lr=2.54e-05, gnorm=0.135, loss_scale=16, train_wall=178, gb_free=15.4, wall=142841
2023-10-20 20:45:39 | INFO | train_inner | epoch 001:  87540 / 1830643 loss=3.366, ppl=10.31, wps=18486.6, ups=0.56, wpb=32768, bsz=32, num_updates=87400, lr=2.52e-05, gnorm=0.143, loss_scale=16, train_wall=177, gb_free=15.4, wall=143018
2023-10-20 20:48:33 | INFO | train_inner | epoch 001:  87640 / 1830643 loss=3.587, ppl=12.02, wps=18805.3, ups=0.57, wpb=32768, bsz=32, num_updates=87500, lr=2.5e-05, gnorm=0.144, loss_scale=16, train_wall=174, gb_free=15.4, wall=143193
2023-10-20 20:51:29 | INFO | train_inner | epoch 001:  87740 / 1830643 loss=3.376, ppl=10.38, wps=18659.7, ups=0.57, wpb=32768, bsz=32, num_updates=87600, lr=2.48e-05, gnorm=0.141, loss_scale=16, train_wall=175, gb_free=15.4, wall=143368
2023-10-20 20:54:26 | INFO | train_inner | epoch 001:  87840 / 1830643 loss=3.46, ppl=11.01, wps=18521.1, ups=0.57, wpb=32768, bsz=32, num_updates=87700, lr=2.46e-05, gnorm=0.148, loss_scale=16, train_wall=177, gb_free=15.4, wall=143545
2023-10-20 20:55:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 20:57:24 | INFO | train_inner | epoch 001:  87941 / 1830643 loss=3.319, ppl=9.98, wps=18388.6, ups=0.56, wpb=32768, bsz=32, num_updates=87800, lr=2.44e-05, gnorm=0.14, loss_scale=16, train_wall=178, gb_free=15.4, wall=143723
2023-10-20 21:00:21 | INFO | train_inner | epoch 001:  88041 / 1830643 loss=3.547, ppl=11.69, wps=18555.7, ups=0.57, wpb=32768, bsz=32, num_updates=87900, lr=2.42e-05, gnorm=0.145, loss_scale=16, train_wall=176, gb_free=15.4, wall=143900
2023-10-20 21:03:17 | INFO | train_inner | epoch 001:  88141 / 1830643 loss=3.253, ppl=9.54, wps=18608.7, ups=0.57, wpb=32768, bsz=32, num_updates=88000, lr=2.4e-05, gnorm=0.137, loss_scale=16, train_wall=176, gb_free=15.4, wall=144076
2023-10-20 21:06:14 | INFO | train_inner | epoch 001:  88241 / 1830643 loss=3.253, ppl=9.53, wps=18508.8, ups=0.56, wpb=32768, bsz=32, num_updates=88100, lr=2.38e-05, gnorm=0.138, loss_scale=16, train_wall=177, gb_free=15.4, wall=144253
2023-10-20 21:09:10 | INFO | train_inner | epoch 001:  88341 / 1830643 loss=3.31, ppl=9.92, wps=18565.7, ups=0.57, wpb=32768, bsz=32, num_updates=88200, lr=2.36e-05, gnorm=0.139, loss_scale=16, train_wall=176, gb_free=15.4, wall=144430
2023-10-20 21:12:07 | INFO | train_inner | epoch 001:  88441 / 1830643 loss=3.551, ppl=11.72, wps=18564.1, ups=0.57, wpb=32768, bsz=32, num_updates=88300, lr=2.34e-05, gnorm=0.143, loss_scale=32, train_wall=176, gb_free=15.4, wall=144606
2023-10-20 21:15:03 | INFO | train_inner | epoch 001:  88541 / 1830643 loss=3.308, ppl=9.9, wps=18600.3, ups=0.57, wpb=32768, bsz=32, num_updates=88400, lr=2.32e-05, gnorm=0.141, loss_scale=32, train_wall=176, gb_free=15.4, wall=144782
2023-10-20 21:15:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 21:18:03 | INFO | train_inner | epoch 001:  88642 / 1830643 loss=3.448, ppl=10.91, wps=18196.1, ups=0.56, wpb=32768, bsz=32, num_updates=88500, lr=2.3e-05, gnorm=0.139, loss_scale=16, train_wall=180, gb_free=15.4, wall=144962
2023-10-20 21:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 21:21:02 | INFO | train_inner | epoch 001:  88743 / 1830643 loss=3.428, ppl=10.77, wps=18335.4, ups=0.56, wpb=32768, bsz=32, num_updates=88600, lr=2.28e-05, gnorm=0.148, loss_scale=8, train_wall=178, gb_free=15.4, wall=145141
2023-10-20 21:23:58 | INFO | train_inner | epoch 001:  88843 / 1830643 loss=3.283, ppl=9.73, wps=18581.8, ups=0.57, wpb=32768, bsz=32, num_updates=88700, lr=2.26e-05, gnorm=0.137, loss_scale=8, train_wall=176, gb_free=15.4, wall=145318
2023-10-20 21:26:54 | INFO | train_inner | epoch 001:  88943 / 1830643 loss=3.303, ppl=9.87, wps=18615.4, ups=0.57, wpb=32768, bsz=32, num_updates=88800, lr=2.24e-05, gnorm=0.135, loss_scale=8, train_wall=176, gb_free=15.4, wall=145494
2023-10-20 21:29:52 | INFO | train_inner | epoch 001:  89043 / 1830643 loss=3.439, ppl=10.84, wps=18472.6, ups=0.56, wpb=32768, bsz=32, num_updates=88900, lr=2.22e-05, gnorm=0.14, loss_scale=8, train_wall=177, gb_free=15.4, wall=145671
2023-10-20 21:32:48 | INFO | train_inner | epoch 001:  89143 / 1830643 loss=3.359, ppl=10.26, wps=18578.2, ups=0.57, wpb=32768, bsz=32, num_updates=89000, lr=2.2e-05, gnorm=0.135, loss_scale=8, train_wall=176, gb_free=15.4, wall=145847
2023-10-20 21:35:44 | INFO | train_inner | epoch 001:  89243 / 1830643 loss=3.506, ppl=11.36, wps=18633.4, ups=0.57, wpb=32768, bsz=32, num_updates=89100, lr=2.18e-05, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=146023
2023-10-20 21:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 21:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-10-20 21:38:45 | INFO | train_inner | epoch 001:  89345 / 1830643 loss=3.256, ppl=9.55, wps=18135.6, ups=0.55, wpb=32768, bsz=32, num_updates=89200, lr=2.16e-05, gnorm=0.153, loss_scale=4, train_wall=180, gb_free=15.4, wall=146204
2023-10-20 21:41:41 | INFO | train_inner | epoch 001:  89445 / 1830643 loss=3.472, ppl=11.1, wps=18534.4, ups=0.57, wpb=32768, bsz=32, num_updates=89300, lr=2.14e-05, gnorm=0.137, loss_scale=4, train_wall=176, gb_free=15.4, wall=146381
2023-10-20 21:44:38 | INFO | train_inner | epoch 001:  89545 / 1830643 loss=3.427, ppl=10.76, wps=18574.1, ups=0.57, wpb=32768, bsz=32, num_updates=89400, lr=2.12e-05, gnorm=0.14, loss_scale=4, train_wall=176, gb_free=15.4, wall=146557
2023-10-20 21:47:34 | INFO | train_inner | epoch 001:  89645 / 1830643 loss=3.431, ppl=10.79, wps=18578.4, ups=0.57, wpb=32768, bsz=32, num_updates=89500, lr=2.1e-05, gnorm=0.139, loss_scale=4, train_wall=176, gb_free=15.4, wall=146733
2023-10-20 21:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-10-20 21:50:32 | INFO | train_inner | epoch 001:  89746 / 1830643 loss=3.319, ppl=9.98, wps=18446, ups=0.56, wpb=32768, bsz=32, num_updates=89600, lr=2.08e-05, gnorm=0.184, loss_scale=2, train_wall=177, gb_free=15.4, wall=146911
2023-10-20 21:53:29 | INFO | train_inner | epoch 001:  89846 / 1830643 loss=3.521, ppl=11.48, wps=18517.9, ups=0.57, wpb=32768, bsz=32, num_updates=89700, lr=2.06e-05, gnorm=0.141, loss_scale=2, train_wall=177, gb_free=15.4, wall=147088
2023-10-20 21:56:25 | INFO | train_inner | epoch 001:  89946 / 1830643 loss=3.352, ppl=10.21, wps=18562.4, ups=0.57, wpb=32768, bsz=32, num_updates=89800, lr=2.04e-05, gnorm=0.142, loss_scale=2, train_wall=176, gb_free=15.4, wall=147265
2023-10-20 21:59:22 | INFO | train_inner | epoch 001:  90046 / 1830643 loss=3.283, ppl=9.74, wps=18555.9, ups=0.57, wpb=32768, bsz=32, num_updates=89900, lr=2.02e-05, gnorm=0.135, loss_scale=2, train_wall=176, gb_free=15.4, wall=147441
2023-10-20 22:02:20 | INFO | train_inner | epoch 001:  90146 / 1830643 loss=3.314, ppl=9.95, wps=18438.3, ups=0.56, wpb=32768, bsz=32, num_updates=90000, lr=2e-05, gnorm=0.136, loss_scale=2, train_wall=177, gb_free=15.4, wall=147619
2023-10-20 22:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 90000 updates
2023-10-20 22:02:20 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_90000.pt
2023-10-20 22:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_90000.pt
2023-10-20 22:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_90000.pt (epoch 1 @ 90000 updates, score None) (writing took 15.299004700034857 seconds)
2023-10-20 22:05:30 | INFO | train_inner | epoch 001:  90246 / 1830643 loss=3.375, ppl=10.37, wps=17202.2, ups=0.52, wpb=32768, bsz=32, num_updates=90100, lr=1.98e-05, gnorm=0.138, loss_scale=4, train_wall=175, gb_free=15.4, wall=147809
2023-10-20 22:08:26 | INFO | train_inner | epoch 001:  90346 / 1830643 loss=3.4, ppl=10.56, wps=18645.7, ups=0.57, wpb=32768, bsz=32, num_updates=90200, lr=1.96e-05, gnorm=0.145, loss_scale=4, train_wall=175, gb_free=15.4, wall=147985
2023-10-20 22:11:21 | INFO | train_inner | epoch 001:  90446 / 1830643 loss=3.284, ppl=9.74, wps=18688.3, ups=0.57, wpb=32768, bsz=32, num_updates=90300, lr=1.94e-05, gnorm=0.136, loss_scale=4, train_wall=175, gb_free=15.4, wall=148160
2023-10-20 22:14:17 | INFO | train_inner | epoch 001:  90546 / 1830643 loss=3.374, ppl=10.37, wps=18635.7, ups=0.57, wpb=32768, bsz=32, num_updates=90400, lr=1.92e-05, gnorm=0.139, loss_scale=4, train_wall=175, gb_free=15.4, wall=148336
2023-10-20 22:17:13 | INFO | train_inner | epoch 001:  90646 / 1830643 loss=3.344, ppl=10.15, wps=18634.3, ups=0.57, wpb=32768, bsz=32, num_updates=90500, lr=1.9e-05, gnorm=0.138, loss_scale=4, train_wall=175, gb_free=15.4, wall=148512
2023-10-20 22:20:08 | INFO | train_inner | epoch 001:  90746 / 1830643 loss=3.341, ppl=10.13, wps=18692.8, ups=0.57, wpb=32768, bsz=32, num_updates=90600, lr=1.88e-05, gnorm=0.138, loss_scale=8, train_wall=175, gb_free=15.4, wall=148687
2023-10-20 22:23:05 | INFO | train_inner | epoch 001:  90846 / 1830643 loss=3.404, ppl=10.59, wps=18503.1, ups=0.56, wpb=32768, bsz=32, num_updates=90700, lr=1.86e-05, gnorm=0.136, loss_scale=8, train_wall=177, gb_free=15.4, wall=148865
2023-10-20 22:26:00 | INFO | train_inner | epoch 001:  90946 / 1830643 loss=3.457, ppl=10.98, wps=18736.6, ups=0.57, wpb=32768, bsz=32, num_updates=90800, lr=1.84e-05, gnorm=0.144, loss_scale=8, train_wall=175, gb_free=15.4, wall=149039
2023-10-20 22:28:55 | INFO | train_inner | epoch 001:  91046 / 1830643 loss=3.508, ppl=11.38, wps=18779.5, ups=0.57, wpb=32768, bsz=32, num_updates=90900, lr=1.82e-05, gnorm=0.141, loss_scale=8, train_wall=174, gb_free=15.4, wall=149214
2023-10-20 22:31:50 | INFO | train_inner | epoch 001:  91146 / 1830643 loss=3.616, ppl=12.26, wps=18706.7, ups=0.57, wpb=32768, bsz=32, num_updates=91000, lr=1.8e-05, gnorm=0.141, loss_scale=8, train_wall=175, gb_free=15.4, wall=149389
2023-10-20 22:34:45 | INFO | train_inner | epoch 001:  91246 / 1830643 loss=3.434, ppl=10.8, wps=18748.8, ups=0.57, wpb=32768, bsz=32, num_updates=91100, lr=1.78e-05, gnorm=0.143, loss_scale=16, train_wall=174, gb_free=15.4, wall=149564
2023-10-20 22:37:39 | INFO | train_inner | epoch 001:  91346 / 1830643 loss=3.282, ppl=9.73, wps=18791.9, ups=0.57, wpb=32768, bsz=32, num_updates=91200, lr=1.76e-05, gnorm=0.139, loss_scale=16, train_wall=174, gb_free=15.4, wall=149738
2023-10-20 22:40:33 | INFO | train_inner | epoch 001:  91446 / 1830643 loss=3.414, ppl=10.66, wps=18800.3, ups=0.57, wpb=32768, bsz=32, num_updates=91300, lr=1.74e-05, gnorm=0.137, loss_scale=16, train_wall=174, gb_free=15.4, wall=149913
2023-10-20 22:43:26 | INFO | train_inner | epoch 001:  91546 / 1830643 loss=3.264, ppl=9.61, wps=18998.6, ups=0.58, wpb=32768, bsz=32, num_updates=91400, lr=1.72e-05, gnorm=0.137, loss_scale=16, train_wall=172, gb_free=15.4, wall=150085
2023-10-20 22:46:21 | INFO | train_inner | epoch 001:  91646 / 1830643 loss=3.333, ppl=10.07, wps=18673.2, ups=0.57, wpb=32768, bsz=32, num_updates=91500, lr=1.7e-05, gnorm=0.136, loss_scale=16, train_wall=175, gb_free=15.4, wall=150261
2023-10-20 22:49:19 | INFO | train_inner | epoch 001:  91746 / 1830643 loss=3.189, ppl=9.12, wps=18436, ups=0.56, wpb=32768, bsz=32, num_updates=91600, lr=1.68e-05, gnorm=0.135, loss_scale=32, train_wall=177, gb_free=15.4, wall=150438
2023-10-20 22:52:15 | INFO | train_inner | epoch 001:  91846 / 1830643 loss=3.45, ppl=10.93, wps=18610.2, ups=0.57, wpb=32768, bsz=32, num_updates=91700, lr=1.66e-05, gnorm=0.137, loss_scale=32, train_wall=176, gb_free=15.4, wall=150614
2023-10-20 22:55:13 | INFO | train_inner | epoch 001:  91946 / 1830643 loss=3.577, ppl=11.93, wps=18469.7, ups=0.56, wpb=32768, bsz=32, num_updates=91800, lr=1.64e-05, gnorm=0.137, loss_scale=32, train_wall=177, gb_free=15.4, wall=150792
2023-10-20 22:57:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-20 22:58:09 | INFO | train_inner | epoch 001:  92047 / 1830643 loss=3.352, ppl=10.21, wps=18549.1, ups=0.57, wpb=32768, bsz=32, num_updates=91900, lr=1.62e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=150968
2023-10-20 23:01:05 | INFO | train_inner | epoch 001:  92147 / 1830643 loss=3.337, ppl=10.1, wps=18608.9, ups=0.57, wpb=32768, bsz=32, num_updates=92000, lr=1.6e-05, gnorm=0.135, loss_scale=16, train_wall=176, gb_free=15.4, wall=151145
2023-10-20 23:01:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 23:04:03 | INFO | train_inner | epoch 001:  92248 / 1830643 loss=3.364, ppl=10.29, wps=18433, ups=0.56, wpb=32768, bsz=32, num_updates=92100, lr=1.58e-05, gnorm=0.135, loss_scale=8, train_wall=177, gb_free=15.4, wall=151322
2023-10-20 23:06:59 | INFO | train_inner | epoch 001:  92348 / 1830643 loss=3.34, ppl=10.13, wps=18636, ups=0.57, wpb=32768, bsz=32, num_updates=92200, lr=1.56e-05, gnorm=0.141, loss_scale=8, train_wall=175, gb_free=15.4, wall=151498
2023-10-20 23:09:55 | INFO | train_inner | epoch 001:  92448 / 1830643 loss=3.349, ppl=10.19, wps=18598.6, ups=0.57, wpb=32768, bsz=32, num_updates=92300, lr=1.54e-05, gnorm=0.141, loss_scale=8, train_wall=176, gb_free=15.4, wall=151674
2023-10-20 23:12:51 | INFO | train_inner | epoch 001:  92548 / 1830643 loss=3.267, ppl=9.63, wps=18599.4, ups=0.57, wpb=32768, bsz=32, num_updates=92400, lr=1.52e-05, gnorm=0.137, loss_scale=8, train_wall=176, gb_free=15.4, wall=151850
2023-10-20 23:15:48 | INFO | train_inner | epoch 001:  92648 / 1830643 loss=3.351, ppl=10.21, wps=18561.5, ups=0.57, wpb=32768, bsz=32, num_updates=92500, lr=1.5e-05, gnorm=0.135, loss_scale=8, train_wall=176, gb_free=15.4, wall=152027
2023-10-20 23:18:44 | INFO | train_inner | epoch 001:  92748 / 1830643 loss=3.434, ppl=10.81, wps=18591.9, ups=0.57, wpb=32768, bsz=32, num_updates=92600, lr=1.48e-05, gnorm=0.143, loss_scale=16, train_wall=176, gb_free=15.4, wall=152203
2023-10-20 23:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 23:21:41 | INFO | train_inner | epoch 001:  92849 / 1830643 loss=3.396, ppl=10.53, wps=18553.2, ups=0.57, wpb=32768, bsz=32, num_updates=92700, lr=1.46e-05, gnorm=0.155, loss_scale=8, train_wall=176, gb_free=15.4, wall=152380
2023-10-20 23:24:35 | INFO | train_inner | epoch 001:  92949 / 1830643 loss=3.293, ppl=9.8, wps=18762.1, ups=0.57, wpb=32768, bsz=32, num_updates=92800, lr=1.44e-05, gnorm=0.138, loss_scale=8, train_wall=174, gb_free=15.4, wall=152555
2023-10-20 23:27:29 | INFO | train_inner | epoch 001:  93049 / 1830643 loss=3.249, ppl=9.51, wps=18861.2, ups=0.58, wpb=32768, bsz=32, num_updates=92900, lr=1.42e-05, gnorm=0.161, loss_scale=8, train_wall=173, gb_free=15.4, wall=152728
2023-10-20 23:30:22 | INFO | train_inner | epoch 001:  93149 / 1830643 loss=3.014, ppl=8.08, wps=18898.7, ups=0.58, wpb=32768, bsz=32, num_updates=93000, lr=1.4e-05, gnorm=0.143, loss_scale=8, train_wall=173, gb_free=15.4, wall=152902
2023-10-20 23:33:17 | INFO | train_inner | epoch 001:  93249 / 1830643 loss=3.479, ppl=11.15, wps=18802.7, ups=0.57, wpb=32768, bsz=32, num_updates=93100, lr=1.38e-05, gnorm=0.14, loss_scale=8, train_wall=174, gb_free=15.4, wall=153076
2023-10-20 23:36:13 | INFO | train_inner | epoch 001:  93349 / 1830643 loss=3.267, ppl=9.62, wps=18629.5, ups=0.57, wpb=32768, bsz=32, num_updates=93200, lr=1.36e-05, gnorm=0.141, loss_scale=16, train_wall=176, gb_free=15.4, wall=153252
2023-10-20 23:39:09 | INFO | train_inner | epoch 001:  93449 / 1830643 loss=3.4, ppl=10.55, wps=18572.7, ups=0.57, wpb=32768, bsz=32, num_updates=93300, lr=1.34e-05, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=153428
2023-10-20 23:42:07 | INFO | train_inner | epoch 001:  93549 / 1830643 loss=3.443, ppl=10.87, wps=18448, ups=0.56, wpb=32768, bsz=32, num_updates=93400, lr=1.32e-05, gnorm=0.142, loss_scale=16, train_wall=177, gb_free=15.4, wall=153606
2023-10-20 23:45:03 | INFO | train_inner | epoch 001:  93649 / 1830643 loss=3.323, ppl=10.01, wps=18591.6, ups=0.57, wpb=32768, bsz=32, num_updates=93500, lr=1.3e-05, gnorm=0.134, loss_scale=16, train_wall=176, gb_free=15.4, wall=153782
2023-10-20 23:47:59 | INFO | train_inner | epoch 001:  93749 / 1830643 loss=3.416, ppl=10.67, wps=18591.5, ups=0.57, wpb=32768, bsz=32, num_updates=93600, lr=1.28e-05, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=153958
2023-10-20 23:48:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-20 23:50:57 | INFO | train_inner | epoch 001:  93850 / 1830643 loss=3.407, ppl=10.61, wps=18432.1, ups=0.56, wpb=32768, bsz=32, num_updates=93700, lr=1.26e-05, gnorm=0.141, loss_scale=8, train_wall=177, gb_free=15.4, wall=154136
2023-10-20 23:53:52 | INFO | train_inner | epoch 001:  93950 / 1830643 loss=3.559, ppl=11.79, wps=18674.1, ups=0.57, wpb=32768, bsz=32, num_updates=93800, lr=1.24e-05, gnorm=0.14, loss_scale=8, train_wall=175, gb_free=15.4, wall=154312
2023-10-20 23:56:49 | INFO | train_inner | epoch 001:  94050 / 1830643 loss=3.297, ppl=9.83, wps=18606.3, ups=0.57, wpb=32768, bsz=32, num_updates=93900, lr=1.22e-05, gnorm=0.137, loss_scale=8, train_wall=176, gb_free=15.4, wall=154488
2023-10-20 23:59:45 | INFO | train_inner | epoch 001:  94150 / 1830643 loss=3.271, ppl=9.65, wps=18562.9, ups=0.57, wpb=32768, bsz=32, num_updates=94000, lr=1.2e-05, gnorm=0.137, loss_scale=8, train_wall=176, gb_free=15.4, wall=154664
2023-10-21 00:02:42 | INFO | train_inner | epoch 001:  94250 / 1830643 loss=3.252, ppl=9.52, wps=18552.9, ups=0.57, wpb=32768, bsz=32, num_updates=94100, lr=1.18e-05, gnorm=0.136, loss_scale=8, train_wall=176, gb_free=15.4, wall=154841
2023-10-21 00:05:37 | INFO | train_inner | epoch 001:  94350 / 1830643 loss=3.312, ppl=9.93, wps=18649.2, ups=0.57, wpb=32768, bsz=32, num_updates=94200, lr=1.16e-05, gnorm=0.135, loss_scale=16, train_wall=175, gb_free=15.4, wall=155017
2023-10-21 00:08:34 | INFO | train_inner | epoch 001:  94450 / 1830643 loss=3.21, ppl=9.25, wps=18560.8, ups=0.57, wpb=32768, bsz=32, num_updates=94300, lr=1.14e-05, gnorm=0.134, loss_scale=16, train_wall=176, gb_free=15.4, wall=155193
2023-10-21 00:11:30 | INFO | train_inner | epoch 001:  94550 / 1830643 loss=3.441, ppl=10.86, wps=18560, ups=0.57, wpb=32768, bsz=32, num_updates=94400, lr=1.12e-05, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=155370
2023-10-21 00:14:28 | INFO | train_inner | epoch 001:  94650 / 1830643 loss=3.393, ppl=10.51, wps=18448.4, ups=0.56, wpb=32768, bsz=32, num_updates=94500, lr=1.1e-05, gnorm=0.134, loss_scale=16, train_wall=177, gb_free=15.4, wall=155547
2023-10-21 00:17:26 | INFO | train_inner | epoch 001:  94750 / 1830643 loss=3.274, ppl=9.67, wps=18467.1, ups=0.56, wpb=32768, bsz=32, num_updates=94600, lr=1.08e-05, gnorm=0.142, loss_scale=16, train_wall=177, gb_free=15.4, wall=155725
2023-10-21 00:20:22 | INFO | train_inner | epoch 001:  94850 / 1830643 loss=3.401, ppl=10.56, wps=18555.1, ups=0.57, wpb=32768, bsz=32, num_updates=94700, lr=1.06e-05, gnorm=0.141, loss_scale=32, train_wall=176, gb_free=15.4, wall=155901
2023-10-21 00:20:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 00:23:20 | INFO | train_inner | epoch 001:  94951 / 1830643 loss=3.458, ppl=10.99, wps=18440.8, ups=0.56, wpb=32768, bsz=32, num_updates=94800, lr=1.04e-05, gnorm=0.146, loss_scale=16, train_wall=177, gb_free=15.4, wall=156079
2023-10-21 00:26:16 | INFO | train_inner | epoch 001:  95051 / 1830643 loss=3.475, ppl=11.12, wps=18619.8, ups=0.57, wpb=32768, bsz=32, num_updates=94900, lr=1.02e-05, gnorm=0.14, loss_scale=16, train_wall=176, gb_free=15.4, wall=156255
2023-10-21 00:29:12 | INFO | train_inner | epoch 001:  95151 / 1830643 loss=3.369, ppl=10.33, wps=18604.8, ups=0.57, wpb=32768, bsz=32, num_updates=95000, lr=1e-05, gnorm=0.135, loss_scale=16, train_wall=176, gb_free=15.4, wall=156431
2023-10-21 00:32:10 | INFO | train_inner | epoch 001:  95251 / 1830643 loss=3.363, ppl=10.29, wps=18380.9, ups=0.56, wpb=32768, bsz=32, num_updates=95100, lr=9.8e-06, gnorm=0.139, loss_scale=16, train_wall=178, gb_free=15.4, wall=156609
2023-10-21 00:35:08 | INFO | train_inner | epoch 001:  95351 / 1830643 loss=3.234, ppl=9.41, wps=18417.9, ups=0.56, wpb=32768, bsz=32, num_updates=95200, lr=9.6e-06, gnorm=0.139, loss_scale=16, train_wall=178, gb_free=15.4, wall=156787
2023-10-21 00:38:04 | INFO | train_inner | epoch 001:  95451 / 1830643 loss=3.428, ppl=10.77, wps=18628.3, ups=0.57, wpb=32768, bsz=32, num_updates=95300, lr=9.4e-06, gnorm=0.135, loss_scale=32, train_wall=175, gb_free=15.4, wall=156963
2023-10-21 00:41:00 | INFO | train_inner | epoch 001:  95551 / 1830643 loss=3.513, ppl=11.41, wps=18600.3, ups=0.57, wpb=32768, bsz=32, num_updates=95400, lr=9.2e-06, gnorm=0.132, loss_scale=32, train_wall=176, gb_free=15.4, wall=157139
2023-10-21 00:43:56 | INFO | train_inner | epoch 001:  95651 / 1830643 loss=3.313, ppl=9.94, wps=18645.6, ups=0.57, wpb=32768, bsz=32, num_updates=95500, lr=9e-06, gnorm=0.137, loss_scale=32, train_wall=175, gb_free=15.4, wall=157315
2023-10-21 00:46:52 | INFO | train_inner | epoch 001:  95751 / 1830643 loss=3.537, ppl=11.61, wps=18565.1, ups=0.57, wpb=32768, bsz=32, num_updates=95600, lr=8.8e-06, gnorm=0.137, loss_scale=32, train_wall=176, gb_free=15.4, wall=157492
2023-10-21 00:49:50 | INFO | train_inner | epoch 001:  95851 / 1830643 loss=3.321, ppl=9.99, wps=18503.5, ups=0.56, wpb=32768, bsz=32, num_updates=95700, lr=8.6e-06, gnorm=0.14, loss_scale=32, train_wall=177, gb_free=15.4, wall=157669
2023-10-21 00:50:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-10-21 00:52:47 | INFO | train_inner | epoch 001:  95952 / 1830643 loss=3.516, ppl=11.44, wps=18435.3, ups=0.56, wpb=32768, bsz=32, num_updates=95800, lr=8.4e-06, gnorm=0.136, loss_scale=32, train_wall=177, gb_free=15.4, wall=157847
2023-10-21 00:55:43 | INFO | train_inner | epoch 001:  96052 / 1830643 loss=3.288, ppl=9.77, wps=18674.8, ups=0.57, wpb=32768, bsz=32, num_updates=95900, lr=8.2e-06, gnorm=0.134, loss_scale=32, train_wall=175, gb_free=15.4, wall=158022
2023-10-21 00:58:40 | INFO | train_inner | epoch 001:  96152 / 1830643 loss=3.341, ppl=10.13, wps=18520.6, ups=0.57, wpb=32768, bsz=32, num_updates=96000, lr=8e-06, gnorm=0.135, loss_scale=32, train_wall=177, gb_free=15.4, wall=158199
2023-10-21 01:01:36 | INFO | train_inner | epoch 001:  96252 / 1830643 loss=3.464, ppl=11.03, wps=18549.2, ups=0.57, wpb=32768, bsz=32, num_updates=96100, lr=7.8e-06, gnorm=0.138, loss_scale=32, train_wall=176, gb_free=15.4, wall=158376
2023-10-21 01:04:32 | INFO | train_inner | epoch 001:  96352 / 1830643 loss=3.381, ppl=10.42, wps=18678.5, ups=0.57, wpb=32768, bsz=32, num_updates=96200, lr=7.6e-06, gnorm=0.141, loss_scale=32, train_wall=175, gb_free=15.4, wall=158551
2023-10-21 01:04:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 01:07:30 | INFO | train_inner | epoch 001:  96453 / 1830643 loss=3.399, ppl=10.55, wps=18395.2, ups=0.56, wpb=32768, bsz=32, num_updates=96300, lr=7.4e-06, gnorm=0.139, loss_scale=16, train_wall=178, gb_free=15.4, wall=158729
2023-10-21 01:10:26 | INFO | train_inner | epoch 001:  96553 / 1830643 loss=3.522, ppl=11.49, wps=18573.6, ups=0.57, wpb=32768, bsz=32, num_updates=96400, lr=7.2e-06, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=158906
2023-10-21 01:13:24 | INFO | train_inner | epoch 001:  96653 / 1830643 loss=3.333, ppl=10.08, wps=18491.1, ups=0.56, wpb=32768, bsz=32, num_updates=96500, lr=7e-06, gnorm=0.136, loss_scale=16, train_wall=177, gb_free=15.4, wall=159083
2023-10-21 01:16:20 | INFO | train_inner | epoch 001:  96753 / 1830643 loss=3.67, ppl=12.73, wps=18594.4, ups=0.57, wpb=32768, bsz=32, num_updates=96600, lr=6.8e-06, gnorm=0.142, loss_scale=16, train_wall=176, gb_free=15.4, wall=159259
2023-10-21 01:19:16 | INFO | train_inner | epoch 001:  96853 / 1830643 loss=3.508, ppl=11.38, wps=18609.3, ups=0.57, wpb=32768, bsz=32, num_updates=96700, lr=6.6e-06, gnorm=0.144, loss_scale=16, train_wall=176, gb_free=15.4, wall=159435
2023-10-21 01:22:12 | INFO | train_inner | epoch 001:  96953 / 1830643 loss=3.312, ppl=9.93, wps=18582.5, ups=0.57, wpb=32768, bsz=32, num_updates=96800, lr=6.4e-06, gnorm=0.136, loss_scale=32, train_wall=176, gb_free=15.4, wall=159611
2023-10-21 01:25:09 | INFO | train_inner | epoch 001:  97053 / 1830643 loss=3.171, ppl=9.01, wps=18516.5, ups=0.57, wpb=32768, bsz=32, num_updates=96900, lr=6.2e-06, gnorm=0.137, loss_scale=32, train_wall=177, gb_free=15.4, wall=159788
2023-10-21 01:28:05 | INFO | train_inner | epoch 001:  97153 / 1830643 loss=3.494, ppl=11.26, wps=18602.8, ups=0.57, wpb=32768, bsz=32, num_updates=97000, lr=6e-06, gnorm=0.138, loss_scale=32, train_wall=176, gb_free=15.4, wall=159965
2023-10-21 01:31:01 | INFO | train_inner | epoch 001:  97253 / 1830643 loss=3.4, ppl=10.56, wps=18616.9, ups=0.57, wpb=32768, bsz=32, num_updates=97100, lr=5.8e-06, gnorm=0.135, loss_scale=32, train_wall=176, gb_free=15.4, wall=160141
2023-10-21 01:33:58 | INFO | train_inner | epoch 001:  97353 / 1830643 loss=3.316, ppl=9.96, wps=18563.3, ups=0.57, wpb=32768, bsz=32, num_updates=97200, lr=5.6e-06, gnorm=0.135, loss_scale=32, train_wall=176, gb_free=15.4, wall=160317
2023-10-21 01:34:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-10-21 01:36:56 | INFO | train_inner | epoch 001:  97454 / 1830643 loss=3.226, ppl=9.35, wps=18385.8, ups=0.56, wpb=32768, bsz=32, num_updates=97300, lr=5.4e-06, gnorm=0.132, loss_scale=32, train_wall=178, gb_free=15.4, wall=160495
2023-10-21 01:39:53 | INFO | train_inner | epoch 001:  97554 / 1830643 loss=3.481, ppl=11.16, wps=18569.7, ups=0.57, wpb=32768, bsz=32, num_updates=97400, lr=5.2e-06, gnorm=0.137, loss_scale=32, train_wall=176, gb_free=15.4, wall=160672
2023-10-21 01:42:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 01:42:51 | INFO | train_inner | epoch 001:  97655 / 1830643 loss=3.46, ppl=11, wps=18329.8, ups=0.56, wpb=32768, bsz=32, num_updates=97500, lr=5e-06, gnorm=0.137, loss_scale=16, train_wall=178, gb_free=15.4, wall=160851
2023-10-21 01:45:48 | INFO | train_inner | epoch 001:  97755 / 1830643 loss=3.492, ppl=11.25, wps=18525, ups=0.57, wpb=32768, bsz=32, num_updates=97600, lr=4.8e-06, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=161027
2023-10-21 01:48:45 | INFO | train_inner | epoch 001:  97855 / 1830643 loss=3.367, ppl=10.31, wps=18551.2, ups=0.57, wpb=32768, bsz=32, num_updates=97700, lr=4.6e-06, gnorm=0.134, loss_scale=16, train_wall=176, gb_free=15.4, wall=161204
2023-10-21 01:51:42 | INFO | train_inner | epoch 001:  97955 / 1830643 loss=3.261, ppl=9.59, wps=18521.7, ups=0.57, wpb=32768, bsz=32, num_updates=97800, lr=4.4e-06, gnorm=0.136, loss_scale=16, train_wall=177, gb_free=15.4, wall=161381
2023-10-21 01:54:38 | INFO | train_inner | epoch 001:  98055 / 1830643 loss=3.382, ppl=10.42, wps=18587.8, ups=0.57, wpb=32768, bsz=32, num_updates=97900, lr=4.2e-06, gnorm=0.134, loss_scale=16, train_wall=176, gb_free=15.4, wall=161557
2023-10-21 01:57:35 | INFO | train_inner | epoch 001:  98155 / 1830643 loss=3.402, ppl=10.57, wps=18488.6, ups=0.56, wpb=32768, bsz=32, num_updates=98000, lr=4e-06, gnorm=0.138, loss_scale=16, train_wall=177, gb_free=15.4, wall=161735
2023-10-21 01:58:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 02:00:34 | INFO | train_inner | epoch 001:  98256 / 1830643 loss=3.382, ppl=10.43, wps=18359.1, ups=0.56, wpb=32768, bsz=32, num_updates=98100, lr=3.8e-06, gnorm=0.137, loss_scale=16, train_wall=178, gb_free=15.4, wall=161913
2023-10-21 02:03:30 | INFO | train_inner | epoch 001:  98356 / 1830643 loss=3.251, ppl=9.52, wps=18607.9, ups=0.57, wpb=32768, bsz=32, num_updates=98200, lr=3.6e-06, gnorm=0.136, loss_scale=16, train_wall=176, gb_free=15.4, wall=162089
2023-10-21 02:06:26 | INFO | train_inner | epoch 001:  98456 / 1830643 loss=3.247, ppl=9.49, wps=18597.2, ups=0.57, wpb=32768, bsz=32, num_updates=98300, lr=3.4e-06, gnorm=0.133, loss_scale=16, train_wall=176, gb_free=15.4, wall=162265
2023-10-21 02:09:24 | INFO | train_inner | epoch 001:  98556 / 1830643 loss=3.381, ppl=10.42, wps=18438, ups=0.56, wpb=32768, bsz=32, num_updates=98400, lr=3.2e-06, gnorm=0.132, loss_scale=16, train_wall=177, gb_free=15.4, wall=162443
2023-10-21 02:12:20 | INFO | train_inner | epoch 001:  98656 / 1830643 loss=3.45, ppl=10.93, wps=18621.5, ups=0.57, wpb=32768, bsz=32, num_updates=98500, lr=3e-06, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=162619
2023-10-21 02:15:16 | INFO | train_inner | epoch 001:  98756 / 1830643 loss=3.422, ppl=10.72, wps=18594.9, ups=0.57, wpb=32768, bsz=32, num_updates=98600, lr=2.8e-06, gnorm=0.135, loss_scale=32, train_wall=176, gb_free=15.4, wall=162795
2023-10-21 02:18:13 | INFO | train_inner | epoch 001:  98856 / 1830643 loss=3.318, ppl=9.97, wps=18511.8, ups=0.56, wpb=32768, bsz=32, num_updates=98700, lr=2.6e-06, gnorm=0.137, loss_scale=32, train_wall=177, gb_free=15.4, wall=162972
2023-10-21 02:21:10 | INFO | train_inner | epoch 001:  98956 / 1830643 loss=3.303, ppl=9.87, wps=18496.6, ups=0.56, wpb=32768, bsz=32, num_updates=98800, lr=2.4e-06, gnorm=0.134, loss_scale=32, train_wall=177, gb_free=15.4, wall=163149
2023-10-21 02:21:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 02:24:09 | INFO | train_inner | epoch 001:  99057 / 1830643 loss=3.457, ppl=10.98, wps=18303.6, ups=0.56, wpb=32768, bsz=32, num_updates=98900, lr=2.2e-06, gnorm=0.14, loss_scale=16, train_wall=179, gb_free=15.4, wall=163328
2023-10-21 02:27:05 | INFO | train_inner | epoch 001:  99157 / 1830643 loss=3.354, ppl=10.22, wps=18587.1, ups=0.57, wpb=32768, bsz=32, num_updates=99000, lr=2e-06, gnorm=0.133, loss_scale=16, train_wall=176, gb_free=15.4, wall=163505
2023-10-21 02:30:02 | INFO | train_inner | epoch 001:  99257 / 1830643 loss=3.477, ppl=11.13, wps=18583.5, ups=0.57, wpb=32768, bsz=32, num_updates=99100, lr=1.8e-06, gnorm=0.132, loss_scale=16, train_wall=176, gb_free=15.4, wall=163681
2023-10-21 02:32:58 | INFO | train_inner | epoch 001:  99357 / 1830643 loss=3.554, ppl=11.75, wps=18565.1, ups=0.57, wpb=32768, bsz=32, num_updates=99200, lr=1.6e-06, gnorm=0.138, loss_scale=16, train_wall=176, gb_free=15.4, wall=163858
2023-10-21 02:35:56 | INFO | train_inner | epoch 001:  99457 / 1830643 loss=3.301, ppl=9.85, wps=18430.1, ups=0.56, wpb=32768, bsz=32, num_updates=99300, lr=1.4e-06, gnorm=0.138, loss_scale=16, train_wall=177, gb_free=15.4, wall=164035
2023-10-21 02:38:53 | INFO | train_inner | epoch 001:  99557 / 1830643 loss=3.472, ppl=11.1, wps=18525.2, ups=0.57, wpb=32768, bsz=32, num_updates=99400, lr=1.2e-06, gnorm=0.136, loss_scale=32, train_wall=177, gb_free=15.4, wall=164212
2023-10-21 02:41:49 | INFO | train_inner | epoch 001:  99657 / 1830643 loss=3.305, ppl=9.89, wps=18581.6, ups=0.57, wpb=32768, bsz=32, num_updates=99500, lr=1e-06, gnorm=0.139, loss_scale=32, train_wall=176, gb_free=15.4, wall=164389
2023-10-21 02:44:45 | INFO | train_inner | epoch 001:  99757 / 1830643 loss=3.678, ppl=12.8, wps=18665.4, ups=0.57, wpb=32768, bsz=32, num_updates=99600, lr=8e-07, gnorm=0.167, loss_scale=32, train_wall=175, gb_free=15.4, wall=164564
2023-10-21 02:47:42 | INFO | train_inner | epoch 001:  99857 / 1830643 loss=3.432, ppl=10.79, wps=18460.9, ups=0.56, wpb=32768, bsz=32, num_updates=99700, lr=6e-07, gnorm=0.14, loss_scale=32, train_wall=177, gb_free=15.4, wall=164742
2023-10-21 02:50:38 | INFO | train_inner | epoch 001:  99957 / 1830643 loss=3.508, ppl=11.37, wps=18629.8, ups=0.57, wpb=32768, bsz=32, num_updates=99800, lr=4e-07, gnorm=0.137, loss_scale=32, train_wall=176, gb_free=15.4, wall=164918
2023-10-21 02:51:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-10-21 02:53:38 | INFO | train_inner | epoch 001:  100058 / 1830643 loss=3.343, ppl=10.15, wps=18273.8, ups=0.56, wpb=32768, bsz=32, num_updates=99900, lr=2e-07, gnorm=0.134, loss_scale=32, train_wall=179, gb_free=15.4, wall=165097
2023-10-21 02:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-10-21 02:56:36 | INFO | train_inner | epoch 001:  100159 / 1830643 loss=3.377, ppl=10.39, wps=18317.3, ups=0.56, wpb=32768, bsz=32, num_updates=100000, lr=0, gnorm=0.133, loss_scale=16, train_wall=179, gb_free=15.4, wall=165276
2023-10-21 02:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 100000 updates
2023-10-21 02:56:36 | INFO | fairseq.trainer | Saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_100000.pt
2023-10-21 02:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_100000.pt
2023-10-21 02:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/zyu401_data/anirudh/longmem_data/train_ckpt/6early/again/checkpoint_1_100000.pt (epoch 1 @ 100000 updates, score None) (writing took 15.070692036068067 seconds)
2023-10-21 02:57:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-10-21 02:59:49 | INFO | train_inner | epoch 001:  100260 / 1830643 loss=3.283, ppl=9.73, wps=17011.8, ups=0.52, wpb=32768, bsz=32, num_updates=100100, lr=0, gnorm=0.15, loss_scale=8, train_wall=177, gb_free=15.4, wall=165468
[E ProcessGroupGloo.cpp:138] Rank 2 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 3 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[E ProcessGroupGloo.cpp:138] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
/data/zyu401_data/anirudh/longmem/lib/python3.8/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
/data/zyu401_data/anirudh/longmem/lib/python3.8/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Traceback (most recent call last):
  File "/data/zyu401_data/anirudh/longmem/bin/fairseq-train", line 8, in <module>
    sys.exit(cli_main())
  File "/nethome/zyu401/anirudh/LongMem/fairseq/fairseq_cli/train.py", line 561, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/nethome/zyu401/anirudh/LongMem/fairseq/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/data/zyu401_data/anirudh/longmem/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/zyu401_data/anirudh/longmem/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/data/zyu401_data/anirudh/longmem/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
/data/zyu401_data/anirudh/longmem/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 15 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
